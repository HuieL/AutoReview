{"name": "ICLR_2017_119.pdf", "metadata": {"source": "CRF", "title": "RECURRENT HIDDEN SEMI-MARKOV MODEL", "authors": ["Hanjun Dai", "Bo Dai", "Yan-Ming Zhang", "Shuang Li", "Le Song"], "emails": ["sli370}@gatech.edu,", "lsong@cc.gatech.edu", "ymzhang@nlpr.ia.ac.cn"], "sections": [{"heading": "1 INTRODUCTION", "text": "Segmentation and labeling of time series data is an important problem in machine learning and signal processing. Given a sequence of observations {x1, x2, . . . , xT }, we want to divide the T observations into several segments and label each segment simultaneously, where each segment consists of consecutive observations. The supervised sequence segmentation or labeling techniques have been well studied in recent decades (Sutskever et al., 2014; Kong et al., 2015; Chen et al., 2015). However, for complicated signals, like human activity sensor data, accurately annotating the segmentation boundary or the activity type would be prohibitive. Therefore, it is urgent to develop unsupervised algorithms that can jointly learn segmentation and labeling information directly from the data without supervisions. Figure 1 provides an illustration which we are focus on.\nThe Hidden Semi-Markov Model (HSMM) (Murphy, 2002) is a powerful model for such task. It eliminates the implicit geometric duration distribution assumptions in HMM (Yu, 2010), thus allows the state to transit in a non-Markovian way. Most of the HSMM variants make strong parametric assumptions on the observation model (Rabiner, 1989; Johnson & Willsky, 2013; Yu, 2010). This makes the learning and inference simple, but ignores the nonlinear and long-range dependency within a segment. Take the human activity signals as an example. The movements a person performs at a certain time step would rely heavily on the previous movements, like the interleaving actions of left hand and right hand in swimming, or more complicated dependency like shooting after jumping in playing basketball. Some models have been proposed to tackle this problem (Ghahramani & Hinton, 2000; Fox et al., 2009; Linderman et al., 2016), but are limited in linear case.\nSince people have justified RNN\u2019s ability in modeling nonlinear and complicated dependencies (Sutskever et al., 2014; Du et al., 2016), we introduce the recurrent neural emission model into HSMM for capturing various dependencies within each segment to address such issue. However, the flexibility of recurrent neural model comes with prices: it makes the exact Expectation-Maximization (EM) algorithm computationally too expensive.\nTo speed up the learning and inference, we exploit the variational encoder (VAE) framework (Kingma & Welling, 2013). Specifically, we propose to use bidirectional RNN (bi-RNN) encoder. Such\narchitecture will mimic the forward-backward algorithm, and hence is expected to capture similar information as in exact posterior calculation.\nIt should be emphasized that due to the discrete nature of the latent variables in our model, the algorithm proposed in Kingma & Welling (2013) and its extension on time-series models (Gao et al., 2016; Krishnan et al., 2015) are not directly applicable. There are plenty of work proposed based on stochastic neuron (Tang & Salakhutdinov, 2013; Bengio et al., 2013; Mnih & Gregor, 2014; Raiko et al., 2014; Gu et al., 2015; Chung et al., 2016) to remedy such issue. However, none of these off-the-shelf methods are easy to achieve good performance according to our experiment: the hundreds or thousands layers of stochastic neuron (which is equal to the length of sequence), together with the switching generative RNN, make the encoding function very sensitive, and thus, extremely difficult to train fully on unsupervised setting. We propose a solution, stochastic distributional penalty method, which introduces auxiliary distributions to separate the decoding R-HSMM and encoding bi-RNN in training procedure, and thus, reduces the learning difficulty for each component. This novel algorithm is general enough and can be applied to other VAE with discrete latent variables, which can be of independent interest. We emphasize that the proposed algorithm is maximizing exact the nagative Helmholtz variational free energy. It is different from Johnson et al. (2016) in which a lower bound of the variational free energy is proposed as the surrogate to be maximized for convenience.\nWe experimentally justified our algorithm on the synthetic datasets and three real-world datasets, namely the segmentation tasks for human activity, fruit fly behavior and heart sound records. The R-HSMM with Viterbi exact inference significantly outperforms basic HSMM and its variants, demonstrating the generative model is indeed flexible. Moreover, the trained bi-RNN encoder also achieve similar state-of-the-art performances to the exact inference, but with 400 times faster inference speed, showing the proposed structured encoding function is able to mimic the exact inference efficiently."}, {"heading": "2 MODEL ARCHITECTURE", "text": "Given a sequence x = [x1, x2, . . . , x|x|], where xt \u2208 Rm is an m dimensional observation at time t, our goal is to divide the sequence into meaningful segments. Thus, each observation xt will have the corresponding label zt \u2208 Z, where Z = {1, 2, . . . ,K} is a finite discrete label set and K is predefined. The label sequence z = [z1, z2, . . . , z|x|] should have the same length of x.\nBesides labels, HSMM will associate each position twith additional variable dt \u2208 D = {1, 2, . . . , D}, where dt is known as duration variable andD is the maximum possible duration. The duration variable can control the number of steps the current hidden state will remain. We use d to denote the duration sequence. We also use notation xt1:t2 to denote the substring [xt1 , xt1+1, . . . , xt2 ] of x. Without ambiguity, we use z as a segment label, and d as the duration.\nIn this paper, we focus on one of the variants of HSMM, namely the explicit duration HMM (EDHMM) (Rabiner, 1989), and use Decreasing Count Variables (Chiappa, 2014) for the notation.\nExplicit Duration Hidden Markov Model. Similar to HMM, this model treats the pair of (z, d) as \u2018macro hidden state\u2019. The probability of initial macro state is defined as P (z, d) = P (z)P (d|z). We use the notation \u03c0z , P (z) and P (d|z) , Bz,d to parametrize the initial probability and duration probability, respectively. Ai,j , P (zt = i|zt\u22121 = j, dt\u22121 = 1) is the state transition probability on the segment boundary. Here \u03c0 \u2208 RK is in K-dimensional simplex. For each hidden state z, the corresponding rows Bz,: and Az,: are also in probability simplex. Here we assume the multinomial distribution for P (d|z). In EDHMM, the transition probability of macro hidden state P (zt, dt|zt\u22121, dt\u22121) is decomposed by P (zt|zt\u22121, dt\u22121)P (dt|zt, dt\u22121) and thus can be defined as:\nP (zt|zt\u22121, dt\u22121) = { Azt\u22121,zt if dt\u22121 = 1 I(zt=zt\u22121) if dt\u22121 > 1 ; P (dt|zt, dt\u22121) = { Bzt,dt if dt\u22121 = 1 I(dt=dt\u22121\u22121) if dt\u22121 > 1 . (1)The graphical model is shown in Figure 2a.\nRecurrent Hidden Semi-Markov Model. For the simplicity of explanation, we focus our algorithm on the single sequence first. It is straightforward to apply the algorithm for dataset that has multiple sequences. Given the parameters {\u03c0,A,B}, the log-likelihood of a single observation sequence x can be written as below,\nL(x) = log \u2211 z,d \u03c0z1Bz1,d1 |x|\u220f t=2 P (zt|zt\u22121, dt\u22121)P (dt|zt, dt\u22121)P (x|z,d), (2)\nwhere P (x|z,d) is the emission probability. To define P (x|z,d), we further denote the sequence variable s = [s1, s2, . . . , s|s|] to be the switching position (or the beginning) of segments. Thus s1 = 1, and si = si\u22121 + dsi\u22121 and |s| is the number of segments. Traditional HSMM assumes P (x|z,d) = \u220f|x| t=1 P (xt|zt), which ignores the dependency and some degree of dynamics exhibited in each segment. While in this paper, we use RNN as the generative model to capture the dependent emission probability. Specifically, for the i-th segment starting from position si, the corresponding generative process is\nP (xsi:si+dsi\u22121|zsi , dsi) = si+dsi\u22121\u220f t=si P (xt|xsi:t\u22121, zsi) = si+dsi\u22121\u220f t=si P (xt|ht, zsi) (3)\nwhere we assume that the dependency of history before time step j can be captured by a vector hj \u2208 Rh. As in RNN, we use a recurrent equation to formulate the history vector,\nht = \u03c3(W (zsi )xt\u22121 + V (zsi )ht\u22121 + b (zsi )). (4) Finally, in this model, P (x|z,d) = \u220f|s| i=1 P (xsi:si+dsi\u22121|zsi , dsi) is computed by the product of generative probabilities for each segment. In Eq. 4, W \u2208 Rm\u00d7h is a weight matrix capturing the last observation xt\u22121, and V \u2208 Rh\u00d7h is for the propagation of history ht\u22121. The b is a bias term. The superscript zsi indexes the RNN we used for the corresponding segment. The segments with different labels are generated using different RNNs. So we should maintain K RNNs. \u03c3(\u00b7) is a nonlinear activation function. We use tanh in our experiments.\nAt the time step t, we assume a diagonal multivariate gaussian distribution over the conditional likelihood, where the mean and covariance matrix are the output of RNN, i.e.,\nP (xt|ht, zsi) \u223c N (xt;\u00b5 = U (zsi ) \u00b5 ht + b (zsi ) \u00b5 ,\u03a3 = Diag(exp(U (zsi ) \u03a3 ht + b (zsi ) \u03a3 ))) (5)\nThe matrices U\u00b5, U\u03a3 \u2208 Rm\u00d7h are used for parametrizing the mean and covariance at each time step j, given the history information. b\u00b5, b\u03a3 \u2208 Rm are bias terms. For simplicity, let\u2019s use \u03b8rnn = {\u03b8(1)rnn, \u03b8(2)rnn, . . . , \u03b8(K)rnn} to denote the collection of parameters in each RNN. On the boundary case, i.e., the starting point of each segment, we simply set ht = 0, which can be viewed as the setting according to the prior knowledge (bias terms) of RNN.\nThe above formulation indicates that the generative model P (xt|ht, zsi) depends not only on the last step observation xt\u22121, but also the last hidden state ht\u22121, which is together captured in Eq. 4. In summary, we denote all the parameters in the proposed R-HSMM as \u03b8 = {\u03c0,A,B, \u03b8rnn}. The corresponding graphical model is shown in Figure 2b."}, {"heading": "3 SEQUENTIAL VARIATIONAL AUTOENCODER", "text": "To obtain the posterior or MAP in the proposed R-HSMM, the classical forward-backward algorithm or Viterbi algorithm needs to solve one dynamic programming per sample, which makes the inference costly, especially for the long sequence with thousands of timestamps. So instead, we treat the Bayesian inference from optimization perspective, and obtain the posterior by maximizing the negative Helmholtz variational free energy (Williams, 1980; Zellner, 1988; Dai et al., 2016),\nmax Q(z,d|x)\u2208P\nL\u03b8Q(x) := EQ(z,d|x) [logP\u03b8(x, z,d)\u2212 logQ(z,d|x)] , (6)\nover the space of all valid densities P . To make the optimization (6) tractable, the variational autoencoder restricts the feasible sets to be some parametrized density Q\u03c8, which can be executed efficiently comparing to the forward-backward algorithm or Viterbi algorithm. However, such restriction will introduce extra approximation error. To reduce the approximation error, we use a structured model, i.e., bidirectional RNN, to mimic the dynamic programming in forward-backward algorithm. Specifically, in the forward-backward algorithm, the forward message \u03b1t(zt, dt) and backward message \u03b2t(zt, dt) can be computed recursively, and marginal posterior at position t depends on both \u03b1t(zt, dt) and \u03b2t(zt, dt). Similarly, in bi-RNN we embed the posterior message with RNN\u2019s latent vector, and marginal posterior is obtained from the latent vectors of two RNNs at the same time step t. Let \u03c8 = {\u03c8\u2212\u2212\u2212\u2192RNN1 , \u03c8\u2190\u2212\u2212\u2212RNN2 ,Wz \u2208 R\nh\u00d7K ,Wd \u2208 Rh\u00d7D} be the parameters of bi-RNN encoder, the Q\u03c8 is decomposed as:\nQ\u03c8(z,d|x) = Q(z1|h1;\u03c8)Q(d1|z1, h1;\u03c8) |x|\u220f t=2 Q(zt|dt\u22121, ht;\u03c8)Q(dt|zt, dt\u22121, ht;\u03c8), (7)\nwhere ht = [ \u2212\u2212\u2212\u2192 RNN1(x1:t), \u2190\u2212\u2212\u2212 RNN2(xt:|x|)] is computed by bi-RNN. We use multinomial distributions Q(zt|ht;\u03c8) =M(softmax(W>z ht)) and Q(dt|zt, ht;\u03c8) =M(softmax(W>d ht)). The dependency over dt\u22121 ensures that the generated segmentation (z,d) is valid according to Eq. 1. For example, if we sampled duration dt\u22121 > 1 from Q\u03c8 at time t\u2212 1, then dt and zt should be deterministic. In our experiment, we use LSTM (Hochreiter & Schmidhuber, 1997) as the recursive units in bi-RNN.\nSince with any fixed \u03b8, the negative Helmholtz variational free energy is indeed the lower bound of the marginal likelihood, i.e.,\nlogP\u03b8(x) \u2265 L(\u03b8, \u03c8;x) := EQ\u03c8(z,d|x)[logP\u03b8(x, z,d)\u2212 logQ\u03c8(z,d|x)], (8) therefore, we can treat it as a surrogate of the marginal log-likelihood and learn \u03b8 jointly with approximate inference, i.e.,\nmax \u03b8,\u03c8\n1\nN N\u2211 n=1 L(\u03b8, \u03c8;x(n)) (9)\nIt should be emphasized that due to the discrete nature of latent variables in our model, the algorithm proposed in Kingma & Welling (2013) is not directly applicable, and its extension with stochastic neuron reparametrization (Bengio et al., 2013; Raiko et al., 2014; Gu et al., 2015; Chung et al., 2016) cannot provide satisfied results for our model according to our experiments. Therefore, we extend the penalty method to distribution space to solve optimization (9).\nAlgorithm 1 Learning sequential VAE with stochastic distributional penalty method\n1: Input: sequences {x(n)}Nn=1 2: Randomly initialize \u03c8(0) and \u03b80 = {\u03c00, A0, B0, \u03b80rnn} 3: for \u03bb = 0, . . . ,\u221e do 4: for t = 0 to T do 5: Sample {x(n)}Mn=1 uniformly from dataset with mini-batch size M . 6: Get {z(n),d(n)}Mn=1 with \u03b8t by dynamic programming in (13). 7: Update \u03c0t+1, At+1, Bt+1 using rule (16). 8: \u03b8t+1rnn = \u03b8 t rnn,\u2212\u03b3t 1M \u2211M n=1\u2207\u03b8trnnL\u0303\u03bb(\u03b8, \u03c8|x (n))\n9: \u03c8t+1 = \u03c8t \u2212 \u03b7t 1M \u2211M n=1\u2207\u03c8tL\u0303\u03bb(\u03b8, \u03c8|x(n)) . bi-rnn sequence to sequence learning\n10: end for 11: end for"}, {"heading": "4 LEARNING VIA STOCHASTIC DISTRIBUTIONAL PENALTY METHOD", "text": "As we discussed, learning the sequential VAE with stochastic neuron reparametrization in unsupervised setting is extremely difficult, and none the off-the-shelf techniques can provide satisfied results. In this section, we introduce auxiliary distribution into (9) and generalize the penalty method Bertsekas (1999) to distribution space.\nSpecifically, we first introduce an auxiliary distribution Q\u0303(z,d|x) for each x and reformulate the optimization (9) as\nmax \u03b8,\u03c8,{Q\u0303(z,d|x(n))}Nn=1\n1\nN N\u2211 n=1 EQ\u0303(z,d|x(n)) [ logP\u03b8(x (n), z,d)\u2212 log Q\u0303(z,d|x(n)) ] , (10)\ns.t. KL ( Q\u0303(z,d|x(n))||Q\u03c8(z,d|x(n)) ) = 0, \u2200x(n), n = 1, . . . , N.\nWe enforce the introduced Q\u0303(z,d|x) equals to Q\u03c8(z,d|x) in term of KL-divergence, so that the optimization problems (9) and (10) are equivalent. Because of the non-negativity of KL-divergence, itself can be viewed as the penalty function, we arrive the alternative formulation of (10) as\nmax \u03b8,\u03c8,{Q\u0303(z,d|x(n))}Nn=1\n1\nN N\u2211 n=1 L\u0303\u03bb(\u03b8, \u03c8|x(n)), (11)\nwhere L\u0303\u03bb(\u03b8, \u03c8|x) = EQ\u0303(z,d|x) [ logP\u03b8(x, z,d)\u2212 log Q\u0303(z,d|xi) ] \u2212 \u03bbKL ( Q\u0303(z,d|x)||Q\u03c8(z,d|x) ) and \u03bb \u2265 0. Obviously, as \u03bb \u2192 \u221e, KL(Q\u0303(z,d|x)||Q\u03c8(z,d|x)) must be 0, otherwise the L\u0303\u221e(\u03b8, \u03c8|x) will be \u2212\u221e for arbitrary \u03b8, \u03c8. Therefore, the optimization (11) will be equivalent to problem (10). Following the penalty method, we can learn the model with \u03bb increasing from 0 to \u221e gradually. The entire algorithm is described in Algorithm 1. Practically, we can set \u03bb = {0,\u221e} and do no need the gradually incremental, while still achieve satisfied performance. For each fixed \u03bb, we optimize Q\u0303 and the parameters \u03b8, \u03c8 alternatively. To handle the expectation in the optimization, we will exploit the stochastic gradient descent. The update rules for \u03b8, \u03c8 and Q\u0303 derived below."}, {"heading": "4.1 UPDATING Q\u0303", "text": "In fact, fix \u03bb, Q\u03c8 and P\u03b8 in optimization (11), the optimal solution Q\u0303\u2217(z,d|x) for each x has closed-form. Theorem 1 Given fixed \u03bb, Q\u03c8 and P\u03b8, Q\u0303\u2217(z,d|x) \u221d Q\u03c8(z,d|x) \u03bb 1+\u03bbP\u03b8(x, z,d) 1 1+\u03bb achieves the optimum in (11). Proof The proof is straightforward. Take the functional derivative of L\u0303 w.r.t. Q\u0303 and set it to zeros,\n\u2207Q\u0303L\u0303 = logP\u03b8(x, z,d) + \u03bb logQ(z,d|x)\u2212 (1 + \u03bb) log Q\u0303(z,d|x) = 0,\nwe obtain 11+\u03bb logP\u03b8(x, z,d) + \u03bb 1+\u03bb logQ(z,d|x) = log Q\u0303(z,d|x). Take exponential on both sides, we achieve the conclusion. In fact, because we are using the stochastic gradient for updating \u03b8 and \u03c8 later, Q\u0303\u2217(z,d|x) is never explicitly computed and only samples from it are required. Recall the fact that Q\u03c8(z,d|x) has a nice decomposition 7, we can multiply its factors into each recursion step and still get the same complexity\nas original Viterbi algorithm for MAP or sampling. Specifically, let\u2019s define \u03b1t(j, r) to be the best joint log probability of prefix x1:t and its corresponding segmentation which has the last segment with label j and duration r, i.e.,\n\u03b1t(j, r) , max z1:t,d1:t log Q\u0303(z1:t,d1:t|x1:t), s.t. zt = j, dt = dt\u2212r = 1, dt\u2212r+1 = r (12)\nhere t \u2208 {1, 2, . . . , |x|}, j \u2208 Z, r \u2208 D. Then we can recursively compute the entries in \u03b1 as below:\n\u03b1t(j, r) =  \u03b1t\u22121(j, r \u2212 1) + 11+\u03bb log( Bj,r Bj,r\u22121 P (xt|xt\u2212r+1:t\u22121, z = j)) r > 1, t > 1 + \u03bb1+\u03bb log Q\u03c8(dt\u2212r+1=r|z=j,x) Q\u03c8(dt\u2212r+1=r\u22121|z=j,x) ; maxi\u2208Z\\j maxr\u2032\u2208D \u03b1t\u22121(i, r \u2032) + 11+\u03bb log(Ai,jBj,1P (xt|z = j)) r = 1, t > 1 + \u03bb1+\u03bb logQ\u03c8(zt\u2212r+1 = j, dt\u2212r+1 = r|x); \u03bb 1+\u03bb logQ\u03c8(z1 = j, d1 = r|x) + 1\n1+\u03bb log(\u03c0jBj,1P (x1|z = j)); r = 1, t = 1 0. otherwise\n(13) To construct the MAP solution, we also need to keep a back-tracing array \u03b2t(j, r) that records the transition path from \u03b1t\u22121(i, r\u2032) to \u03b1t(j, r). The sampling from Q\u0303(z,d|x) also can be completed with almost the same style forwards filtering backwards sampling algorithm, except replacing the max-operator by sum-operator in \u03b1 propagation Murphy (2012).\nWithout considering the complexity of computing emission probabilities, the dynamic programming needs time complexity O ( |x|K2 + |x|KD ) (Yu & Kobayashi, 2003) and O(|x|K) memory. We explain the details of optimizing the time and memory requirements in Appendix A.\nRemark: When \u03bb =\u221e, the Q\u0303(z,d|x) will be exactly Q\u03c8(z,d|x) and the algorithm will reduce to directly working on Q\u03c8(z,d|x) without the effect from P\u03b8(x, z,d). Therefore, it is equivalent to obtaining MAP or sampling of the latent variables z,d from Q\u03c8(z,d|x), whose cost is O(|x|K). In practical, to further accelerate the computation, we can follow such strategy to generate samples when \u03bb is already large enough, and thus, the effect of P\u03b8(x, z,d) is negligible.\n4.2 UPDATING \u03b8 AND \u03c8\nWith the fixed Q\u0303(z,d|x), we can update the \u03b8 and \u03c8 by exploiting stochastic gradient descent algorithm to avoid scanning the whole training set. Sample a mini-batch of sequences {xn}Mn=1 with size M N , we proceed to update {\u03b8, \u03c8} by optimizing the Monte Carlo approximation of (11),\nmax \u03b8,\u03c8\n1\nM M\u2211 n=1 logP\u03b8(x (n), z(n),d(n)) + \u03bb logQ\u03c8(z (n),d(n)|x(n)), (14)\nwhere {z(n),d(n)} is the MAP or a sample of Q\u0303(z,d|x(n)). Note that the two parts related to \u03b8 and \u03c8 are separated now, we can optimize them easily.\nUpdate \u03b8: Finding parameters to maximize the likelihood needs to solve the constrained optimization shown below\nmax \u03b8\n1\nM M\u2211 n=1\n( log \u03c0\nz (n) 1\n+ |s|\u2211 i=2 logA z (n) si\u22121 ,z (n) si + |s|\u2211 i=1 B z (n) si ,d (n) si + si+d (n) si \u22121\u2211\nj=si\nlogP (x (n) j |h (n) j , z (n) si ; \u03b8rnn) ) (15)\nwhere {\u03c0,A,B} are constrained to be valid probability distribution. We use stochastic gradient descent to update \u03b8rnn in totally K RNNs. For parameters \u03c0,A,B which are restricted to simplex, the stochastic gradient update will involve extra projection step. To avoid such operation which may be costly, we propose the closed-form update rule derived by Lagrangian,\n\u03c0i =\n\u2211M n=1 I(z (n) 1 = i)\nm , Ai,j =\n\u2211M n=1 \u2211|s(n)|\u22121 t=1 I(z (n) st = i and z\n(n) st+1 = j)\u2211M\nn=1 |s(n)| \u2212M (16)\nBj,r =\n\u2211M n=1 \u2211|s(n)| t=1 I(d (n) st = r and z\n(n) st = j)\u2211M\nn=1 |s(n)| Since we already have the segmentation solution, the total number of samples used for training is equal to the number of observations in dataset. The different RNNs use different parameters, and train on different parts of observations. This makes it easy for parallelized training.\nUpdate \u03c8: Given fixed \u03bb, logQ\u03c8(z(n),d(n)|x(n)) is essentially the sequence to sequence likelihood, where the input sequence is x and output sequence is {z,d}. Using the form of Q\u03c8 in Eq 7, this likelihood can be decomposed by positions. Thus we can conveniently train a bi-RNN which maximize the condition likelihood of latent variables by stochastic gradient descent.\nRemark: We can get multiple samples {z,d} for each x from Q\u0303(z,d|x) to reduce the variance in stochastic gradient. In our algorithm, the samples of latent variable come naturally from the auxiliary distributions (which are integrated with penalty method), rather than the derivation from lower bound of objective (Tang & Salakhutdinov, 2013; Raiko et al., 2014; Mnih & Rezende, 2016)."}, {"heading": "5 EXPERIMENTS", "text": "Baselines We compare with classical HSMM and two popular HSMM variants. The first one is Hierarchical Dirichlet-Process HSMM (HDP-HSMM) (Johnson & Willsky, 2013), which is the nonparametric Bayesian extension to the traditional HSMM that allows infinite number of hidden states; the second one is called subHSMM (Johnson & Willsky, 2014), which uses infinite HMM as the emission model for each segment. This model also has two-level of latent structure. It considers the dependency within each segment, which is a stronger algorithm than HDP-HSMM. We also compare with the CRF autoencoder (CRF-AE) (Ammar et al., 2014), which uses markovian CRF as recognition model and conditional i.i.d.model for reconstruction. Comparing to HSMM, this model ignores the segmentation structures in modeling and is more similar to HMM. Evaluation Metric We evaluate the performance of each method via the labeling accuracy. Specifically, we compare the labels of each single observations in each testing sequence. Since the labels are unknown during training, we use KM algorithm (Munkres, 1957) to find the best mapping between predicted labels and ground-truth labels. Settings Without explicitly mentioned, we use leave-one-sequence-out protocol to evaluate the methods. Each time we test on one held-out sequence, and train on other sequences. We report the mean accuracy in Table 1. We set the truncation of max possible duration D to be 400 for all tasks. We also set the number of hidden states K to be the same as ground truth.\nFor the HDP-HSMM and subHSMM, the observation distributions are initialized as standard Multivariate Gaussian distributions. The duration is modeled by the Poisson distribution. We tune the concentration parameters \u03b1, \u03b3 \u2208 {0.1, 1, 3, 6, 10}. The hyperparameters are learned automatically. For subHSMM, we tune the truncation threshold of the second level infinite HMM from {2 . . . 15}. For CRF-AE, we extend the origin model for the continuous observations, and learn all parameters similar to M. Schmidt (2008). We use mixture of Gaussians to model the emission, where the number of mixtures is tuned in {1, . . . , 10}. For the proposed R-HSMM, we use Adam (Kingma & Ba, 2014) to train the K generative RNN and bi-RNN encoder. To make the learning tractable for long sequences, we use back propagation through time (BPTT) with limited budget. We also tune the dimension of hidden vector in RNN, the L2-regularization weights and the stepsize. We implemented with CUDA that parallelized for different RNNs, and conduct experiments on K-20 enabled cluster. We include both the R-HSMM with the exact MAP via dynamic programming (rHSMM-dp) and sequential VAE with forward pass (rHSMM-fw) in experiments. In all tasks, the rHSMM-fw achieves almost the same performance to rHSMM-dp, but 400 times faster, showing the bi-RNN is able to mimic the forward-backward algorithm very well with efficient computation."}, {"heading": "5.1 SEGMENTATION ACCURACY", "text": "Synthetic Experiments We first evaluate the proposed method on two 1D synthetic sequential data sets. The first data set is generated by a HSMM with 3 hidden states, where \u03c0,A,B are designed beforehand. A segment with hidden state z is a sine function \u03bbz sin(\u03c9zx+ 1) + 2, where 1 and 2 are Gaussian random noises. Different hidden states use different scale parameters \u03bbz and frequency parameters \u03c9z . The second data set also has 3 hidden states, where the segment with hidden state z is sampled from a Gaussian process (GP) with kernel function kz(x, y). Different hidden states employ different kernel functions. The specific kernel functions used here are k1(x, y) = exp{\u2212min(| x\u2212y | , |x+ y|)2/10}, k2(x, y) = exp{\u2212(x\u2212 y)2/10} and k3(x, y) = (5\u2212 |x\u2212 y|)I{(5\u2212 |x\u2212 y|) < 5}. For both of the Sine and GP data sets, the duration of a segment is randomly sampled from a distribution defined on {1, ..., 100}, which depends on the hidden states. Thus, the segmentation task corresponds to finding out different functions embedded in the sequences.\nHDP-HSMM 42.74 \u00b1 2.73% 41.90 \u00b1 1.58% 35.46 \u00b1 6.19% 43.59 \u00b1 1.58% 47.56 \u00b1 4.31% 42.58 \u00b1 1.54% CRF-AE 44.87 \u00b1 1.63% 51.43 \u00b1 2.14% 49.26 \u00b1 10.63% 57.62 \u00b1 0.22% 53.16 \u00b1 4.78% 45.73 \u00b1 0.66%\nWe visualize the segmentation results of ground truth and three competitors on Sine and GP data sets in Figure 1a and Figure 1b respectively, and report the numerical results in Table 1. As we can see, R-HSMM provides much better results on even small segments, dramatically outperforms HSMM variants and CRF-AE. Also note that, the sine function depicts short term dependencies, while Gaussian process has long dependency that determined by the kernel bandwidth. This demonstrates the ability of R-HSMM in capturing the long or short term dependencies.\nHuman activity This dataset which is collected by Reyes-Ortiz et al. (2016) consists of signals collected from waist-mounted smartphone with accelerometers and gyroscopes. Each of the volunteers is asked to perform a protocol of activities composed of 12 activities (see Figure 3a for the details). Since the signals within an activity type exhibit high correlation, it is natural for RNN to model this dependency. We use these 61 sequences, where each sequence has length around 3000. Each observation is a 6 dimensional vector, consists of triaxial measures from accelerometers and gyroscopes.\nFigure 3a shows the ground truth and the segmentation results of all methods. Both rHSMM-dp and rHSMM-fw almost perfectly recover the true segmentation. They can also capture the transition activity types, e.g., stand to lie or sit to lie. The HSMM, HDP-HSMM and CRF-AE makes some fragmental but periodical segmentations for walking, caused by lacking the dependency modeling within a segment. The subHSMM also has similar problem, possibly due to the limited ability of HMM generative model.\nDrosophila Here we study the behavior patterns of drosophilas. The data was collected by Kain et al. (2013) with two dyes, two cameras and some optics to track each leg of a spontaneously behaving fruit fly. The dimension of observation in each timestamp is 45, which consists of the raw features and some higher order features. See Figure 3b for the detail of the 11 behavior types. We perform leave-one-sequence-out experiment on 10 sequences of length 10000 each. Figure 3b shows the segmentation results on the prefix of one sequence, while Table 1 gives the mean accuracy on all sequences. Different from the previous experiment, where the human activity signals are relatively\nsmooth, here the signals depict high variance. Different activities exhibit quite different duration and patterns. Also, the activity types changes frequently. The R-HSMM almost captured each changing point of activities with both long and short durations. The corresponding mean accuracy also outperforms the baselines. However, we observed there are some correct segmentations with wrong labels. This happens mostly to the short segments, in which the RNN doesn\u2019t have enough history established for distinguishing similar activity types.\nPhysionet The heart sound records, usually represented graphically by phonocardiogram (PCG), are key resources for pathology classification of patients. We collect data from PhysioNet Challenge 2016 (Springer et al., 2015), where each observation has been labeled with one of the four states, namely Diastole, S1, Systole and S2. We experiment with both the raw signals and the signals after feature extraction. Regarding the raw signals (Heart dataset), we collect 7 1-dimensional sequences of length around 40000. The feature-rich dataset (PN-Full) contains 2750 sequences, where each of them consists of 1500 4-dimensional observations. We do 5-fold cross validation for PN-Full. The visualization of segmentation results are shown in Appendix B.4. As the results shown in Table 1, our algorithm still outperforms the baselines significantly. Also for such long raw signal sequences, the speed advantage of bi-RNN encoder over Viterbi is more significant. Viterbi takes 8min to do one inference, while bi-RNN only takes several seconds. Our framework is also flexible to incorporate prior knowledge, like the regularity of heart state transition into HSMM."}, {"heading": "5.2 RECONSTRUCTION", "text": "In this section, we examine the ability of learned generative model by visualizing the reconstructed signals. Given a sequence x, we use recognition model to get the latent variables z and d, then use learned K generative RNNs to generate signals within each segment. For the ease of visualization, we show the results on 1D signal dataset in Fig. 4a and Fig. 4b.\nFrom Fig. 4 we can see the generative RNN correctly captures different characteristics from signals of different segment labels, such as different frequencies and scales in Sine dataset, or the different variance patterns in GP dataset. This is essential to distinguish between different segments."}, {"heading": "6 CONCLUSION", "text": "We presented the R-HSMM, a generalization of HSMM by incorporating recurrent neural generative model as the emission probability. To eliminate the difficulty caused by such flexible and powerful model in inference, we introduced the bi-RNN as the encoding distribution via the variational autoencoder framework to mimic the forward-backward algorithm. To deal with the difficulty of training VAE containing discrete latent variables, we proposed a novel stochastic distributional penalty method. We justified the modeling power of the proposed R-HSMM via segmentation accuracy and reconstruction visualization. From the comprehensive comparison, the proposed model significantly outperforms the existing models. It should be emphasized that the structured bi-RNN encoder yields similar performance as the exact MAP inference, while being 400 times faster. Future work includes further speeding up of our algorithm, as well as generalizing our learning algorithm to other discrete variational autoencoder."}, {"heading": "ACKNOWLEDGMENTS", "text": "This project was supported in part by NSF IIS-1218749, NIH BIGDATA 1R01GM108341, NSF CAREER IIS-1350983, NSF IIS-1639792 EAGER, ONR N00014-15-1-2340, Nvidia and Intel."}, {"heading": "Appendix", "text": ""}, {"heading": "A OPTIMIZING DYNAMIC PROGRAMMING", "text": ""}, {"heading": "A.1 SQUEEZE THE MEMORY REQUIREMENT", "text": "In this section, we show that the Eq. 13 can be computed in a memory efficient way. Specifically, the dynamic programming procedure can be done with O(|x|K) memory requirement, and caching for precomputed emission probabilities requires O(D2K) memory space.\nUpdate forward variable \u03b1 Note that in Eq. 13, when r > 1, we can update \u03b1t(j, r) deterministically. So it is not necessary to keep the records for r > 1.\nSpecifically, let\u2019s only record \u03b1t(j, 1), and do the updates in a similar way as in Eq. 13. The only difference is that, when constructing the answer, i.e., the last segment solution, we need to do a loop over all possible z and d in order to find the best overall segmentation solution.\nIt is easy to see that the memory consumption is O(|x|K).\nCaching emission probability At each time step t, we compute P (xt+r|xt:t+r\u22121, z = j) for each j \u2208 Z and r \u2208 D. That is to say, we compute all the emission probabilities of observations starting from time t, and within max possible duration D. This can be done by performing feed-forward of K RNNs. After that, storing these results will require O(KD) space. For simplicity, we let etj,r = P (xt+r|xt:t+r\u22121, z = j), where et \u2208 RK\u00d7D. Note that, at a certain time step t, we would require the emission probability of observations P (xt|xt\u2212r+1:t\u22121, z = j) for some j \u2208 Z and r \u2208 D. In this case, the corresponding first observation is xt\u2212r. That is to say, we should keep et\u2212D+1, . . . , et at time step t. This makes the memory consumption goes to O(KD2)"}, {"heading": "A.2 SQUEEZE THE TIME COMPLEXITY", "text": "In Eq. 13, the most expensive part is when r = 1 and t > 1. If we solve this in a naive way, then this step would require O(|x|K2D) for time complexity, which is quite expensive. Here we adopt similar technique as in Yu & Kobayashi (2003). Let \u03b3t(i) = maxr\u2032\u2208D \u03b1t\u22121(i, r\u2032), then we can get\n\u03b1t(j, r) = max i\u2208Z max r\u2032\u2208D\n\u03b1t1(i, r \u2032) +\n1\n1 + \u03bb log(Ai,jBj,1P (xt|z = j)) (17)\n+ \u03bb\n1 + \u03bb logQ\u03c8(zt\u2212r+1 = j, dt\u2212r+1 = r|x)\n= max i\u2208Z\n\u03b3t\u22121(i) + 1\n1 + \u03bb log(Ai,jBj,1P (xt|z = j)) (18)\n+ \u03bb\n1 + \u03bb logQ\u03c8(zt\u2212r+1 = j, dt\u2212r+1 = r|x)\nThis reduces the complexity to be O(|x|K2)."}, {"heading": "B MORE EXPERIMENT RESULTS", "text": ""}, {"heading": "B.1 SYNTHETIC DATASETS", "text": "The reconstructed signals from the original signals are shown in Fig. 5 and Fig. 6 for sine dataset and gaussian Process dataset respectively. We can see the reconstructed signal almost recovered the original signal. The RNN captured the key differences of states, such as the frequency and scale; while in gaussian process dataset, it also recovered the complicated pattern involving long term dependencies.\nWe show the confusion matrix of all methods on synthetic sine and gaussian process dataset in Figure 7 and Figure 8 respectively."}, {"heading": "B.2 HUMAN ACTIVITY", "text": "The confusion matrices of our method and two baseline algorithms are shown in Figure 9.\nIn Figure 10, we also show several other segmentation results on different testing sequences."}, {"heading": "B.3 DROSOPHILA", "text": "The confusion matrices of our method and two baseline algorithms are shown in Figure 11.\nSince each sequence is too long to be clearly shown in one figure, we split the segmentation results of one sequence into four parts, and show them in Figure 12."}, {"heading": "B.4 HEART SOUND RECORDS", "text": "The confusion matrices of our method and two baseline algorithms are shown in Figure 13.\nAlso, we split the segmentation results of one sequence into four parts, and show them in Figure 14."}], "references": [{"title": "Conditional random field autoencoders for unsupervised structured prediction", "author": ["Waleed Ammar", "Chris Dyer", "Noah A Smith"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Ammar et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ammar et al\\.", "year": 2014}, {"title": "Estimating or propagating gradients through stochastic neurons for conditional computation", "author": ["Yoshua Bengio", "Nicholas L\u00e9onard", "Aaron Courville"], "venue": "arXiv preprint arXiv:1308.3432,", "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "Nonlinear Programming", "author": ["D.P. Bertsekas"], "venue": "Athena Scientific,", "citeRegEx": "Bertsekas.,? \\Q1999\\E", "shortCiteRegEx": "Bertsekas.", "year": 1999}, {"title": "Gated recursive neural network for chinese word segmentation", "author": ["Xinchi Chen", "Xipeng Qiu", "Chenxi Zhu", "Xuanjing Huang"], "venue": "In Proceedings of Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Explicit-duration markov switching models", "author": ["Silvia Chiappa"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Chiappa.,? \\Q2014\\E", "shortCiteRegEx": "Chiappa.", "year": 2014}, {"title": "Hierarchical multiscale recurrent neural networks", "author": ["Junyoung Chung", "Sungjin Ahn", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1609.01704,", "citeRegEx": "Chung et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chung et al\\.", "year": 2016}, {"title": "Provable bayesian inference via particle mirror descent", "author": ["Bo Dai", "Niao He", "Hanjun Dai", "Le Song"], "venue": "In Proceedings of the 19th International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Dai et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Dai et al\\.", "year": 2016}, {"title": "Recurrent marked temporal point processes: Embedding event history to vector", "author": ["Nan Du", "Hanjun Dai", "Rakshit Trivedi", "Utkarsh Upadhyay", "Manuel Gomez-Rodriguez", "Le Song"], "venue": null, "citeRegEx": "Du et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Du et al\\.", "year": 2016}, {"title": "Nonparametric bayesian learning of switching linear dynamical systems", "author": ["Emily Fox", "Erik B Sudderth", "Michael I Jordan", "Alan S Willsky"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Fox et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Fox et al\\.", "year": 2009}, {"title": "Linear dynamical neural population models through nonlinear embeddings", "author": ["Yuanjun Gao", "Evan W Archer", "Liam Paninski", "John P Cunningham"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Gao et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Gao et al\\.", "year": 2016}, {"title": "Variational learning for switching state-space models", "author": ["Zoubin Ghahramani", "Geoffrey E Hinton"], "venue": "Neural computation,", "citeRegEx": "Ghahramani and Hinton.,? \\Q2000\\E", "shortCiteRegEx": "Ghahramani and Hinton.", "year": 2000}, {"title": "Muprop: Unbiased backpropagation for stochastic neural networks", "author": ["Shixiang Gu", "Sergey Levine", "Ilya Sutskever", "Andriy Mnih"], "venue": "arXiv preprint arXiv:1511.05176,", "citeRegEx": "Gu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gu et al\\.", "year": 2015}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter and Schmidhuber.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Stochastic variational inference for bayesian time series models", "author": ["Matthew Johnson", "Alan Willsky"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "Johnson and Willsky.,? \\Q2014\\E", "shortCiteRegEx": "Johnson and Willsky.", "year": 2014}, {"title": "Bayesian nonparametric hidden semi-markov models", "author": ["Matthew J Johnson", "Alan S Willsky"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Johnson and Willsky.,? \\Q2013\\E", "shortCiteRegEx": "Johnson and Willsky.", "year": 2013}, {"title": "Structured vaes: Composing probabilistic graphical models and variational autoencoders", "author": ["Matthew J Johnson", "David Duvenaud", "Alexander B Wiltschko", "Sandeep R Datta", "Ryan P Adams"], "venue": "arXiv preprint arXiv:1603.06277,", "citeRegEx": "Johnson et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Johnson et al\\.", "year": 2016}, {"title": "Leg-tracking and automated behavioural classification in drosophila", "author": ["Jamey Kain", "Chris Stokes", "Quentin Gaudry", "Xiangzhi Song", "James Foley", "Rachel Wilson", "Benjamin de Bivort"], "venue": "Nature communications,", "citeRegEx": "Kain et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kain et al\\.", "year": 2013}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma and Ba.,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Auto-encoding variational bayes", "author": ["Diederik P Kingma", "Max Welling"], "venue": "arXiv preprint arXiv:1312.6114,", "citeRegEx": "Kingma and Welling.,? \\Q2013\\E", "shortCiteRegEx": "Kingma and Welling.", "year": 2013}, {"title": "Segmental recurrent neural networks", "author": ["Lingpeng Kong", "Chris Dyer", "Noah A Smith"], "venue": "arXiv preprint arXiv:1511.06018,", "citeRegEx": "Kong et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kong et al\\.", "year": 2015}, {"title": "Deep kalman filters", "author": ["Rahul G Krishnan", "Uri Shalit", "David Sontag"], "venue": "arXiv preprint arXiv:1511.05121,", "citeRegEx": "Krishnan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Krishnan et al\\.", "year": 2015}, {"title": "Recurrent switching linear dynamical systems", "author": ["Scott W Linderman", "Andrew C Miller", "Ryan P Adam", "David M Blei", "Liam Paninski", "Matthew J Johnson"], "venue": "arXiv preprint arXiv:1610.08466,", "citeRegEx": "Linderman et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Linderman et al\\.", "year": 2016}, {"title": "crfchain: Matlab code for chain-structured conditional random fields with categorical features", "author": ["K. Swersky M. Schmidt"], "venue": null, "citeRegEx": "Schmidt.,? \\Q2008\\E", "shortCiteRegEx": "Schmidt.", "year": 2008}, {"title": "Neural variational inference and learning in belief networks", "author": ["Andriy Mnih", "Karol Gregor"], "venue": "arXiv preprint arXiv:1402.0030,", "citeRegEx": "Mnih and Gregor.,? \\Q2014\\E", "shortCiteRegEx": "Mnih and Gregor.", "year": 2014}, {"title": "Variational inference for monte carlo objectives", "author": ["Andriy Mnih", "Danilo J Rezende"], "venue": "arXiv preprint arXiv:1602.06725,", "citeRegEx": "Mnih and Rezende.,? \\Q2016\\E", "shortCiteRegEx": "Mnih and Rezende.", "year": 2016}, {"title": "Algorithms for the assignment and transportation problems", "author": ["J. Munkres"], "venue": "Journal of SIAM,", "citeRegEx": "Munkres.,? \\Q1957\\E", "shortCiteRegEx": "Munkres.", "year": 1957}, {"title": "Hidden semi-markov models (hsmms)", "author": ["Kevin P Murphy"], "venue": null, "citeRegEx": "Murphy.,? \\Q2002\\E", "shortCiteRegEx": "Murphy.", "year": 2002}, {"title": "Machine learning: a probabilistic perspective", "author": ["Kevin P. Murphy"], "venue": null, "citeRegEx": "Murphy.,? \\Q2012\\E", "shortCiteRegEx": "Murphy.", "year": 2012}, {"title": "A tutorial on hidden markov models and selected applications in speech recognition", "author": ["Lawrence R Rabiner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "Rabiner.,? \\Q1989\\E", "shortCiteRegEx": "Rabiner.", "year": 1989}, {"title": "Techniques for learning binary stochastic feedforward neural networks", "author": ["Tapani Raiko", "Mathias Berglund", "Guillaume Alain", "Laurent Dinh"], "venue": "arXiv preprint arXiv:1406.2989,", "citeRegEx": "Raiko et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Raiko et al\\.", "year": 2014}, {"title": "Transition-aware human activity recognition using smartphones", "author": ["Jorge-L Reyes-Ortiz", "Luca Oneto", "Albert Sam\u00e0", "Xavier Parra", "Davide Anguita"], "venue": null, "citeRegEx": "Reyes.Ortiz et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Reyes.Ortiz et al\\.", "year": 2016}, {"title": "Logistic regression-hsmm-based heart sound segmentation", "author": ["David Springer", "Lionel Tarassenko", "Gari Clifford"], "venue": null, "citeRegEx": "Springer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Springer et al\\.", "year": 2015}, {"title": "Sequence to sequence learning with neural networks. In Advances in neural information processing", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": null, "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Learning stochastic feedforward neural networks", "author": ["Yichuan Tang", "Ruslan R Salakhutdinov"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Tang and Salakhutdinov.,? \\Q2013\\E", "shortCiteRegEx": "Tang and Salakhutdinov.", "year": 2013}, {"title": "Bayesian conditionalisation and the principle of minimum information", "author": ["P.M. Williams"], "venue": "British Journal for the Philosophy of Science,", "citeRegEx": "Williams.,? \\Q1980\\E", "shortCiteRegEx": "Williams.", "year": 1980}, {"title": "Hidden semi-markov models", "author": ["Shun-Zheng Yu"], "venue": "Artificial Intelligence,", "citeRegEx": "Yu.,? \\Q2010\\E", "shortCiteRegEx": "Yu.", "year": 2010}, {"title": "An efficient forward-backward algorithm for an explicitduration hidden markov model", "author": ["Shun-Zheng Yu", "Hisashi Kobayashi"], "venue": "Signal Processing Letters, IEEE,", "citeRegEx": "Yu and Kobayashi.,? \\Q2003\\E", "shortCiteRegEx": "Yu and Kobayashi.", "year": 2003}, {"title": "Optimal Information Processing and Bayes\u2019s Theorem", "author": ["Arnold Zellner"], "venue": "The American Statistician,", "citeRegEx": "Zellner.,? \\Q1988\\E", "shortCiteRegEx": "Zellner.", "year": 1988}], "referenceMentions": [{"referenceID": 32, "context": "The supervised sequence segmentation or labeling techniques have been well studied in recent decades (Sutskever et al., 2014; Kong et al., 2015; Chen et al., 2015).", "startOffset": 101, "endOffset": 163}, {"referenceID": 19, "context": "The supervised sequence segmentation or labeling techniques have been well studied in recent decades (Sutskever et al., 2014; Kong et al., 2015; Chen et al., 2015).", "startOffset": 101, "endOffset": 163}, {"referenceID": 3, "context": "The supervised sequence segmentation or labeling techniques have been well studied in recent decades (Sutskever et al., 2014; Kong et al., 2015; Chen et al., 2015).", "startOffset": 101, "endOffset": 163}, {"referenceID": 26, "context": "The Hidden Semi-Markov Model (HSMM) (Murphy, 2002) is a powerful model for such task.", "startOffset": 36, "endOffset": 50}, {"referenceID": 35, "context": "It eliminates the implicit geometric duration distribution assumptions in HMM (Yu, 2010), thus allows the state to transit in a non-Markovian way.", "startOffset": 78, "endOffset": 88}, {"referenceID": 28, "context": "Most of the HSMM variants make strong parametric assumptions on the observation model (Rabiner, 1989; Johnson & Willsky, 2013; Yu, 2010).", "startOffset": 86, "endOffset": 136}, {"referenceID": 35, "context": "Most of the HSMM variants make strong parametric assumptions on the observation model (Rabiner, 1989; Johnson & Willsky, 2013; Yu, 2010).", "startOffset": 86, "endOffset": 136}, {"referenceID": 8, "context": "Some models have been proposed to tackle this problem (Ghahramani & Hinton, 2000; Fox et al., 2009; Linderman et al., 2016), but are limited in linear case.", "startOffset": 54, "endOffset": 123}, {"referenceID": 21, "context": "Some models have been proposed to tackle this problem (Ghahramani & Hinton, 2000; Fox et al., 2009; Linderman et al., 2016), but are limited in linear case.", "startOffset": 54, "endOffset": 123}, {"referenceID": 32, "context": "Since people have justified RNN\u2019s ability in modeling nonlinear and complicated dependencies (Sutskever et al., 2014; Du et al., 2016), we introduce the recurrent neural emission model into HSMM for capturing various dependencies within each segment to address such issue.", "startOffset": 93, "endOffset": 134}, {"referenceID": 7, "context": "Since people have justified RNN\u2019s ability in modeling nonlinear and complicated dependencies (Sutskever et al., 2014; Du et al., 2016), we introduce the recurrent neural emission model into HSMM for capturing various dependencies within each segment to address such issue.", "startOffset": 93, "endOffset": 134}, {"referenceID": 9, "context": "It should be emphasized that due to the discrete nature of the latent variables in our model, the algorithm proposed in Kingma & Welling (2013) and its extension on time-series models (Gao et al., 2016; Krishnan et al., 2015) are not directly applicable.", "startOffset": 184, "endOffset": 225}, {"referenceID": 20, "context": "It should be emphasized that due to the discrete nature of the latent variables in our model, the algorithm proposed in Kingma & Welling (2013) and its extension on time-series models (Gao et al., 2016; Krishnan et al., 2015) are not directly applicable.", "startOffset": 184, "endOffset": 225}, {"referenceID": 1, "context": "There are plenty of work proposed based on stochastic neuron (Tang & Salakhutdinov, 2013; Bengio et al., 2013; Mnih & Gregor, 2014; Raiko et al., 2014; Gu et al., 2015; Chung et al., 2016) to remedy such issue.", "startOffset": 61, "endOffset": 188}, {"referenceID": 29, "context": "There are plenty of work proposed based on stochastic neuron (Tang & Salakhutdinov, 2013; Bengio et al., 2013; Mnih & Gregor, 2014; Raiko et al., 2014; Gu et al., 2015; Chung et al., 2016) to remedy such issue.", "startOffset": 61, "endOffset": 188}, {"referenceID": 11, "context": "There are plenty of work proposed based on stochastic neuron (Tang & Salakhutdinov, 2013; Bengio et al., 2013; Mnih & Gregor, 2014; Raiko et al., 2014; Gu et al., 2015; Chung et al., 2016) to remedy such issue.", "startOffset": 61, "endOffset": 188}, {"referenceID": 5, "context": "There are plenty of work proposed based on stochastic neuron (Tang & Salakhutdinov, 2013; Bengio et al., 2013; Mnih & Gregor, 2014; Raiko et al., 2014; Gu et al., 2015; Chung et al., 2016) to remedy such issue.", "startOffset": 61, "endOffset": 188}, {"referenceID": 28, "context": "In this paper, we focus on one of the variants of HSMM, namely the explicit duration HMM (EDHMM) (Rabiner, 1989), and use Decreasing Count Variables (Chiappa, 2014) for the notation.", "startOffset": 97, "endOffset": 112}, {"referenceID": 4, "context": "In this paper, we focus on one of the variants of HSMM, namely the explicit duration HMM (EDHMM) (Rabiner, 1989), and use Decreasing Count Variables (Chiappa, 2014) for the notation.", "startOffset": 149, "endOffset": 164}, {"referenceID": 34, "context": "So instead, we treat the Bayesian inference from optimization perspective, and obtain the posterior by maximizing the negative Helmholtz variational free energy (Williams, 1980; Zellner, 1988; Dai et al., 2016), max Q(z,d|x)\u2208P LQ(x) := EQ(z,d|x) [logP\u03b8(x, z,d)\u2212 logQ(z,d|x)] , (6) over the space of all valid densities P .", "startOffset": 161, "endOffset": 210}, {"referenceID": 37, "context": "So instead, we treat the Bayesian inference from optimization perspective, and obtain the posterior by maximizing the negative Helmholtz variational free energy (Williams, 1980; Zellner, 1988; Dai et al., 2016), max Q(z,d|x)\u2208P LQ(x) := EQ(z,d|x) [logP\u03b8(x, z,d)\u2212 logQ(z,d|x)] , (6) over the space of all valid densities P .", "startOffset": 161, "endOffset": 210}, {"referenceID": 6, "context": "So instead, we treat the Bayesian inference from optimization perspective, and obtain the posterior by maximizing the negative Helmholtz variational free energy (Williams, 1980; Zellner, 1988; Dai et al., 2016), max Q(z,d|x)\u2208P LQ(x) := EQ(z,d|x) [logP\u03b8(x, z,d)\u2212 logQ(z,d|x)] , (6) over the space of all valid densities P .", "startOffset": 161, "endOffset": 210}, {"referenceID": 1, "context": "n=1 L(\u03b8, \u03c8;x) (9) It should be emphasized that due to the discrete nature of latent variables in our model, the algorithm proposed in Kingma & Welling (2013) is not directly applicable, and its extension with stochastic neuron reparametrization (Bengio et al., 2013; Raiko et al., 2014; Gu et al., 2015; Chung et al., 2016) cannot provide satisfied results for our model according to our experiments.", "startOffset": 245, "endOffset": 323}, {"referenceID": 29, "context": "n=1 L(\u03b8, \u03c8;x) (9) It should be emphasized that due to the discrete nature of latent variables in our model, the algorithm proposed in Kingma & Welling (2013) is not directly applicable, and its extension with stochastic neuron reparametrization (Bengio et al., 2013; Raiko et al., 2014; Gu et al., 2015; Chung et al., 2016) cannot provide satisfied results for our model according to our experiments.", "startOffset": 245, "endOffset": 323}, {"referenceID": 11, "context": "n=1 L(\u03b8, \u03c8;x) (9) It should be emphasized that due to the discrete nature of latent variables in our model, the algorithm proposed in Kingma & Welling (2013) is not directly applicable, and its extension with stochastic neuron reparametrization (Bengio et al., 2013; Raiko et al., 2014; Gu et al., 2015; Chung et al., 2016) cannot provide satisfied results for our model according to our experiments.", "startOffset": 245, "endOffset": 323}, {"referenceID": 5, "context": "n=1 L(\u03b8, \u03c8;x) (9) It should be emphasized that due to the discrete nature of latent variables in our model, the algorithm proposed in Kingma & Welling (2013) is not directly applicable, and its extension with stochastic neuron reparametrization (Bengio et al., 2013; Raiko et al., 2014; Gu et al., 2015; Chung et al., 2016) cannot provide satisfied results for our model according to our experiments.", "startOffset": 245, "endOffset": 323}, {"referenceID": 29, "context": "In our algorithm, the samples of latent variable come naturally from the auxiliary distributions (which are integrated with penalty method), rather than the derivation from lower bound of objective (Tang & Salakhutdinov, 2013; Raiko et al., 2014; Mnih & Rezende, 2016).", "startOffset": 198, "endOffset": 268}, {"referenceID": 0, "context": "We also compare with the CRF autoencoder (CRF-AE) (Ammar et al., 2014), which uses markovian CRF as recognition model and conditional i.", "startOffset": 50, "endOffset": 70}, {"referenceID": 25, "context": "Since the labels are unknown during training, we use KM algorithm (Munkres, 1957) to find the best mapping between predicted labels and ground-truth labels.", "startOffset": 66, "endOffset": 81}, {"referenceID": 31, "context": "We collect data from PhysioNet Challenge 2016 (Springer et al., 2015), where each observation has been labeled with one of the four states, namely Diastole, S1, Systole and S2.", "startOffset": 46, "endOffset": 69}], "year": 2017, "abstractText": "Segmentation and labeling of high dimensional time series data has wide applications in behavior understanding and medical diagnosis. Due to the difficulty of obtaining a large amount the label information, realizing this objective in an unsupervised way is highly desirable. Hidden Semi-Markov Model (HSMM) is a classical tool for this problem. However, existing HSMM and its variants typically make strong generative assumptions on the observations within each segment, thus their ability to capture the nonlinear and complex dynamics within each segment is limited. To address this limitation, we propose to incorporate the Recurrent Neural Network (RNN) as the generative process of each segment, resulting the Recurrent HSMM (R-HSMM). To accelerate the inference while preserving accuracy, we designed a structure encoding function to mimic the exact inference. By generalizing the penalty method to distribution space, we are able to train the model and the encoding function simultaneously. We also demonstrate that the R-HSMM significantly outperforms the previous state-of-the-art on both the synthetic and real-world datasets.", "creator": "LaTeX with hyperref package"}, "id": "ICLR_2017_119"}