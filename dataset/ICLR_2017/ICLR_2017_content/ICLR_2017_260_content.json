{"name": "ICLR_2017_260.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Masatosi Uehara", "Issei Sato", "Masahiro Suzuki", "Kotaro Nakayama", "Yutaka Matsuo"], "emails": ["uehara-masatoshi136@g.ecc.u-tokyo.ac.jp", "sato@k.u-tokyo.ac.jp", "matsuo}@weblab.t.u-tokyo.ac.jp"], "sections": [{"heading": "1 INTRODUCTION", "text": "There have been many recent studies about deep generative models. Generative adversarial networks (GAN) (Goodfellow et al., 2014) is the variant of these models that has attracted the most attention. It has been demonstrated that generating vivid, realistic images from a uniform distribution is possible (Radford et al., 2015; Denton et al., 2015). GANs are formulated as a two-player minimax game. However, the objective function derived in the original motivation is modified to obtain stronger gradients when learning the generator. GANs have been applied in various studies; however, few studies have attempted to reveal their mechanism (Goodfellow, 2014; Huszar, 2015).\nRecently, f-GAN, which minimizes the variational estimate of f-divergence, has been proposed (Nowozin et al., 2016). The original GAN is a special case of f-GAN.\nIn this study, we propose a novel algorithm inspired by GANs from the perspective of density ratio estimation based on the Bregman divergence, which we refer to as b-GAN. The proposed algorithm iterates density ratio estimation and f-divergence minimization based on the obtained density ratio. This study make the following two primary contributions:\n1. We derive a novel unified algorithm that employs well-studied results regarding density ratio estimation (Kanamori et al., 2012; Sugiyama et al., 2012; Menon & Ong, 2016).\n2. In the original GANs, the value function derived from the two-player minimax game does not match the objective function that is actually used for learning the generative model. In our algorithm, the objective function derived from the original motivation is not changed for learning the generative model.\nThe remainder of this study is organized as follows. Section 2 describes related work. Section 3 introduces and analyzes the proposed algorithm in detail. Section 4 explains the proposed algorithm for specific cases. Section 5 reports experimental results. Section 6 summarizes our findings and discusses future work."}, {"heading": "2 RELATED WORK", "text": "In this study, we denote an input space as X and a hidden space as Z. Let p(x) be the distribution of training data over X and q(x) be the generated distribution over X .\nGANs (Goodfellow et al., 2014) were developed based on a game theory scenario, where two model, i.e., a generator network and a discriminator network, are simultaneously trained. The generator network G\u03b8G(z) produces samples with a probability density function of q(x; \u03b8G). The discriminator network T\u03b8D (x) attempts to distinguish the samples from the training samples and that from the generator. GANs are described as a zero-sum game, where the function v(G,T ) determines the pay-off of the discriminator and the function \u2212v(G,T ) determines the pay-off of the generator. The discriminator T\u03b8D (x) and generator G\u03b8G(z) play the following two-player minimax game min\u03b8G max\u03b8D v(G,T ), where v(G,T ) can be expressed as follows:\nEx\u223cp(x)[log T\u03b8D (x)] + Ex\u223cq(x;\u03b8G)[log(1\u2212 T\u03b8D (x))].\nThe discriminator and generator are iteratively trained by turns. For fixed G, the optimal T(x) is p(x)p(x)+q(x) . This suggests that training the discriminator can be formulated as a density ratio estimation. The generator is trained to minimize v(G,T ) adversarially. In fact, maximizing Ex\u223cq(x;\u03b8G)[log T\u03b8D (x)] is preferable instead of minimizing Ex\u223cq(x;\u03b8G)[log(1\u2212 T\u03b8D (x))]. Although this does not match the theoretical motivation, this heuristic is the key to successful learning. We analyze this heuristic in Section 3.4.\nf-GAN (Nowozin et al., 2016) generalizes the GAN concept. First, we introduce f-divergence (Ali & Silvey, 1966). The f-divergence measures the difference between two probability distributions p and q and is defined as\nDf (p||q) = \u222b q(x)f ( p(x)\nq(x)\n) dx = \u222b q(x)f (r(x)) dx, (1)\nwhere f(x) is a convex function satisfying f(1) = 0. Note that in the space of positive measures, i.e., not satisfying normalized conditions, f-divergence must satisfy f \u2032(1) = 0 due to its invariance (Amari & Cichoki, 2010).\nThe function v(G,T ) of f-GAN is given by\nEx\u223cp(x)[T\u03b8D (x)]\u2212 Ex\u223cq(x;\u03b8G)[f \u2217 (T\u03b8D (x))], (2)\nwhere f\u2217 is a Fenchel conjugate of f (Nguyen et al., 2010). In Eq. 2, v(G,T ) comes from,\n\u222b q(x)f ( p(x)\nq(x)\n) dx = sup\nT Ex\u223cp[T (x)]\u2212 Ex\u223cq[f\u2217(T (x))]. (3)\nFollowing GANs, \u03b8D is trained to maximize Eq. 2 in order to estimate the f-divergence. In contrast, \u03b8G is trained to adversarially minimize Eq. 2 to minimize the f-divergence estimate. However, as in GANs, maximizing Ex\u223cq[T (x)] is used rather than minimizing Ex\u223cq[\u2212f\u2217(T (x))]. The latter optimization is theoretically valid in their formulation; however, they used the former heuristically. Similar to GANs, f-GAN also formulates the training discriminator as a density ratio estimation. For a fixed G, the optimal T (x) is f \u2032(pq ), where f \u2032 denotes the first-order derivative of f . When f(x) is\nx log x\u2212 (x+ 1) log(1 +x), f-GANs are equivalent to GANs. Table 1 summarizes GAN and f-GAN. We denote the step for updating \u03b8D as D-step and the step for updating \u03b8G as G-step."}, {"heading": "3 METHOD", "text": "As described in Section 2, training the discriminators in the D-step of GANs and f-GANs is regarded as density ratio estimation. In this section, we further extend this idea. We first review the density ratio estimation method based on the Bregman divergence. Then, we explain and analyze a novel proposed b-GAN algorithm. See appendix E for recent research related to density ratio estimation."}, {"heading": "3.1 DENSITY RATIO MATCHING UNDER THE BREGMAN DIVERGENCE", "text": "There have been many studies on direct density ratio estimation, where a density ratio model is fitted to a true density ratio model under the Bregman divergence (Sugiyama et al., 2012). We briefly review this method.\nAssume there are two distributions p(x) and q(x). Our aim is to directly estimate the true density ratio r(x) = p(x)q(x) without estimating p(x) and q(x) independently . Let r\u03b8(x) be a density ratio model. The integration of the Bregman divergence Bf [r(x)\u2016r\u03b8(x)] between the density ratio model and the true density ratio with respect to measure q(x)dx is\nBDf (r||r\u03b8) = \u222b Bf [r(x)\u2016r\u03b8(x)]q(x)dx\n= \u222b (f(r(x))\u2212 f (r\u03b8(x))\u2212 f \u2032 (r\u03b8(x)) (r(x)\u2212 r\u03b8(x))) q(x)dx. (4)\nWe define the terms related to r\u03b8 in BDf (r||r\u03b8) as\nBRf (r\u03b8) = \u222b (f \u2032(r\u03b8(x))r\u03b8(x)\u2212 f(r\u03b8(x))) q(x)dx\u2212 \u222b f \u2032 (r\u03b8(x)) p(x)dx (5)\n= \u222b f \u2032(r\u03b8(x)) (r\u03b8(x)q(x)\u2212 p(x)) dx\u2212Df (qr\u03b8\u2016q). (6)\nThus, estimating the density ratio problem turns out to be the minimization of Eq. 5 with respect to \u03b8."}, {"heading": "3.2 MOTIVATION", "text": "In this section, we introduce important propositions required to derive b-GAN. Proofs of propositions are given in Appendix C. The following proposition suggests that the supremum of the negative of Eq. 5 is equal to the f-divergence between p(x) and q(x).\nProp 3.1. The following equation holds:\nEq\n[ f ( p(x)\nq(x)\n)] = sup\nr\u03b8\nEx\u223cp[f \u2032 (r\u03b8(x))]\u2212 Ex\u223cq[(f \u2032(r\u03b8(x))r\u03b8(x)\u2212 f(r\u03b8(x)))]. (7)\nThe right side of Eq. 7 reaches the supremum when r\u03b8(x) = r(x) is satisfied.\nIt has been shown that the supremum of negative of Eq. 5 is equivalent to the supremum of Eq. 2. Interestingly, the negative of Eq. 5 has a dual relation with the objective function of f-GAN, i.e., Eq. 2.\nProp 3.2. Introducing dual coordinates T\u03b8D = f \u2032(r\u03b8)(Amari & Cichoki, 2010) yields the right side of Eq. 5 from Eq. 2.\nProp 3.2 shows that the D-step of f-GAN can be regarded as the density ratio estimation because Eq. 5 expresses the density ratio estimation and Eq. 2 is a value function of f-GAN."}, {"heading": "3.3 B-GAN", "text": "Our objective is to minimize the f-divergence between the distribution of the training data p(x) and the generated distribution q(x). We introduce two functions constructed using neural networks: r\u03b8D (x) : X \u2192 R parameterized by \u03b8D, and G\u03b8G(z) : Z \u2192 X parameterized by \u03b8G. Measure q(x; \u03b8G)dx is a probability measure induced from the uniform distribution by G\u03b8G(z). In this case, r\u03b8D (x) is regarded as a density ratio estimation network and G\u03b8G(z) is regarded as a generator network for minimizing the f-divergence between p(x) and q(x).\nMotivated by Section 3.2, we construct a b-GAN using the following two steps.\n1. Update \u03b8D to estimate the density ratio between p(x) and q(x; \u03b8G). To achieve this, we minimize Eq. 5 with respect to r\u03b8(x). In this step, the density ratio model r\u03b8(x) in Eq. 5 can be considered as r\u03b8D (x) in this step.\n2. Update \u03b8G to minimize the f-divergence Df (p||q) between p(x) and q(x; \u03b8G) using the obtained density-ratio. We are able to suppose that q(x; \u03b8G)r\u03b8(x) is close to p(x). Instead of Df (p||q), we update \u03b8G to minimize the empirical approximation of Df (qr\u03b8||q).\nThe b-GAN algorithm is summarized in Algorithm 1, where B is the batch size. In this study, a single-step gradient method (Goodfellow et al., 2014; Nowozin et al., 2016) is adopted.\nAlgorithm 1: b-GAN for number of training iterations do\nsample X\u0302 = {x1, ..., xB} from p(x) and Z\u0302 = {z1, ..., zB} from an uniform distribution. D-step: Update \u03b8D:\n\u03b8t+1D = \u03b8 t D \u2212\u2207\u03b8D\n( 1\nB B\u2211 i=1 f \u2032 ( r\u03b8D (G(zi)) ) r\u03b8D (G(zi))\u2212 f ( r\u03b8D (G(zi)) ) \u2212 f \u2032 ( r\u03b8D (xi)\n)) .\nG-step: Update \u03b8G:\n\u03b8t+1G = \u03b8 t G \u2212\u2207\u03b8G\n( 1\nB B\u2211 i=1 f ( r(G\u03b8G(zi))\n)) .\nend for\nIn the D-step, the proposed algorithm estimates pq toward any divergence; thus, it differs slightly from the D-step of f-GAN because the estimated values, i.e., f \u2032(pq ), are dependent on the divergences. We also introduce an f-GAN-like update as follows. As mentioned in Section 2, we have two options in the G step.\n1. D-step: minimize Ex\u223cp(x)[\u2212f \u2032(r\u03b8D (x))] +Ex\u223cq(x)[f \u2032(r\u03b8D (x))r\u03b8D (x)\u2212 f(r\u03b8D (x))] w.r.t \u03b8D.\n2. G-step: minimize Ex\u223cq(x;\u03b8G)[\u2212f \u2032(r(x))] or Ex\u223cq(x;\u03b8G)[\u2212f \u2032(r(x))r(x) + f(r(x))] w.r.t \u03b8G."}, {"heading": "3.4 ANALYSIS", "text": "Following Goodfellow et al. [2014], we explain the validity of the G-step and D-step. We then explain the meaning of b-GAN. Finally, we analyze differences between b-GAN and f-GAN.\nThe density ratio is estimated in the D-step. The estimator of r(x) is an M-estimator and is asymptotically consistent under the proper normal conditions (Appendix E.1).\nIn the G-step, we update the generator as minimizing Df (p||q) by replacing p(x) with r\u03b8(x)q(x). We assume that q(x; \u03b8G) is equivalent to p(x) when \u03b8G = \u03b8\u2217, q(x; \u03b8G) is identifiable, and the optimal r(x) is obtained in the D-step. By our assumption, the acquired value in the G-step is \u03b8\u0302, which minimizes the empirical approximation of Df (r(x)q(x; \u03b8G)\u2016q(x; \u03b8G)) = Ex\u223cq(x;\u03b8G)[r(x)].\nWhen \u03b8G is equal to \u03b8\u2217, this equation is equal to 0. The estimator \u03b8\u0302 can be considered as a kind of Z-estimator.\nUsually, we cannot perform only a G-step because we do not know the form of p(x) and q(x). In b-GAN, Df (p||q) can be minimized by estimating the density ratio r(x) without estimating the densities directly.\nIn fact, the r(x) obtained at each iteration is different and not optimal because we adopt a single-step gradient method (Nowozin et al., 2016). Thus, b-GAN dynamically updates the generator to minimize the f-divergence between p(x) and q(x). As mentioned previously, f(x) must satisfy f \u2032(1) = 0 in this case because we cannot guarantee that r\u03b8(x)q(x) is normalized.\nSimilar to GANs, the D-step and G-step work adversarially. In the D-step, r\u03b8(x) is updated to fit the ratio between p(x) and q(x). In the G-step, q(x) changes, which means r\u03b8(x) becomes inaccurate in terms of the density ratio estimator. Next, r\u03b8(x) is updated in the D-step so that it fits the density ratio of p(x) and the new q(x). This learning situation is derived from Eq. 6 , which shows that \u03b8D is updated to increase Df (qr\u03b8\u2016q) in the D-step. In contrast, \u03b8G is updated to decrease Df (qr\u03b8\u2016q) in the G-step.\nIn Section 3.3, we also introduced a f-GAN-like update. Three choices can be considered for the G-step:\n(1)Ex\u223cq(x:\u03b8G)[f(r(x))], (2)Ex\u223cq(x;\u03b8G)[\u2212f \u2032(r(x))], (3)Ex\u223cq(x;\u03b8G)[\u2212f \u2032(r(x))r(x) + f(r(x))].\nNote that f is a convex function, f(1) = 0, and f \u2032(1) = 0. It is noted in (Nowozin et al., 2016) that case (2) works better than case (3) in practice. We also confirm this. The complete reason for this is unclear. However, we can find a partial reason by differentiating objective functions with respect to r. The derivatives of the objective functions are\n(1)f \u2032(r), (2)\u2212 f \u2032\u2032(r), (3)\u2212 rf \u2032\u2032(r).\nAll signs are negative when r(x) is less than 1. Usually, when x is sampled from q(x), r(x) is less than 1. Therefore, we speculate that r(x) is less than 1 during most of the learning process when x is sampled from\nq(x). When r(x) is small, the derivative is also small in (3) because the term r(x) is multiplied. Therefore, the derivative tends to be small in (3). The mechanism pulling r(x) to 1 does not work when r(x) is small. Thus, the case of (3) does not work well. A similar argument was proposed by Goodfellow et al. (2014) and Nowozin et al. (2016).\nIn our experimental case of (1) and (2) work properly (Section 5). The reason case (2) works is that function\u2212f \u2032(r) behaves like an f-divergence and the derivative is large when r(x) is small. However, we cannot guarantee that \u2212f \u2032(r) satisfies the conditions of f-divergence between positive measures, i.e,\u2212f \u2032(r) is a convex function and\u2212f \u2032\u2032(1) = 0. If the derivatives in case (2) are negative when r(x) is greater than 1, there is a possibility that the mechanism pulling r(x) to 1 does not occur. In contrast, in case (1), when r(x) is greater than 1, the derivatives are positive, therefore, the mechanism pulling r(x) to 1 occurs. This prevents generators from emitting the same points. We can expect the same effects as -minibatch discrimination- (Salimans et al., 2016).\nThroughout the analysis, we can easily extend the algorithm of b-GAN by using different divergences in the G-step and D-step. The original GAN can be regarded as one of such algorithms."}, {"heading": "4 ALGORITHMS FOR SPECIFIC CASES", "text": "We adopt \u03b1-divergence in the positive measure space as the f-divergence (Amari & Cichoki, 2010). Here, we explain specific algorithms when f is \u03b1-divergence. Then, we explain some heuristics used in b-GAN.\n4.1 ALGORITHMS WITH \u03b1-DIVERGENCE\nIn \u03b1-divergence, f(r) in Eq. 1 is\nf\u03b1(r) =  4 1\u2212\u03b12 (1\u2212 r 1+\u03b1 2 ) + 21\u2212\u03b1 (r \u2212 1) (\u03b1 6= \u00b11)\nr log r \u2212 r + 1 (\u03b1 = 1) \u2212 log r + r \u2212 1 (\u03b1 = \u22121).\n(8)\nThe objective function derived from \u03b1-divergence is summarized as follows."}, {"heading": "4.2 HEURISTICS", "text": "We describe some heuristic methods that work for our experiments. The heuristics introduced here are justified theoretically in Appendix C.\nIn the initial learning process, empirical distribution p and generated distribution q are completely different. Therefore, the estimated density ratio r(x) = p(x)q(x) is enormous when x is taken from p and tiny when x is taken from q. It seems that the learning does not succeed in this case. In fact, in our setting, when the final activation function of r\u03b8D (x) is taken from functions in the range (0,\u221e), b-GAN does not properly work. Therefore, we use a scaled sigmoid function such as a two-times sigmoid function. A similar idea has also been used in (Cortes et al., 2010).\nAs mentioned, density ratio p(x)q(x) is extremely sensitive. To avoid this problem, in the D-step of the KL-divergence, we also conducted experiments wherein we estimated p\u03b1p+(1\u2212\u03b1)q (where \u03b1 is small.) rather than p(x)q(x) . The same idea is introduced in the covariate shift situation (Sugiyama et al., 2013). A similar idea has also been used for GAN learning (Salimans et al., 2016) and class probability estimation (Reid & Williamson, 2010)."}, {"heading": "5 EXPERIMENTS", "text": "We conducted experiments to establish that the proposed algorithm works properly and can successfully generate natural images. The proposed algorithm is based on density ratio estimation; therefore, knowledge regarding the density ratio estimation can be utilized. In the experiments, using the Pearson divergence and estimating the relative density ratio is shown to be useful for stable learning. We also empirically confirm our statement in Section 3.4, i.e., f-divergence is increased when learning \u03b8D and decreased when learning \u03b8G."}, {"heading": "5.1 SETTINGS", "text": "We applied the proposed algorithm to the CIFAR-10 data set (Krizhevsky, 2009) and Celeb A data set (Liu et al., 2015) because they are often used in GAN research (Salimans et al., 2016; Goodfellow et al., 2014). The images size are 32\u00d7 32 pixels. All results in this section are analyzed based on the results of the CIFAR-10 data set. The results for the Celeb A data set are presented in Appendix B. Our network architecture is nearly equivalent to that of previous study (Radford et al., 2015) (refer to the appendix A,B for details). Note that unless stated otherwise, the last layer function of r\u03b8D (x) is a sigmoid function multiplied by two. We used the TensorFlow for automatic differentiation (Abadi et al., 2015). For stochastic optimization, Adam was adopted (Kingma & Ba, 2014)."}, {"heading": "5.2 RESULTS", "text": "Figure 2 shows the density ratio estimate r\u03b8D (x) and loss values of the generators. For each divergence, we conducted four experiments with 40,000 epochs, where the initial learning rate value was fixed (5 \u00d7 10\u22125) with the exception of reversed KL divergence. These results show that the b-GANs using Pearson divergence are stable because the learning did not stop. The same results have been reported in the research into density ratio estimation (Yamada et al., 2011). In contrast, b-GANs using the KL divergence are unstable. In fact, the learning stopped between the 20,000th and 37,000th epoch when the learning rate was not as small. When we use a heuristic method, i.e.,\nestimating the relative density ratio as described in Section 4.2, this problem is solved. For reversed KL divergence, the learning stopped too soon if the initial learning rate value was 5\u00d7 10\u22125. If the learning rate was 1\u00d7 10\u22126, the learning did not stop; however, it was still unstable. In Figure 2, the last layer activation function of the b-GANs is a twofold sigmoid function. In Figure 3, we use a sigmoid function multiplied by five. The results indicate that the estimated density ratio values approach one. We also confirm that the proposed algorithm works with sigmoid functions at other scales.\nFigure 4 shows the estimated f-divergence Df (qr\u03b8||q) before the G-step subtracted by Df (qr\u03b8||q) after the G-step. Most of the values are greater than zero, which suggests f-divergence decreases at every G-step iteration. This observation is consistent with our analysis in Section 3.4.\nNote that learning is successful with an f-GAN-like update when minimizing Eq[\u2212f \u2032(r)]. However, the learning f-GAN-like update when minimizing Eq[f(r) \u2212 rf \u2032(r)] did not work well for our network architecture and data set."}, {"heading": "6 CONCLUSIONS AND FUTURE WORK", "text": "We have proposed a novel unified algorithm to learn a deep generative model from a density ratio estimation perspective. Our algorithm provides the experimental insights that Pearson divergence and estimating relative density ratio are useful to improve the stability of GAN learning. Other insights regarding density ratio estimation would also be also useful. GANs are sensitive to data sets, the form of the network and hyper-parameters. Therefore, providing methods to improve GAN learning is meaningful.\nRelated research to our study that focuses on linking density ratio and a GAN, has been performed by explaining specific algorithms independently (Mohamed & Lakshminarayanan, 2016). In contrast, our framework is more unified.\nIn future, the following things should be considered.\n\u2022 What is the optimal divergence? In research regarding density ratio estimation, the Pearson divergence (\u03b1 = 3) is considered robust (Nam & Sugiyama, 2015). We empirically and theoretically confirmed the same property when learning deep generative models. It is also reported that using KL-divergence and reversed KL-divergence is not robust as scoring rules (Dawid et al., 2015). For generating realistic images, the reversed KL divergence (\u03b1 = \u22121) is preferred because it is mode seeking (Huszar, 2015). However, if \u03b1 is small, the density ratio estimation becomes inaccurate. For a robust density ratio, using power divergence has also been proposed (Sugiyama et al., 2012). The determination of the optimal divergence is a persistent problem (Appendix E).\n\u2022 What should be estimates in D-step? In the D-step of b-GAN, r(x) is estimated. However, in the original GAN, r(x)/(1 + r(x)) is estimated. As unnormalized models, the latter is more robust than estimating r(x) (Pihlaja et al., 2010) (Appendix E.7). \u2022 We can consider algorithms that use different divergences in the G-step and D-step. In that\ncase, choice of the divergences are more diverse. Original GANs are described in such algorithms as mentioned in Section 3.5. \u2022 We can consider algorithms that use multiple divergences. This may improve the stability of\nlearning. \u2022 When sampling from q(x), if the objective is sampling from real data p(x), r(x) should be\nmultiplied. Hence, the density ratio is also useful when using samples from q(x). How to use samples obtained from generators meaningfully is an remaining important problem."}, {"heading": "ACKNOWLEDGEMENTS", "text": "The authors would like to thank Masanori Misono for technical assistance with the experiments. We are grateful to Masashi Sugiyama, Makoto Yamada, and the members of the Preferred Networks team."}, {"heading": "A CIFAR-10 DATASET", "text": "Figure 5 shows samples generated randomly using b-GANs. These results indicate that b-GANs can create natural images successfully. We did not conduct a Parzen window density estimation for the evaluations because of Theis et al., [2016].\nHere, we describe the network architecture of r\u03b8D (x) and G\u03b8G(z) used in the b-GAN. BN is the batch normalization layer (Sergey & Christian, 2015).\nA.1 r\u03b8D (x)\nx\u2192 Conv(3, 64)\u2192 lRelu\u2192 Conv(64, 256)\u2192 BN\u2192 lRelu\u2192 Conv(256, 512)\u2192 BN\u2192 lRelu\u2192 Reshape(4\u00d7 4\u00d7 512)\u2192 Linear(4\u00d7 4\u00d7 512, 1)\u2192 2\u00d7 Sigmoid\nA.2 G\u03b8G(z)\nz\u2192 Linear(100,4\u00d7 4\u00d7 512)\u2192 BN\u2192 Relu\u2192 Reshape(4, 4, 512)\u2192 Conv(512, 256)\u2192 BN\u2192 Relu\u2192 Conv(256, 64)\u2192 BN\u2192 Relu\u2192 Conv(64, 3)\u2192 tanh"}, {"heading": "B CELEB A DATASET", "text": "We also applied our algorithm to the Celeb A data set. The images are resized and cropped to 64\u00d7 64 pixcels. Figures 6 and 7 show samples randomly generated using b-GANs. The Network architecture is as follows.\nB.1 r\u03b8D (x)\nx\u2192 Conv(3, 64)\u2192 lRelu\u2192 Conv(64, 128)\u2192 BN\u2192 lRelu\u2192 Conv(128, 256)\u2192 BN\u2192 lRelu\u2192 Conv(256, 512)\u2192 BN\u2192 lRelu\u2192 Reshape(4\u00d7 4\u00d7 512)\u2192 Linear(4\u00d7 4\u00d7 512, 1)\u2192 2\u00d7Sigmoid\nB.2 G\u03b8G(z)\nz\u2192 Linear(64, 4 \u00d7 4 \u00d7 512)\u2192 BN\u2192 Relu\u2192 Reshape(4, 4, 512)\u2192 Conv(512, 256)\u2192 BN\u2192 Relu\u2192 Conv(256, 128)\u2192 BN\u2192 Relu\u2192 Conv(128, 64)\u2192 BN\u2192 Relu\u2192 Conv(64, 3)\u2192 tanh"}, {"heading": "C PROOF OF PROPOSITIONS IN SECTION 3", "text": ""}, {"heading": "C.1 PROOF OF PROP 3.1", "text": "From Eq. 4, the following equation holds,\nEx\u223cp [f \u2032 (r\u03b8(x))]\u2212 Ex\u223cq[(f \u2032(r\u03b8(x))r\u03b8(x)\u2212 f(r\u03b8(x)))] = \u2212BDf (r||r\u03b8) + Eq [ f ( p(x)\nq(x)\n)] . (9)\nUsing BDf (r||r\u03b8) \u2265 0 yields Eq. 7. We have BDf (r||r\u03b8) = 0 when r is equal to r\u03b8. Thus, the equality holds if and only if r is equal to r\u03b8."}, {"heading": "C.2 PROOF OF PROP3.2", "text": "r.h.s of Eq.2 = Ex\u223cp(x)[f \u2032(r\u03b8(x))]\u2212 Ex\u223cq(x)[f\u2217 (f \u2032(r\u03b8(x)))] (10)\n= Ex\u223cp(x)[f \u2032(r\u03b8(x))]\u2212 Ex\u223cq(x)[f(r\u03b8(x))r\u03b8(x)\u2212 f(r\u03b8(x))] = Ex\u223cp(x)[f \u2032 (r\u03b8(x))]\u2212 Ex\u223cq(x)[(f \u2032(r\u03b8(x))r\u03b8(x)\u2212 f(r\u03b8(x)))]\n= the negative of Eq. 5 In the derivation, we have used the following equation f\u2217 ( f \u2032(r\u03b8(x)) ) = f(r\u03b8(x))r\u03b8(x)\u2212 f(r\u03b8(x)) ."}, {"heading": "D EXPLANATION OF HEURISTICS USING RADEMACHER COMPLEXITY", "text": "Here, we justify three points using Rademacher complexity. All techniques used are described in the literature (Mohri et al., 2012).\n\u2022 Pearson divergence is preferable to KL divergence in density ratio estimation.\n\u2022 Relative density ratio is useful (introduced in Sec 4.2).\n\u2022 The meaning of bounding the last output functions of discriminators (introduced in Sec 4.2).\nOur objective is estimating r(x) = p(x)q(x) . We define hypothesis sets as H. In Section 3.4, we assume H as parametric models for simplicity. In this section, we do not restrict H to parametric models. We define r0 and rs as\nr0 = argminh\u2208HBRf (h)\nrs = argminh\u2208HB\u0302Rf (h),\nwhere B\u0302R is an empirical approximation of BR. Note that BRf (h) reaches minimum values if and only if r = h holds. We want to analyze BRf (rs)\u2212BRf (r). The regret, i.e., BRf (rs)\u2212BRf (r) can be bounded as follows:\nBRf (rs)\u2212BRf (r) = BRf (rs)\u2212BRf (r0) +BRf (r0)\u2212BRf (r) \u2264 2 sup\nh\u2208H |BRf (h)\u2212 B\u0302Rf (h)|+BRf (r0)\u2212BRf (r). (11)\nThe first term of Eq. 11 is bounded by uniform law of large numbers. To do that, assume that all elements in H are bounded by constant C. First, we consider the case when f is the Pearson divergence. In that case, BRf (h) is\nEx\u223cp(x)[0.5h(x) 2]\u2212 Ex\u223cq(x)[h(x)]. (12)\nWe denote the Rademacher complexity of H as Rm,q when x is sampled from q(x) and the sample size is m. The first term of Eq. 12 is upper bounded by Talagrand\u2019s lemma. For any \u03b4 with probability as least 1\u2212 \u03b4, we have\nsup h\u2208H |Ex\u223cp(x)[0.5h(x)2]\u2212\n1\nm\n\u2211 0.5h(xi) 2| \u2264 CRm,p(H) + 0.5C2 \u221a\nlog 1\u03b4 2m , (13)\nwhere samples are taken from p(x) independently. the fact that 0.5h(x)2 is C-Lipchitz over the interval (0, C) is used (C is a constant real number). The first term of Eq. 12 is upper-bounded by Talagrand\u2019s lemma. For any \u03b4 with probability at least 1\u2212 \u03b4, we have\nsup h\u2208H |Ex\u223cq(x)[h(x)]\u2212\n1\nm\n\u2211 h(xi)| \u2264 Rm,q(H) + C \u221a log 1\u03b4 2m , (14)\nwhere samples are taken from q(x) independently. By combining Eq. 13 and Eq. 14, for any \u03b4 with probability as least 1\u2212 \u03b4, the first term of Eq. 11 is bounded by\n2CRm,p(H) + 2Rm,q(H) + (C2 + 2C) \u221a log 12\u03b4 2m . (15)\nWhen f is the KL-divergence, BRf (h) is Ex\u223cq(x)[h(x)]\u2212 Ex\u223cp(x)[log h(x)]. (16)\nThe second term of Eq. 16 cannot be bounded because log(x) is no longer Lipchitz continuous over (0, C). This explains why Pearson divergence is preferable to KL divergence in density ratio estimation. However, if h(x) is lower-bounded by the constant real number C, the problem is solved. Using the relative density ratio has the same effect.\nIn our setting, r(x) is a sigmoid function multiplied by C. If C is large, the approximation error, i.e., BRf (r0)\u2212BRf (r) is small. However, there is a possibility that the estimation error increases according to Eq. 15, which may lead to the learning instability."}, {"heading": "E SUMMARY OF DENSITY RATIO ESTIMATION RESEARCH", "text": "In this section, we review researches related to density ratio estimation, entangling them to b-GAN. The Eq. 4 has also been used in class probability density estimation and unnormalized models research. We briefly describe research that is closely connected to density ratio estimation and extract ideas that can also be applied to b-GAN."}, {"heading": "E.1 NOTATION", "text": "We summarize notations frequently used in this section.\n\u2022 r(x) = p(x)/q(x) Density ratios between p(x) and q(x). In b-GAN, p(x) is the probability density function of \u201dreal data\u201d and q(x) is the probability density function of \u201dgenerated data\u201d.\n\u2022 x(n)i Samples taken from p(x).\n\u2022 x(d)i Samples taken from q(x).\n\u2022 D = (p, q, \u03c0) The joint distribution of X and Y . The variable X has the the mixture distribution of \u03c0p + (1 \u2212 \u03c0)q and Y is a binary label taking values in {\u22121,+1} which satisfies \u03c0 = P (Y = 1); thus, (p, q) = (P (X|Y = 1), P (X|Y = \u22121)) holds.\n\u2022 \u03b7 The Bayes optimal estimator P (Y = 1|X) for binary classification.\n\u2022 l : {\u22121, 1} \u00d7 [0, 1]\u2192 R Loss function\n\u2022 h1 : X \u2192 [0, 1] An element of hypothesis sets. In this case, the objective is estimating P (Y = 1|x).\n\u2022 hg : X \u2192 V An element of hypothesis sets. V is a subset of R. Note that h1 is a special case of hg .\n\u2022 \u03a8 : [0, 1]\u2192 V A link function.\n\u2022 k(x, \u00b7) A positive definite and characteristic (Fukumizu et al., 2004) kernel on the measurable space ofR.\n\u2022 Hk A reproducing kernel Hilbert space with a kernel k (Steinwart, 2011). An inner product in Hk is \u3008\u00b7, \u00b7\u3009.\n\u2022 \u03a6 : R \u2192 Hk A characteristic function:x\u2192 k(x, \u00b7).\n\u2022 Xp A random variable with probability density function p.\n\u2022 Bf [p\u2016q] Bregman divergence with f between p and q."}, {"heading": "E.2 THEORETICAL ASPECTS OF DENSITY RATIO ESTIMATION", "text": "Following Kanamori et al. (2012), we expand the explanation of density ratio estimation. As noted in Section 3, the objective function of density ratio estimation is\nB\u0302Rf (r\u03b8) = 1\nn n\u2211 i=1 ( f \u2032(r\u03b8(x (d) i ))r\u03b8(x (d) i )\u2212 f(r\u03b8(x (d) i )) ) \u2212 1 n n\u2211 i=1 f \u2032 ( r\u03b8(x (n) i ) ) , (17)\nwhich is an empirical approximation of Eq. 5. The estimator \u03b8\u0302n is obtained by minimizing Eq. 17. The estimator \u03b8\u0302n is an M-estimator because Eq. 17 is a form of 1n \u2211n i=1m(x), where m is a function of x and x \u223c (xdi , xni ) holds. The estimator \u03b8\u0302n satisfies consistency under mild conditions (see Prop 7.4. (Hayashi, 1997)). The essential condition is the expectation of Eq. 17 is uniquely minimized when r\u03b8 is equivalent to the true density ratio r. We have proved that proposition in Appendix D. Asymptotic normality also holds under suitable conditions (see Prop 7.8. (Hayashi, 1997)).\nBy differentiating Eq. 17 with respect to \u03b8, the above method can be regarded as a type of moment matching as follows:\n\u2202BRf (r\u03b8)\n\u2202\u03b8 =\n1\nn n\u2211 i=1 f \u2032\u2032(r\u03b8(x (d) i )r \u2032 \u03b8(x (d) i )r\u03b8(x (d) i )\u2212 1 n n\u2211 i=1 f \u2032\u2032(r\u03b8(x (n) i ))r \u2032 \u03b8(x (n) i ). (18)\nThe estimator \u03b8\u0302n is attained when Eq.18 is equal to 0. By substituting f \u2032\u2032(r\u03b8(xi)r\u2032\u03b8(xi) with s(xi), Eq. 18 is reduced to be\n1\nn n\u2211 i=1 s(x (d) i )r\u03b8(x (d) i )\u2212 1 n n\u2211 i=1 s(x (n) i ). (19)\nThe above Eq. 18 is a form of moment matching.1 What is the optimal s(x)? Here, we focus on the variance of the estimator (efficiency). It is known that the Eq. 17 derived from the logistic model is known to be optimal (Qin, 1998). It is a natural consequence because the logistic model can be considered as a maximum likelihood and maximum likelihood reaches the Cramer-Rao bound asymptotically. Typically, general moment matching (GMM) achieves the lower bound when the estimating equation is the score of observations, i.e., when GMM is identical to maximum likelihood.\nEfficiency is not the absolute criterion for choosing losses. For example, when there are many outliers in the data, robustness is more important than efficiency. In reality, an M estimator was introduced in the contest of robust statistics (Huber & Ronchetti, 2009)."}, {"heading": "E.3 CLASS PROBABILITY ESTIMATION", "text": "We have explained density ratio estimation, starting with the Bregman divergence. Importantly, density-ratio estimation is equivalent to class probability estimation. For details, see (Reid & Williamson, 2011; 2010; Dawid & Musio, 2014; Menon & Ong, 2016).\nAs in Section E.1, we introduce the variable Y . The joint distribution of X and Y is denoted as D = (p, q, \u03c0). Class probability estimation can be regraded as a minimization problem of the empirical estimation of the full risk E(X,Y )\u223cD[l(Y, h1)], which is denoted L(h1;D, l) (h1 is a hypothesis element). When the hypothesis h1, which minimizes E(X,Y )\u223cD[l(Y, h1)], is the Bayes optimal estimator \u03b7(x) uniquely, such a loss is called a proper loss.\nA proper loss is naturally extended to a composite proper loss by introducing a link function \u03a6. In this case, the objective is estimating \u03a6(\u03b7(x)) correctly. The estimator is obtained by the empirical minimization of full risk E(X,Y )\u223cD[l\u03a6(Y, hg)] when l\u03a6(Y, hg) means l(Y,\u03a6\u22121(hg(x))) and \u03a6(h1(x)) is the same as hg(x). When the hypothesis hg(x), which minimizes E(X,Y )\u223cD[l\u03a6(Y, hg)], is the Bayes optimal estimator \u03a6(\u03b7(x)) uniquely, such a loss is called a proper composite loss with a link function \u03a6.\nThe conditional risk (conditioned on x) EY\u223c\u03b7[l\u03a6(Y, hg)] can be decomposed to\nEY\u223c\u03b7[l \u03a6(Y, hg)] = \u03b7L1(h g) + (1\u2212 \u03b7)L\u22121(hg). (20)\nThe conditional Bayes risk is\n\u03b7L1(\u03a6(\u03b7(x))) + (1\u2212 \u03b7)L\u22121(\u03a6(\u03b7(x))) = \u03b7\u03bb+1(\u03b7) + (1\u2212 \u03b7)\u03bb\u22121(\u03b7), (21)\nwhere \u03bb+1(x) = L1(\u03a6(x)) and \u03bb\u22121(x) = L\u22121(\u03a6(x)). We set Eq. 21, i.e., x\u03bb+1(x)+(1\u2212x)\u03bb\u22121(x) as c(x). The regret of the composite proper loss can be written using Bregman divergence\nL(hg;D, l)\u2212 L(\u03a6 \u25e6 \u03b7;D, l) = EX [ Bc [ \u03b7(X)\u2016\u03a6\u22121(hg(X)) ]] . (22)\n1In usual moment matching, s(x) is not be dependent on the form of probability density function. However, it depends on the form of r\u03b8 in this case.\nThe problem of minimizing the composite proper loss turns out be the density ratio estimation problem by setting \u03a6(x) as u/(1\u2212 u) and \u03c0 = 0.5 (Menon & Ong, 2016). In this case, the LHS of Eq. 22 can be written as EX\u223cq [Bc\u2297 [\u03a6(\u03b7(X))\u2016hg(X)]] (\u03a6(\u03b7(X)) = r(x)), where c\u2297 is given by\nc\u2297 : x\u2192 (1 + x)c ( x\n1 + x\n) .\nThe equation EX\u223cq [Bc\u2297 [r(X)\u2016hg(X)]] corresponds to Eq. 4 by substituting c\u2297 with f and hg with r\u03b8.\nWhat loss is the optimal loss? The above loss can be written in another form using weight by transforming Eq. 22 further. Determining what loss is better has been analyzed from the perspective of weight. For example, Reid & Williamson (2010) proposed the \u201dminimal symmetric convex proper loss\u201d for surrogate loss. Regarding density ratio, Menon & Ong (2016) suggest that Pearson divergence is robust because the weight of Pearson divergence is uniform. However, according to their covariate shift experiment, Pearson divergence was not significantly superior to other divergence.\nWhat is the difference between density ratio estimation (class probability estimation) and classification? The objective and assumption differ. As for assumption, in density ratio, the situation where p(x) and q(x) are overlapping would be preferable. However, in classification, the situation where p(x) and q(x) separate would be preferable. In addition, the objective of classification is slightly different from estimating a Bayes rule correctly. Margin loss is widely used in classification rather than zero-one loss. The theoretical guarantee of using margin loss for classification is that it is included in class calibrated loss (Bartlett et al., 2006). However, the margin loss is not equivalent to a proper loss, i.e, it is often not suitable for estimating \u03b7. The condition whereby margin loss is a proper loss is explained by Reid & Williamson (2010). A GAN using margin loss has been proposed (Zhao et al., 2016). Note that using margin loss is not supposed in b-GAN. They succeeded in generating high resolution images."}, {"heading": "E.4 ROBUST LOSS AND DIVERGENCE", "text": "What is robust loss and divergence? Basu et al. (1998) proposed a robust divergence called power divergence (Basu et al., 1998), which is given as B\u03bd\u03b2 [p\u2016q], where \u03bd\u03b2 is\n\u03bd\u03b2(x) = 1\n\u03b2(\u03b2 + 1) (x\u03b2+1 \u2212 (\u03b2 + 1)x+ \u03b2). (23)\nThis is also called \u03b2-divergence (Amari & Cichoki, 2010). The robust estimation equation is derived from power divergence compared to maximum likelihood. By setting f as \u03bd\u03b2 , robust density ratio estimation has been proposed (Sugiyama et al., 2012). In this case, the objective function is Ex\u223cq(x)[B\u03bd\u03b2 [r\u2016r\u03b8]]. Dawid et al. (2015) analyze robust proper loss from the perspective of influence function. They proposed a concept of B-robustness from the perspective of influence function. It is stated that using KL divergence and reversed KL divergence is not robust because the second derivative of f is not bounded at 0. That is a similar conclusion to our analysis in Appendix D."}, {"heading": "E.5 KERNEL METHODS", "text": "We assume that k(x, \u00b7) is a positive definite kernel. When X is a random variable taking values inR and \u03a8(X) is a random variable taking values inHk with a characteristic map \u03a8 : x\u2192 k(\u00b7, x), we can think of the mean of random variable \u03a6(X) denoted as mkX taking values inHk, which satisfy \u3008f,mkX\u3009 = E[\u3008f,\u03a8(X)\u3009] = E[f(x)](\u2200f \u2208 Hk) and mkX(y) = \u3008mkX , k(\u00b7, y)\u3009 = E[k(X, y)]. If the kernel is characteristic, the bijective from all measures onR to Hk exists such that a measure p(x)dx corresponds to the mean mkXp (Fukumizu et al., 2004). When there are random variables Xp and Xq , we can measure the distance between Xp and Xq by calculating \u2016mkXp \u2212m k Xq \u20162Hk .\nAs the density ratio estimation methods using kernels, the objective function is the empirical approximation of \u2016mkXqr\u03b8 \u2212m k Xp \u20162Hk . As generative moment matching networks (GMMN), the objective\nfunction is \u2016mkXq \u2212m k Xp \u20162Hk (Dziugaite et al., 2015; Li et al., 2015). GMMNs seem to be superior to b-GAN because they can be trained without density ratio. However, the choice of kernels is difficult. In addition, an autoencoder appears to be required for generating complex data."}, {"heading": "E.6 F-DIVERGENCE ESTIMATION AND TWO SAMPLE TEST", "text": "We consider the problem of f-divergence estimation between p(x) and q(x). This is applied straightforwardly to a two-sample test. Variational f-divergence estimation using Eq. 3 is proposed (Nguyen et al., 2010). In addition, the two step method, i.e., first estimating density ratio and then estimating f-divergence, is proposed (Kanamori et al., 2012). This method is also applied to a two-sample test. The latter method is similar to b-GAN. A kernel two sample test is also introduced calculating \u2016mkXq \u2212m k Xp \u20162Hk in (Gretton et al., 2012)."}, {"heading": "E.7 UNNORMALIZED MODELS", "text": "When the model p0(xm;\u03c6) is unnormalized, the unified method including noise contrastive estimation was proposed in (Pihlaja et al., 2010; Gutmann & Hirayama, 2011; Gutmann & Hyvarinen, 2010).\nIn this case, the objective is estimating \u03b8 = {\u03c6,C} when the log-likelihood of normalized model log p(x; \u03b8) is equal to log p0(x;\u03c6) + C and C is a normalizing constant. Compared to b-GAN, the auxiliary distribution q(x) is known. The parameter \u03b8 can be estimated as a minimization problem of Eq. 17 by replacing r\u03b8(x) with p(x; \u03b8)/q(x) (Pihlaja et al., 2010). As similar algorithm, the method estimating r\u03b8 first, then estimating p(x; \u03b8) as r\u03b8(x)q(x) is suggested by Gutmann & Hirayama (2011). Note that the latter method is similar to b-GAN.\nPihlaja et al. (2011) analyzed what loss is better by differentiating loss. They experimentally confirmed that noise contrastive estimation is robust with respect to the choice of the auxiliary distribution."}], "references": [{"title": "TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. URL http://tensorflow.org/. Software available from tensorflow.org", "author": ["M. Abadi", "A. Agarwal", "P Barham"], "venue": null, "citeRegEx": "Abadi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Abadi et al\\.", "year": 2015}, {"title": "A general class of coefficients of divergence of one distribution from another", "author": ["M. Ali", "S. Silvey"], "venue": "Journal Royal Statistical Society Series B,", "citeRegEx": "Ali and Silvey.,? \\Q1966\\E", "shortCiteRegEx": "Ali and Silvey.", "year": 1966}, {"title": "Information geometry of divergence functions", "author": ["S. Amari", "A. Cichoki"], "venue": "Bull. Polish. Acad. Sci.,", "citeRegEx": "Amari and Cichoki.,? \\Q2010\\E", "shortCiteRegEx": "Amari and Cichoki.", "year": 2010}, {"title": "Convexity, classification and risk bounds", "author": ["P.L. Bartlett", "M.I. Jordan", "J.D. McAuliffe"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Bartlett et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Bartlett et al\\.", "year": 2006}, {"title": "Robust and efficient estimation by minimising a density power divergence", "author": ["A. Basu", "I.R. Harris", "N.L. Hjort", "M.C. Jones"], "venue": null, "citeRegEx": "Basu et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Basu et al\\.", "year": 1998}, {"title": "Learning bounds for importance weighing", "author": ["C. Cortes", "Y. Mansour", "M. Mohri"], "venue": "In Advances in Neural Information Processing System (NIPS),", "citeRegEx": "Cortes et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Cortes et al\\.", "year": 2010}, {"title": "Theory and applications of proper scoring", "author": ["A.P. Dawid", "M. Musio"], "venue": "rules. Metron,", "citeRegEx": "Dawid and Musio.,? \\Q2014\\E", "shortCiteRegEx": "Dawid and Musio.", "year": 2014}, {"title": "Minimum scoring rule inference", "author": ["A.P. Dawid", "M. Musio", "L. Ventura"], "venue": "Scandinavian Journal of Statistics,", "citeRegEx": "Dawid et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dawid et al\\.", "year": 2015}, {"title": "Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks", "author": ["E. Denton", "S. Chintala", "A. Szlam", "R. Fergus"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Denton et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Denton et al\\.", "year": 2015}, {"title": "Training generative neural networks via maximum mean discrepancy optimization", "author": ["G.K. Dziugaite", "D.M. Roy", "Z. Ghahramani"], "venue": "In Proc. Conf. on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "Dziugaite et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dziugaite et al\\.", "year": 2015}, {"title": "Dimensionality reduction for supervised learning with reproducing kernel hilbert spaces", "author": ["K. Fukumizu", "F. Bach", "M. Jordan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Fukumizu et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Fukumizu et al\\.", "year": 2004}, {"title": "Generative adversarial nets", "author": ["I. Goodfellow", "J.M. Pouget-Abadie", "Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "On distinguishability criteria for estimating generative models", "author": ["I.J. Goodfellow"], "venue": "ArXiv e-prints,", "citeRegEx": "Goodfellow.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow.", "year": 2014}, {"title": "A kernel two-sample test", "author": ["A. Gretton", "K. Borgwardt", "M. Rasch", "B. Schoelkopf", "A. Smola"], "venue": "Journal of Machine Learning Research,,", "citeRegEx": "Gretton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gretton et al\\.", "year": 2012}, {"title": "Noisecontrastive estimation: A new estimation principle for unnormalized statistical models", "author": ["M. Gutmann", "A. Hyvarinen"], "venue": "In Artificial Intelligence and Statistics Conference (AISTATS),", "citeRegEx": "Gutmann and Hyvarinen.,? \\Q2010\\E", "shortCiteRegEx": "Gutmann and Hyvarinen.", "year": 2010}, {"title": "Bregman divergence as general framework to estimate unnormalized statistical models", "author": ["M.U. Gutmann", "J. Hirayama"], "venue": "In Uncertainty in Artificial Intelligence", "citeRegEx": "Gutmann and Hirayama.,? \\Q2011\\E", "shortCiteRegEx": "Gutmann and Hirayama.", "year": 2011}, {"title": "Robust statistics", "author": ["P.J. Huber", "E.M. Ronchetti"], "venue": null, "citeRegEx": "Huber and Ronchetti.,? \\Q2009\\E", "shortCiteRegEx": "Huber and Ronchetti.", "year": 2009}, {"title": "How (not) to Train your Generative Model: Scheduled Sampling, Likelihood", "author": ["F. Huszar"], "venue": "Adversary? ArXiv e-prints,", "citeRegEx": "Huszar.,? \\Q2015\\E", "shortCiteRegEx": "Huszar.", "year": 2015}, {"title": "Divergence estimation and two-sample homogeneity test under semiparametric density-ratio models", "author": ["T. Kanamori", "T. Suzuki", "M. Sugiyama"], "venue": "IEEE Trans. Inform. Theory,", "citeRegEx": "Kanamori et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kanamori et al\\.", "year": 2012}, {"title": "Divergence estimation and two-sample homogeneity test under semiparametric density-ratio models", "author": ["T. Kanamori", "T Suzuki", "M. Sugiyama"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Kanamori et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kanamori et al\\.", "year": 2012}, {"title": "Adam: A Method for Stochastic Optimization", "author": ["D. Kingma", "J. Ba"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "Kingma and Ba.,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": null, "citeRegEx": "Krizhevsky.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky.", "year": 2009}, {"title": "Generative moment matching networks", "author": ["Y. Li", "K. Swersky", "R. Zemel"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Li et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Deep learning face attributes in the wild", "author": ["Z. Liu", "P. Luo", "X. Wang", "X. Tang"], "venue": "In Proceedings of International Conference on Computer Vision (ICCV),", "citeRegEx": "Liu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Linking losses for density ratio and class-probability estimation", "author": ["A.K. Menon", "C.S. Ong"], "venue": "In In International Conference on Machine Learning (ICML),", "citeRegEx": "Menon and Ong.,? \\Q2016\\E", "shortCiteRegEx": "Menon and Ong.", "year": 2016}, {"title": "Learning in Implicit Generative Models", "author": ["S. Mohamed", "B. Lakshminarayanan"], "venue": "ArXiv e-prints,", "citeRegEx": "Mohamed and Lakshminarayanan.,? \\Q2016\\E", "shortCiteRegEx": "Mohamed and Lakshminarayanan.", "year": 2016}, {"title": "Foundation of Machine Learning", "author": ["M. Mohri", "A. Rostamizadeh", "A. Talwalkar"], "venue": "The MIT press,", "citeRegEx": "Mohri et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mohri et al\\.", "year": 2012}, {"title": "Direct density ratio estimation with convolutional neural networks with application in outlier detection", "author": ["H. Nam", "M. Sugiyama"], "venue": "IEICE Transactions,", "citeRegEx": "Nam and Sugiyama.,? \\Q2015\\E", "shortCiteRegEx": "Nam and Sugiyama.", "year": 2015}, {"title": "Estimating divergence functionals and the likelihood ratio by convex risk minimization", "author": ["X. Nguyen", "M Wainwright", "M. Jordan"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Nguyen et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2010}, {"title": "f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization", "author": ["S. Nowozin", "B. Cseke", "R. Tomioka"], "venue": "ArXiv e-prints,", "citeRegEx": "Nowozin et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nowozin et al\\.", "year": 2016}, {"title": "A family of computationally efficient and simple estimators for unnormalized statistical models", "author": ["M. Pihlaja", "M.U. Gutmann", "A Hyvarinen"], "venue": "In Proc. Conf. on Uncertainty in Artificial Intelligence (UAI2010),", "citeRegEx": "Pihlaja et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Pihlaja et al\\.", "year": 2010}, {"title": "Inferences for case-control and semiparametric two-sample density ratio models", "author": ["J. Qin"], "venue": null, "citeRegEx": "Qin.,? \\Q1963\\E", "shortCiteRegEx": "Qin.", "year": 1963}, {"title": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks", "author": ["A. Radford", "L. Metz", "S. Chintala"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "Radford et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Radford et al\\.", "year": 2015}, {"title": "Composite binary losses", "author": ["M.D Reid", "R.C Williamson"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Reid and Williamson.,? \\Q2010\\E", "shortCiteRegEx": "Reid and Williamson.", "year": 2010}, {"title": "Information, divergence and risk for binary experiments", "author": ["M.D Reid", "R.C Williamson"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Reid and Williamson.,? \\Q2011\\E", "shortCiteRegEx": "Reid and Williamson.", "year": 2011}, {"title": "Improved Techniques for Training GANs", "author": ["T. Salimans", "I. Goodfellow", "W. Zaremba", "V. Cheung", "A. Radford", "X. Chen"], "venue": null, "citeRegEx": "Salimans et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Salimans et al\\.", "year": 2016}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["I. Sergey", "S. Christian"], "venue": null, "citeRegEx": "Sergey and Christian.,? \\Q2015\\E", "shortCiteRegEx": "Sergey and Christian.", "year": 2015}, {"title": "On the influence of the kernel on the consistency of support vector machines", "author": ["I Steinwart"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Steinwart.,? \\Q2011\\E", "shortCiteRegEx": "Steinwart.", "year": 2011}, {"title": "Density ratio matching under the bregman divergence: a unified framework of density ratio estimation", "author": ["M. Sugiyama", "T. Suzuki", "T. Kanamori"], "venue": "Annals of the Institute of Statistical Mathematics,", "citeRegEx": "Sugiyama et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Sugiyama et al\\.", "year": 2012}, {"title": "Learning under non-stationarity:covariate shift and class-balance change", "author": ["M. Sugiyama", "M. Yamada", "M.C. du Plessis"], "venue": "WIREs Computational Statistics,", "citeRegEx": "Sugiyama et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sugiyama et al\\.", "year": 2013}, {"title": "Relative density-ratio estimation for robust distribution comparison", "author": ["M. Yamada", "T. Suzuki", "T. Kanamori", "H. Hachiya", "M. Sugiyama"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Yamada et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Yamada et al\\.", "year": 2011}, {"title": "Energy-based Generative Adversarial Network", "author": ["J. Zhao", "M. Mathieu", "Y. LeCun"], "venue": "ArXiv e-prints,", "citeRegEx": "Zhao et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2016}, {"title": "EXPLANATION OF HEURISTICS USING RADEMACHER COMPLEXITY Here, we justify three points using Rademacher complexity. All techniques used are described in the literature", "author": ["D f(r\u03b8(x))r\u03b8(x)\u2212 f(r\u03b8(x"], "venue": "(Mohri et al.,", "citeRegEx": ".,? \\Q2012\\E", "shortCiteRegEx": ".", "year": 2012}, {"title": "2012), we expand the explanation of density ratio estimation. As noted in Section 3, the objective function of density ratio estimation", "author": ["Following Kanamori"], "venue": null, "citeRegEx": "Kanamori,? \\Q2012\\E", "shortCiteRegEx": "Kanamori", "year": 2012}, {"title": "analyze robust proper loss from the perspective of influence function. They proposed a concept of B-robustness from the perspective of influence function. It is stated that using KL divergence and reversed KL divergence is not robust because the second derivative of f is not bounded at 0. That is a similar conclusion to our analysis in Appendix D", "author": ["Dawid"], "venue": null, "citeRegEx": "Dawid,? \\Q2015\\E", "shortCiteRegEx": "Dawid", "year": 2015}], "referenceMentions": [{"referenceID": 11, "context": "Generative adversarial networks (GAN) (Goodfellow et al., 2014) is the variant of these models that has attracted the most attention.", "startOffset": 38, "endOffset": 63}, {"referenceID": 32, "context": "It has been demonstrated that generating vivid, realistic images from a uniform distribution is possible (Radford et al., 2015; Denton et al., 2015).", "startOffset": 105, "endOffset": 148}, {"referenceID": 8, "context": "It has been demonstrated that generating vivid, realistic images from a uniform distribution is possible (Radford et al., 2015; Denton et al., 2015).", "startOffset": 105, "endOffset": 148}, {"referenceID": 12, "context": "GANs have been applied in various studies; however, few studies have attempted to reveal their mechanism (Goodfellow, 2014; Huszar, 2015).", "startOffset": 105, "endOffset": 137}, {"referenceID": 17, "context": "GANs have been applied in various studies; however, few studies have attempted to reveal their mechanism (Goodfellow, 2014; Huszar, 2015).", "startOffset": 105, "endOffset": 137}, {"referenceID": 29, "context": "Recently, f-GAN, which minimizes the variational estimate of f-divergence, has been proposed (Nowozin et al., 2016).", "startOffset": 93, "endOffset": 115}, {"referenceID": 18, "context": "We derive a novel unified algorithm that employs well-studied results regarding density ratio estimation (Kanamori et al., 2012; Sugiyama et al., 2012; Menon & Ong, 2016).", "startOffset": 105, "endOffset": 170}, {"referenceID": 38, "context": "We derive a novel unified algorithm that employs well-studied results regarding density ratio estimation (Kanamori et al., 2012; Sugiyama et al., 2012; Menon & Ong, 2016).", "startOffset": 105, "endOffset": 170}, {"referenceID": 11, "context": "GANs (Goodfellow et al., 2014) were developed based on a game theory scenario, where two model, i.", "startOffset": 5, "endOffset": 30}, {"referenceID": 29, "context": "f-GAN (Nowozin et al., 2016) generalizes the GAN concept.", "startOffset": 6, "endOffset": 28}, {"referenceID": 28, "context": "Ex\u223cp(x)[T\u03b8D (x)]\u2212 Ex\u223cq(x;\u03b8G)[f \u2217 (T\u03b8D (x))], (2) where f\u2217 is a Fenchel conjugate of f (Nguyen et al., 2010).", "startOffset": 86, "endOffset": 107}, {"referenceID": 38, "context": "There have been many studies on direct density ratio estimation, where a density ratio model is fitted to a true density ratio model under the Bregman divergence (Sugiyama et al., 2012).", "startOffset": 162, "endOffset": 185}, {"referenceID": 11, "context": "In this study, a single-step gradient method (Goodfellow et al., 2014; Nowozin et al., 2016) is adopted.", "startOffset": 45, "endOffset": 92}, {"referenceID": 29, "context": "In this study, a single-step gradient method (Goodfellow et al., 2014; Nowozin et al., 2016) is adopted.", "startOffset": 45, "endOffset": 92}, {"referenceID": 29, "context": "In fact, the r(x) obtained at each iteration is different and not optimal because we adopt a single-step gradient method (Nowozin et al., 2016).", "startOffset": 121, "endOffset": 143}, {"referenceID": 29, "context": "It is noted in (Nowozin et al., 2016) that case (2) works better than case (3) in practice.", "startOffset": 15, "endOffset": 37}, {"referenceID": 35, "context": "We can expect the same effects as -minibatch discrimination- (Salimans et al., 2016).", "startOffset": 61, "endOffset": 84}, {"referenceID": 38, "context": "Density ratio estimation via the KL divergence corresponds to the Kullback-Leibler Importance Estimation Procedure (Sugiyama et al., 2012).", "startOffset": 115, "endOffset": 138}, {"referenceID": 40, "context": "\u2022 \u03b1 = 3 Density ratio estimation via the Pearson divergence corresponds to the LeastSquares Importance Fitting (Yamada et al., 2011).", "startOffset": 111, "endOffset": 132}, {"referenceID": 40, "context": "It is more robust than under KL divergence (Yamada et al., 2011; Dawid et al., 2015).", "startOffset": 43, "endOffset": 84}, {"referenceID": 7, "context": "It is more robust than under KL divergence (Yamada et al., 2011; Dawid et al., 2015).", "startOffset": 43, "endOffset": 84}, {"referenceID": 17, "context": "However, it is preferable to use reversed KL divergence when generating realistic images (Huszar, 2015).", "startOffset": 89, "endOffset": 103}, {"referenceID": 5, "context": "A similar idea has also been used in (Cortes et al., 2010).", "startOffset": 37, "endOffset": 58}, {"referenceID": 39, "context": "The same idea is introduced in the covariate shift situation (Sugiyama et al., 2013).", "startOffset": 61, "endOffset": 84}, {"referenceID": 35, "context": "A similar idea has also been used for GAN learning (Salimans et al., 2016) and class probability estimation (Reid & Williamson, 2010).", "startOffset": 51, "endOffset": 74}, {"referenceID": 21, "context": "We applied the proposed algorithm to the CIFAR-10 data set (Krizhevsky, 2009) and Celeb A data set (Liu et al.", "startOffset": 59, "endOffset": 77}, {"referenceID": 23, "context": "We applied the proposed algorithm to the CIFAR-10 data set (Krizhevsky, 2009) and Celeb A data set (Liu et al., 2015) because they are often used in GAN research (Salimans et al.", "startOffset": 99, "endOffset": 117}, {"referenceID": 35, "context": ", 2015) because they are often used in GAN research (Salimans et al., 2016; Goodfellow et al., 2014).", "startOffset": 52, "endOffset": 100}, {"referenceID": 11, "context": ", 2015) because they are often used in GAN research (Salimans et al., 2016; Goodfellow et al., 2014).", "startOffset": 52, "endOffset": 100}, {"referenceID": 32, "context": "Our network architecture is nearly equivalent to that of previous study (Radford et al., 2015) (refer to the appendix A,B for details).", "startOffset": 72, "endOffset": 94}, {"referenceID": 0, "context": "We used the TensorFlow for automatic differentiation (Abadi et al., 2015).", "startOffset": 53, "endOffset": 73}, {"referenceID": 40, "context": "The same results have been reported in the research into density ratio estimation (Yamada et al., 2011).", "startOffset": 82, "endOffset": 103}, {"referenceID": 7, "context": "It is also reported that using KL-divergence and reversed KL-divergence is not robust as scoring rules (Dawid et al., 2015).", "startOffset": 103, "endOffset": 123}, {"referenceID": 17, "context": "For generating realistic images, the reversed KL divergence (\u03b1 = \u22121) is preferred because it is mode seeking (Huszar, 2015).", "startOffset": 109, "endOffset": 123}, {"referenceID": 38, "context": "For a robust density ratio, using power divergence has also been proposed (Sugiyama et al., 2012).", "startOffset": 74, "endOffset": 97}, {"referenceID": 30, "context": "As unnormalized models, the latter is more robust than estimating r(x) (Pihlaja et al., 2010) (Appendix E.", "startOffset": 71, "endOffset": 93}], "year": 2016, "abstractText": "Generative adversarial networks (GANs) are successful deep generative models. They are based on a two-player minimax game. However, the objective function derived in the original motivation is changed to obtain stronger gradients when learning the generator. We propose a novel algorithm that repeats density ratio estimation and f-divergence minimization. Our algorithm offers a new unified perspective toward understanding GANs and is able to make use of multiple viewpoints obtained from the density ratio estimation research, e.g. what divergence is stable and relative density ratio is useful.", "creator": "LaTeX with hyperref package"}, "id": "ICLR_2017_260"}