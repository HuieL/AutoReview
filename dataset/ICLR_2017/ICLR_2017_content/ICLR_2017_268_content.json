{"name": "ICLR_2017_268.pdf", "metadata": {"source": "CRF", "title": "BOOSTED GENERATIVE MODELS", "authors": ["Aditya Grover", "Stefano Ermon"], "emails": ["ermon}@cs.stanford.edu"], "sections": [{"heading": "1 INTRODUCTION", "text": "Many of the recent successful applications of machine learning in computer vision, speech recognition, and natural language processing are based on discriminative models. Learning generative models has proven to be much more difficult. Deep architectures, including latent variable models such as Boltzmann machines (Smolensky, 1986), variational autoencoders (Kingma & Welling, 2014), and generative adversarial networks (Goodfellow et al., 2014), have recently shown great success. Despite significant progress, existing generative models cannot fit complex distributions with a sufficiently high degree of accuracy.\nIn this paper, we propose a technique for ensembling (imperfect) generative models to improve their overall performance. Our meta-algorithm is inspired by boosting, a powerful technique used in supervised learning to construct ensembles of weak classifiers (e.g., decision stumps or trees), which individually might not perform well on a given classification task. The boosting algorithm will attempt to learn a classifier to correct for the mistakes made and repeat this procedure recursively. Under some conditions on the weak classifiers\u2019 effectiveness, the boosting meta-algorithm can drive the (training) error to zero (Freund et al., 1999). Boosting can also be thought as a feature learning algorithm, where at each round a new feature is learned by training a classifier on a re-weighted version of the original dataset. In practice, algorithms based on boosting (such as boosted trees) perform extremely well in machine learning competitions (Caruana & Niculescu-Mizil, 2006).\nWe show that a similar procedure can be applied to generative models. Given an initial generative model that provides an imperfect fit to the data distribution, we construct a second model to correct for the error, and repeat recursively. The second model is also a generative one, which is trained on a re-weighted version of the original training set. Our meta algorithm is general and can construct ensembles of many existing generative models such as restricted Boltzmann machines and variational autoencoders. Surprisingly, our method can even leverage discriminative models, which have been shown to perform extremely well in practice (Krizhevsky et al., 2012; LeCun et al., 2015). Specifically, we train a discriminator to distinguish true data samples from \u201cfake\u201d ones generated by\nthe current model and provide a principled way to include this discriminator in the ensemble. We also provide conditions under which adding a model to the ensemble is guaranteed to improve the fit and recover the true data distribution under idealized conditions.\nTo evaluate our algorithmic framework, we learn several ensembles of weakly-trained generators and discriminators and test them on popular use cases of generative models: density estimation, sample generation, and unsupervised feature learning. We show how boosted generative models can outperform baseline models without any additional computation cost."}, {"heading": "2 BOOSTING GENERATIVE MODELS", "text": "Boosting is an ensembling technique for supervised learning, providing an algorithmic formalization of the hypothesis that a sequence of weak learners can create a single strong learner (Schapire & Freund, 2012). In this section, we propose a framework that extends boosting to unsupervised settings for learning joint distributions using generative models. For ease of presentation, all distributions are w.r.t. any arbitrary x \u2208 Rd, unless otherwise specified. Formally, we consider the following maximum likelihood estimation (MLE) setting. Given some data points X = {xi \u2208 Rd}mi=1 sampled i.i.d. from an unknown distribution with p.d.f. p, we provide a model class Q parametrizing the distributions that can be represented by the generative model and minimize the KL-divergence w.r.t. the true distribution,\nmin q\u2208Q\nDKL(p \u2016 q). (1)\nIn practice, we only observe samples from p and hence, maximize the log-likelihood of the observed data X . Selecting the model class for maximum likelihood learning is non-trivial; the maximum likelihood estimate w.r.t. a small class can be very far from the true distribution whereas a large class poses the risk of overfitting."}, {"heading": "2.1 FACTORED LIKELIHOODS FOR UNSUPERVISED BOOSTING", "text": "In unsupervised boosting, we factorize the joint distribution specified by a generative model as a geometric average of T +1 intermediate model distributions {ht}Tt=0, each assigned an exponentiated weight \u03b1t,\nqT =\n\u220fT t=0 h \u03b1t t\nZT where the partition function ZT = \u222b \u220fT t=0 h \u03b1t t dx. Because a joint optimization over all the intermediate model distributions and weights is computationally prohibitive, we instead perform a greedy optimization at every round. The joint distribution of a boosted generative model (BGM) can be recursively expressed as,\nq\u0303t = h \u03b1t t \u00b7 q\u0303t\u22121 (2)\nwhere q\u0303t is the unnormalized BGM distribution (at round t). The base model distribution h0 is learned using the maximum likelihood principle. Given suitable weights, we now derive conditions on the intermediate model distributions that allow us to make \u201cprogress\u201d in every round of boosting.\nTheorem 1. Let \u03b4tKL(ht, \u03b1t) = DKL(p \u2016 qt\u22121) \u2212 DKL(p \u2016 qt) denote the reduction in KL divergence at the tth round of boosting. Then, for all 0 \u2264 \u03b1t \u2264 1, the following conditions hold,\n1. Sufficient: If Ep[log ht] \u2265 logEqt\u22121 [ht], then \u03b4tKL(ht, \u03b1t) \u2265 0.\n2. Necessary: If \u03b4tKL(ht, \u03b1t) \u2265 0, then Ep[log ht] \u2265 Eqt\u22121 [log ht].\nProof. See Appendix A.1.1.\nAlgorithm 1 DiscBGM(X = {xi}mi=1, T rounds) Initialize D0(xi) = 1/m for all i = 1, 2, . . . ,m. Set (unnormalized) density estimate q\u03030 = h0 Train generative model h0 to maximize Exi\u223cD0 [log h0(xi)]\nfor t = 1, . . . , T do \u2022 Generate k negative samples from qt\u22121 \u2022 Train discriminative model dt to maximize Exi\u223cD0 [log dt] + Exi\u223cqt\u22121 [log(1\u2212 dt)]. \u2022 Set ht = \u03b3 \u00b7 dt1\u2212dt where \u03b3 = k/m. \u2022 Choose \u03b1t. \u2022 Set (unnormalized) density estimate q\u0303t = h\u03b1tt \u00b7 q\u0303t\u22121. end for\nEstimate ZT = \u222b q\u0303T (x)dx. return qT = q\u0303T /ZT\nThe equality in the above conditions holds true for \u03b1t = 0 which corresponds to the trivial case where the intermediate model distribution in the current round is ignored in the BGM distribution in Eq. (2). For all other valid \u03b1t > 0, the non-degenerate versions of the sufficient inequality guarantees progress towards the true data distribution. Note that the intermediate models increase the overall capacity of the BGM at every round.\nFrom the necessary condition, we see that a \u201cgood\u201d intermediate density ht necessarily assigns a better-or-equal log-likelihood under the true desired distribution as opposed to the BGM distribution in the previous round, qt\u22121. This condition suggests two learning objectives for intermediate models which we discuss next."}, {"heading": "2.2 DISCRIMINATIVE APPROACH FOR BOOSTING GENERATIVE MODELS", "text": "In the discriminative approach for boosting generative models, the intermediate model distribution is specified as the odds ratio of a binary classifier. Specifically, consider the following binary classification problem: we observe m samples drawn i.i.d. from the true data distribution p (w.l.o.g. assigned the label y = +1), and k samples drawn i.i.d. from the BGM distribution in the previous round qt\u22121 (assigned the label y = \u22121). The objective of the binary classifier is to learn a conditional distribution dt \u2208 Dt that maximizes the cross-entropy,\nmax dt\u2208Dt\nEx\u223cp[log dt] + Ex\u223cqt\u22121 [log(1\u2212 dt)]. (3)\nDefinition 1. If ut denotes the joint distribution over (x, y) at round t, then a binary classifier with density dt is Bayes optimal iff,\ndt(x) = ut(y = +1 | x). Theorem 2. If a binary classifier dt trained to optimize Eq. (3) is Bayes optimal, then the BGM distribution at the end of the round will immediately converge to the true data distribution if we set \u03b1t = 1 and\nht = \u03b3 \u00b7 dt\n1\u2212 dt (4)\nwhere \u03b3 = k/m.\nProof. See Appendix A.1.2.\nIn practice, a classifier with limited capacity trained on a finite dataset will not generally be Bayes optimal. The above theorem, however, suggests that a good classifier can provide a \u201cdirection of improvement\u201d. Additionally, if the intermediate model distribution ht obtained using Eq. (4) satisfies the conditions in Theorem 1, it is guaranteed to improve the BGM distribution.\nAlgorithm 2 GenBGM(X = {xi}mi=1, T rounds)\nInitialize D0(xi) = 1/m for all i = 1, 2, . . . ,m. Train generative model h0 to maximize Exi\u223cD0 [log h0(xi)]. Set (unnormalized) density estimate q\u03030 = h0\nfor t = 1, 2, . . . , T do \u2022 Update Dt using Eq. (5). \u2022 Train generative model ht to maximize Exi\u223cDt [log ht(xi)]. \u2022 Choose \u03b1t. \u2022 Set (unnormalized) density estimate q\u0303t = q\u0303t\u22121 \u00b7 h\u03b1tt . end for\nEstimate ZT = \u222b q\u0303T (x)dx. return qT = q\u0303T /ZT .\nThe pseudocode for the corresponding boosting algorithm DiscBGM is given in Algorithm 1. At every round of boosting, we train a binary classifier to optimize the objective in Eq. (3). Note that the BGM distributions at the intermediate boosting rounds can be specified up to a normalization constant if samples from the previous BGM distribution are generated via MCMC sampling. If the partition function is required, it can be estimated using techniques such as Annealed Importance Sampling (Neal, 2001).1\nThe weights 0 \u2264 \u03b1t \u2264 1 can be interpreted as our confidence in the classifier density estimate. While in practice we use heuristic strategies for assigning weights to the intermediate models, the greedy optimum value of these weights at every round is a critical point for \u03b4tKL (defined in Theorem 1). We consider a few special cases below.\n\u2022 If dt is uninformative, i.e., dt \u2261 0.5, then \u03b4tKL(ht, \u03b1t) = 0 for all 0 \u2264 \u03b1t \u2264 1. \u2022 If dt is Bayes optimal, then \u03b4tKL attains a maxima at \u03b1?t = 1. (Theorem 2). \u2022 For a completely adversarial classifier w.r.t. the Bayes optimality criteria, i.e., dt(x) = u(y = \u22121|x), we have the following result.\nCorollary 1. If dt is completely adversarial, then \u03b4tKL attains a maxima of zero at \u03b1?t = 0.\nProof. See Appendix A.1.3."}, {"heading": "2.3 GENERATIVE APPROACH FOR BOOSTING GENERATIVE MODELS", "text": "In the greedy optimization framework of unsupervised boosting, we want to learn an intermediate model distribution at every round that maximizes \u03b4tKL when factored as a product with the BGM distribution in the previous round. In the generative approach, the intermediate model specifies a ratio of densities and maximizes the log-likelihood of data sampled from a reweighted data distribution,\nmax ht Ex\u223cDt [log ht]\nwhere Dt \u221d p\nqt\u22121 . (5)\nThe pseudocode for the corresponding unsupervised boosting algorithm, GenBGM is is given in Algorithm 2. Starting with a uniform distribution overX , GenBGM learns an intermediate model at every round that maximizes the log-likelihood of data sampled from a reweighted data distribution.\n1For many applications of generative models such as sample generation and feature learning, we can sidestep computing the partition function."}, {"heading": "2.4 GENERATIVE-DISCRIMINATIVE APPROACH FOR BOOSTING GENERATIVE MODELS", "text": "Intermediate models need not be exclusively generators or discriminators as in Algorithm 1 and Algorithm 2; we can design a boosting algorithm that uses any ensemble of generators and discriminators as intermediate models. If an intermediate distribution is required to be a generator, we train a generative model by appropriately reweighting our training set. If a discriminator odds ratio is used to specify an intermediate distribution, we set up the corresponding binary classification problem.\nIn practice, we want BGMs to generalize to data points outside the training set X. Regularization in BGMs is imposed primarily in two ways. First, every intermediate model can be independently regularized by incorporating explicit terms in the learning objective, early stopping of training based on validation error, specialized techniques such as dropout, etc. Moreover, regularization in BGMs is also imposed by restricting the number of rounds of boosting. If the intermediate models are exseveral applications of pressive enough, then very few rounds of boosting are required. We now do an empirical study of BGMs for several applications of generative modeling."}, {"heading": "3 EMPIRICAL EVALUATION", "text": "We evaluated the performance of BGMs as a general-purpose meta-algorithm for generative modeling applications on real and synthetic datasets for three tasks: density estimation, sample generation, and unsupervised feature learning for downstream semi-supervised classification."}, {"heading": "3.1 DENSITY ESTIMATION", "text": "A common pitfall with training generative models is model misspecification w.r.t. the true underlying data distribution. To illustrate how BGMs can effectively correct for model misspecification, we consider density estimation on synthetic data. The true data distribution in Figure 1 (a) is a equi-weighted mixture of four Gaussians centered symmetrically around the origin, each having an identity covariance matrix. We only observe 1,000 samples drawn i.i.d. from the data distribution (shown as black dots), and the task is to learn this distribution.\nExperimental setup. As a baseline (misspecified) model, we fit a mixture of two Gaussians to the data shown in Figure 1 (b). We evaluate the following ensembling techniques.\n1. Bagging. Bagging works just like GenBGM but without any reweighting at every round of ensembling. The intermediate generative models are mixtures of two Gaussians.\n2. GenBGM (Algorithm 2). The intermediate models are mixtures of two Gaussians.\n3. DiscBGM (Algorithm 1). The binary classifiers used to specify the intermediate models are support vector machines (SVMs) with a radial basis function kernel.\nIn all ensembles, equal weights are heuristically assigned to every model such that \u2211Ti=1\u03b1i = 1. For the bagging and GenBGM approaches, ensembling is stopped after T = 3 rounds when the addition of a new model does not result in any significant change in the density estimate. For the DiscBGM approach, ensembling is stopped after T = 15 rounds to prevent overfitting.\nResults and discussion. The contour plots for the density estimated by the three approaches are shown in Figure 1. While the bagging approach is not very effective, GenBGM and DiscBGM steer the initial misspecified distribution towards the true distribution. DiscBGM is more conservative in assigning density mass to outliers and requires more rounds of boosting as opposed to GenBGM."}, {"heading": "3.2 SAMPLE GENERATION", "text": "In this task, we generate samples from the learned BGM models and visually inspect their quality. We consider sample generation for the binarized MNIST handwritten digits dataset (LeCun et al., 2010), which contains 50,000 train, 10,000 validation, and 10,000 test images of dimensions 28\u00d728. Experimental setup. Boosting is a particularly attractive framework for improving weak learners. For a baseline generative model, we consider the following two latent variable models.\nVariational Autoencoder (Kingma & Welling, 2014). VAEs are directed models with continuous latent units where the posterior over the latent units is specified using a neural network. We use the evidence lower bound as a proxy for approximately evaluating the log-likelihood during learning.\nRestricted Boltzmann Machine (Smolensky, 1986). RBMs are undirected 2-layer models with discrete latent units such that the latent and visible layer form a fully-connected bipartite graph. In RBMs, the log-likelihood can be tractably computed up to a normalization constant and learning is done using contrastive divergence (Hinton, 2002).\nWe compare the baseline models with several BGMs. The starting distribution h0 for a BGM is specified using a VAE or an RBM with the same model specification and learning procedure as the baseline models. However, when baseline models are used on their own (T = 0, i.e., no boosting) the training is run for 50 epochs. It is reduced to 10 epochs when the base model is used to specify\na BGM with T > 0, in an attempt to ensure fairness in terms of computation. The intermediate distributions are specified either using a VAE or RBM, or through a Convolutional Neural Network (CNN) (LeCun & Bengio, 1995) that performs binary classification.\nThe model architectures, learning procedure, and hyperparameters for the VAE, RBM, and CNN are described in Appendix A.2. The boosting sequences we consider are as follows.\n1. T = 0: Baseline VAE, Baseline RBM."}, {"heading": "2. T = 1: VAE\u2192 VAE, RBM\u2192 RBM, VAE\u2192 RBM, VAE\u2192 CNN, RBM\u2192 CNN.", "text": "3. T = 2: VAE\u2192 CNN\u2192 RBM.\nThe weights, \u03b1\u2019s, at every round are set to unity for all BGMs, with exceptions made in the cases of RBM\u2192 RBM (\u03b10 = 0.1, \u03b11 = 0.9) and VAE\u2192 RBM (\u03b10 = 0.3, \u03b11 = 0.7) where the tuned weights offered significant performance enhancements over the default setting. For the baseline models, we use the respective customary sampling technique, i.e., forward sampling for VAEs and blocked Gibbs sampling for RBMs. Samples from the BGMs are generated by running a Markov chain using the Metropolis-Hastings algorithm with a discrete, uniformly random proposal and the BGM distribution as the stationary distribution for the chain.\nResults and discussion. The samples generated by the baseline models and BGM models are shown in Figure 2. While BGMs significantly improve over baselines models in all cases, evaluating the relative performance of the intermediate models purely based on the samples is hard since these models have different architectures and parameter settings.\nLearning in BGMs is also computationally efficient. We show the wall-clock time taken to learn these models in Table 1. In many cases, BGMs generate significantly better looking samples with a lower training time compared to the baseline models. A key observation that emerges from the results is that discriminators are more computationally expensive since they require MCMC sampling from the previous generative model distribution as opposed to using intermediate generative models, which only require reweighting of the training set."}, {"heading": "3.3 UNSUPERVISED FEATURE LEARNING", "text": "Latent variable models are particularly attractive for unsupervised feature learning since they directly learn hidden representations that model interdependencies between the data variables. In this task, we evaluate the latent representations learned by BGMs for semi-supervised classification on the MNIST dataset consisting of 10 classes.\nSetup. We consider the same baselines as before and compare against BGM sequences that have more than a single generator. For the BGM sequences, we concatenate the parameters specifying the posterior over the latent variables (conditioned on the observed variables) in the intermediate models to form a feature representation which we then feed into a transductive-SVM. For the transductiveSVM, we use a publicly available implemention (Joachims, 1999) with a linear kernel and all other parameters set to their default values. Due to computational constraints on the classification procedure, we experiment with subsets of the training dataset and perform semi-supervised classification on a class-balanced sampling of 1,000 and 2,000 training data points varying the number of labelled instances per class from 5 to 80. The procedure is repeated 10 times for statistical significance.\nResults and discussion. The classification accuracies are show in Figure 3. We observe that BGMs closely match, and in some cases outperform the representations learned by baseline models in spite of making fewer passes over the data. A likely explanation of this phenomena is due to the fact that the learning objective for intermediate models is aware of the BGM distribution at the previous\nround, and hence, is more computationally efficient in modeling specific regions of the underlying distribution that are not covered by the BGM distribution in the previous round.\nWhile it is difficult to make general statements about the intermediate models (which are likely to be dataset specific), a surprising observation is that representations learned by the sequence VAE\u2192 CNN \u2192 RBM are weaker for classification purposes than the representations learned by a similar VAE\u2192 RBM sequence. The likely explanation for this observation is that having a generator later in the sequence offers diminishing advantage from the perspective of feature learning, assuming the previous intermediate models are making progress in modeling the underlying true distribution."}, {"heading": "4 DISCUSSION AND RELATED WORK", "text": "In this work, we revisited boosting, a meta-algorithmic framework developed in response to a seminal question posed by Kearns & Valiant (1994): can a set of weak learners create a strong learner? For the supervised learning problem, boosting has offered interesting theoretical insights into the fundamental limits of learning and led to the development of practical algorithms that work well in practice (Schapire, 1990; Freund et al., 1999; Friedman, 2002; Caruana & Niculescu-Mizil, 2006).\nThe algorithmic framework we propose in this work builds on the insights offered by prior work in boosting, yet is significantly different as the motivation is to learn generative models in unsupervised settings. In order to do so, we first defined an appropriate objective function for the generative model. We considered the standard log-loss because of its tight connections with the maximum likelihood principle. In the supervised setting, Lebanon & Lafferty (2002) have shown theoretical results connecting the log-loss for exponential families and the exponential loss minimized by AdaBoost (Freund et al., 1999). Subsequently, we showed how we can greedily optimize a factored generative model as a sequence of intermediate models. Finally, we incorporated the boosting intuition to develop an algorithmic framework where the intermediate models are tightly coupled with the previous models in the sequence and yet can be efficiently learned in practice.\nIn the context of unsupervised learning, recent advancements in deep generative models have significantly improved our ability to model high-dimensional distributions. For example, highly expressive models such as pixel-RNNs (Oord et al., 2016) and ladder networks (Rasmus et al., 2015) exhibit state-of-the-art performance in generating natural images and semi-supervised learning respectively. The flexibility in choosing intermediate models in BGMs allows for potential integration of these models in our proposed framework.\nThere has also been a renewed interest in the use of density ratios to distinguish data samples from the model samples. This unsupervised-as-supervised learning approach was first proposed by Friedman et al. (2001) and forms the basis for using binary classifiers for specifying intermediate models in Algorithm 1. The approach has subsequently been applied elsewhere, including parameter estimation in unnormalized models (Gutmann & Hyva\u0308rinen, 2010). Tu (2007)\u2019s approach for generative modeling is closely related to Algorithm 1, but fails to account for imperfections in learning of discriminative models, and the ability to incorporate generative models alongside discriminative models. Hybrid generative-discriminative classifiers have been applied to supervised settings (Truyen et al., 2006; Grabner et al., 2007; Negri et al., 2008; Ratner et al., 2016).\nRecently, the unsupervised-as-supervised learning approach has been successfully applied for sample generation in generative adversarial networks (GAN) (Goodfellow et al., 2014). GANs consist of a pair of generative-discriminative networks. While the discriminator maximizes the conditional entropy as in Eq. (3), the generator minimizes the same objective. For a parametric class of generative and discriminative networks, the stationary point is a saddle point i.e., a local minima for the generator and a local maxima for the discriminator. Accordingly, the GAN objective is not guaranteed to converge, and stable training of GANs is difficult in practice (Goodfellow, 2014). Additionally, GANs do not explicitly represent the likelihood of the generative model limiting their applicability, and Parzen window estimates of the model\u2019s log-likelihood (Breuleux et al., 2011) can be misleading (Theis et al., 2016).\nBorrowing terminology from Mohamed & Lakshminarayanan (2016), our work fits into the framework of prescribed probabilistic models that provide an explicit characterization of the loglikelihood and can still benefit from the unsupervised-as-supervised learning approach by incorporating intermediate models specified using discriminative approaches."}, {"heading": "5 CONCLUSION", "text": "We presented a general-purpose framework for boosting generative models by explicit factorization of the model likelihood as a product of simpler intermediate model distributions. These intermediate model distributions are learned greedily using discriminative or generative approaches, gradually increasing the overall model\u2019s capacity. We demonstrated the effectiveness of boosted generative models by designing ensembles of weakly trained variational autoencoders, restricted Boltzmann machines, and convolutional neural networks. Our ensembles improve upon baseline generative models on density estimation, sample generation, and unsupervised feature learning without incurring any significant computational overhead.\nAs a future work, we would like to apply our framework to more sophisticated models on complex datasets such as natural images. The optimal weighting for intermediate models also remains an open question to explore in future work. Finally, in the proposed framework, an intermediate model specified using a discriminator requires MCMC sampling from the BGM distribution at the previous round. This can be expensive, and future work could explore the design of more efficient strategies."}, {"heading": "A APPENDICES", "text": "A.1 PROOFS\nA.1.1 THEOREM 1\nProof. We first derive the sufficient condition,\n\u03b4tKL(ht, \u03b1t) = \u222b p log qt dx\u2212 \u222b p log qt\u22121 dx\n= \u222b p log\nh\u03b1tt \u00b7 qt\u22121 Zt\n\u2212 \u222b p log qt\u22121 (using Eq. (2))\n= \u03b1t \u00b7 Ep[log ht]\u2212 logEqt\u22121 [h\u03b1tt ] (6) \u2265 \u03b1t \u00b7 Ep[log ht]\u2212 logEqt\u22121 [ht]\u03b1t (Jensen\u2019s inequality) = \u03b1t \u00b7 [ Ep[log ht]\u2212 logEqt\u22121 [ht]\n] \u2265 0 (by assumption).\nNote that if \u03b1t = 1, the sufficient condition is also necessary. For the necessary condition, 0 \u2264 \u03b4tKL(ht, \u03b1t) = \u03b1t \u00b7 Ep[log ht]\u2212 logEqt\u22121 [h\u03b1tt ]\n\u2264 \u03b1t \u00b7 Ep[log ht]\u2212 Eqt\u22121 [log h\u03b1tt ] (Jensen\u2019s inequality) = \u03b1t \u00b7 [Ep[log ht]\u2212 Eqt\u22121 [log ht]] (Linearity of expectation) \u2264 Ep[log ht]\u2212 Eqt\u22121 [log ht] (since 0 \u2264 \u03b1t \u2264 1).\nA.1.2 THEOREM 2\nProof. For the proposed binary classification problem, since the m positive training examples are sampled from p and the k negative training examples are sampled from qt\u22121,\np = u(x|y = +1) u(y = +1) = m m+ k\n(7)\nqt\u22121 = u(x|y = \u22121) u(y = \u22121) = k\nm+ k . (8)\nThe Bayes optimal density d can be expressed as, dt = u(y = +1 | x) (from Definition 1) = u(x | y = +1)u(y = +1)/u(x). (9) Similarly,\n1\u2212 dt = u(x | y = \u22121)u(y = \u22121)/u(x). (10) From Eqs. (7- 10), we have,\n\u03b3 \u00b7 dt 1\u2212 dt = p qt\u22121 .\nFinally from Eq. (2), qt = qt\u22121 \u00b7 h\u03b1tt\n= p\nfinishing the proof.\nA.1.3 COROLLARY 1\nProof. For a completely adversarial classifier w.r.t. Bayes optimality, dt = u(x | y = \u22121)u(y = \u22121)/u(x) (11)\n1\u2212 dt = u(x | y = +1)u(y = +1)/u(x). (12) From Eqs. (7,8, 11,12),\nht = \u03b3 \u00b7 dt\n1\u2212 dt = qt\u22121 p .\nSubstituting the above intermediate model distribution in Eq. (6), \u03b4tKL(ht, \u03b1t) = \u03b1t \u00b7 Ep [ log\nqt\u22121 p\n] \u2212 logEqt\u22121 [ qt\u22121 p ]\u03b1t \u2264 \u03b1t \u00b7 Ep [ log\nqt\u22121 p\n] \u2212 Eqt\u22121 [ \u03b1t \u00b7 log\nqt\u22121 p\n] (Jensen\u2019s inequality)\n= \u03b1t \u00b7 [ Ep [ log\nqt\u22121 p\n] \u2212 Eqt\u22121 [ log\nqt\u22121 p\n]] (Linearity of expectation)\n= \u2212\u03b1t [DKL(p \u2016 qt\u22121) +DKL(qt\u22121 \u2016 p)] \u2264 0 (DKL is non-negative).\nBy inspection, the equality holds when \u03b1t = 0 finishing the proof.\nA.2 MODEL ARCHITECTURES AND PARAMETER SETTINGS\nThe baseline VAE model consists of a deterministic hidden layer with 500 units between the visible layer and stochastic hidden layer with 50 latent variables. The inference network specifying the posterior also contains a single deterministic layer with 500 units. The prior over the latent variables is standard Gaussian, the hidden layer activations are tanh, and learning is done using Adam (Kingma & Ba, 2015) with a learning rate of 10\u22123 and mini-batches of size 100.\nThe baseline RBM model consists of 250 hidden units trained for 50 epochs using Stochastic Gradient Descent with a learning rate of 5\u00d7 10\u22122, mini-batches of size 100, and 15 steps of contrastive divergence.\nThe CNN contains two convolutional layers and a single full connected layer with 1024 units. Convolution layers have kernel size 5\u00d75, and 32 and 64 output channels, respectively. We apply ReLUs and 2\u00d7 2 max pooling after each convolution. The net is randomly initialized prior to training, and learning is done for 2 epochs using Adam (Kingma & Ba, 2015) with a learning rate of 10\u22123 and mini-batches of size 100."}], "references": [{"title": "Quickly generating representative samples from an rbm-derived process", "author": ["Olivier Breuleux", "Yoshua Bengio", "Pascal Vincent"], "venue": "Neural Computation,", "citeRegEx": "Breuleux et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Breuleux et al\\.", "year": 2011}, {"title": "An empirical comparison of supervised learning algorithms", "author": ["Rich Caruana", "Alexandru Niculescu-Mizil"], "venue": "In ICML,", "citeRegEx": "Caruana and Niculescu.Mizil.,? \\Q2006\\E", "shortCiteRegEx": "Caruana and Niculescu.Mizil.", "year": 2006}, {"title": "A short introduction to boosting", "author": ["Yoav Freund", "Robert Schapire", "N Abe"], "venue": "Journal-Japanese Society For Artificial Intelligence,", "citeRegEx": "Freund et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Freund et al\\.", "year": 1999}, {"title": "The elements of statistical learning, volume 1. Springer series in statistics", "author": ["Jerome Friedman", "Trevor Hastie", "Robert Tibshirani"], "venue": null, "citeRegEx": "Friedman et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 2001}, {"title": "Stochastic gradient boosting", "author": ["Jerome H Friedman"], "venue": "Computational Statistics & Data Analysis,", "citeRegEx": "Friedman.,? \\Q2002\\E", "shortCiteRegEx": "Friedman.", "year": 2002}, {"title": "Generative adversarial nets", "author": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "venue": "In NIPS,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "On distinguishability criteria for estimating generative models", "author": ["Ian J Goodfellow"], "venue": "arXiv preprint arXiv:1412.6515,", "citeRegEx": "Goodfellow.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow.", "year": 2014}, {"title": "Eigenboosting: Combining discriminative and generative information", "author": ["Helmut Grabner", "Peter M Roth", "Horst Bischof"], "venue": "In CVPR,", "citeRegEx": "Grabner et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Grabner et al\\.", "year": 2007}, {"title": "Noise-contrastive estimation: A new estimation principle for unnormalized statistical models", "author": ["Michael Gutmann", "Aapo Hyv\u00e4rinen"], "venue": "In AISTATS,", "citeRegEx": "Gutmann and Hyv\u00e4rinen.,? \\Q2010\\E", "shortCiteRegEx": "Gutmann and Hyv\u00e4rinen.", "year": 2010}, {"title": "Training products of experts by minimizing contrastive divergence", "author": ["Geoffrey E Hinton"], "venue": "Neural computation,", "citeRegEx": "Hinton.,? \\Q2002\\E", "shortCiteRegEx": "Hinton.", "year": 2002}, {"title": "Transductive inference for text classification using support vector machines", "author": ["T. Joachims"], "venue": "In ICML,", "citeRegEx": "Joachims.,? \\Q1999\\E", "shortCiteRegEx": "Joachims.", "year": 1999}, {"title": "Cryptographic limitations on learning boolean formulae and finite automata", "author": ["Michael Kearns", "Leslie Valiant"], "venue": "JACM, 41(1):67\u201395,", "citeRegEx": "Kearns and Valiant.,? \\Q1994\\E", "shortCiteRegEx": "Kearns and Valiant.", "year": 1994}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba"], "venue": "In ICLR,", "citeRegEx": "Kingma and Ba.,? \\Q2015\\E", "shortCiteRegEx": "Kingma and Ba.", "year": 2015}, {"title": "Auto-encoding variational bayes", "author": ["Diederik P Kingma", "Max Welling"], "venue": "In ICLR,", "citeRegEx": "Kingma and Welling.,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Welling.", "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": "In NIPS,", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Boosting and maximum likelihood for exponential models", "author": ["Guy Lebanon", "John Lafferty"], "venue": "In NIPS,", "citeRegEx": "Lebanon and Lafferty.,? \\Q2002\\E", "shortCiteRegEx": "Lebanon and Lafferty.", "year": 2002}, {"title": "Convolutional networks for images, speech, and time series", "author": ["Yann LeCun", "Yoshua Bengio"], "venue": "The handbook of brain theory and neural networks,", "citeRegEx": "LeCun and Bengio.,? \\Q1995\\E", "shortCiteRegEx": "LeCun and Bengio.", "year": 1995}, {"title": "Mnist handwritten digit database", "author": ["Yann LeCun", "Corinna Cortes", "Christopher JC Burges"], "venue": "AT&T Labs [Online]. Available: http://yann. lecun. com/exdb/mnist,", "citeRegEx": "LeCun et al\\.,? \\Q2010\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 2010}, {"title": "Learning in implicit generative models", "author": ["Shakir Mohamed", "Balaji Lakshminarayanan"], "venue": "arXiv preprint arXiv:1610.03483,", "citeRegEx": "Mohamed and Lakshminarayanan.,? \\Q2016\\E", "shortCiteRegEx": "Mohamed and Lakshminarayanan.", "year": 2016}, {"title": "Annealed importance sampling", "author": ["Radford M Neal"], "venue": "Statistics and Computing,", "citeRegEx": "Neal.,? \\Q2001\\E", "shortCiteRegEx": "Neal.", "year": 2001}, {"title": "A cascade of boosted generative and discriminative classifiers for vehicle detection", "author": ["Pablo Negri", "Xavier Clady", "Shehzad Muhammad Hanif", "Lionel Prevost"], "venue": "EURASIP Journal on Advances in Signal Processing,", "citeRegEx": "Negri et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Negri et al\\.", "year": 2008}, {"title": "Pixel recurrent neural networks", "author": ["Aaron van den Oord", "Nal Kalchbrenner", "Koray Kavukcuoglu"], "venue": "In ICML,", "citeRegEx": "Oord et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Oord et al\\.", "year": 2016}, {"title": "Semisupervised learning with ladder networks", "author": ["Antti Rasmus", "Mathias Berglund", "Mikko Honkala", "Harri Valpola", "Tapani Raiko"], "venue": "In NIPS,", "citeRegEx": "Rasmus et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rasmus et al\\.", "year": 2015}, {"title": "Data programming: Creating large training sets, quickly", "author": ["Alexander Ratner", "Christopher De Sa", "Sen Wu", "Daniel Selsam", "Christopher R\u00e9"], "venue": null, "citeRegEx": "Ratner et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ratner et al\\.", "year": 2016}, {"title": "The strength of weak learnability", "author": ["Robert E Schapire"], "venue": "Machine learning,", "citeRegEx": "Schapire.,? \\Q1990\\E", "shortCiteRegEx": "Schapire.", "year": 1990}, {"title": "Boosting: Foundations and algorithms", "author": ["Robert E Schapire", "Yoav Freund"], "venue": "MIT press,", "citeRegEx": "Schapire and Freund.,? \\Q2012\\E", "shortCiteRegEx": "Schapire and Freund.", "year": 2012}, {"title": "Information processing in dynamical systems: Foundations of harmony theory", "author": ["Paul Smolensky"], "venue": "Technical report, DTIC Document,", "citeRegEx": "Smolensky.,? \\Q1986\\E", "shortCiteRegEx": "Smolensky.", "year": 1986}, {"title": "A note on the evaluation of generative models", "author": ["Lucas Theis", "A\u00e4ron van den Oord", "Matthias Bethge"], "venue": "In ICLR,", "citeRegEx": "Theis et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Theis et al\\.", "year": 2016}, {"title": "Adaboost. mrf: Boosted markov random forests and application to multilevel activity recognition", "author": ["Tran The Truyen", "Dinh Q Phung", "Svetha Venkatesh", "Hung Hai Bui"], "venue": "In CVPR,", "citeRegEx": "Truyen et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Truyen et al\\.", "year": 2006}, {"title": "Learning generative models via discriminative approaches", "author": ["Zhuowen Tu"], "venue": "In CVPR,", "citeRegEx": "Tu.,? \\Q2007\\E", "shortCiteRegEx": "Tu.", "year": 2007}], "referenceMentions": [{"referenceID": 26, "context": "Deep architectures, including latent variable models such as Boltzmann machines (Smolensky, 1986), variational autoencoders (Kingma & Welling, 2014), and generative adversarial networks (Goodfellow et al.", "startOffset": 80, "endOffset": 97}, {"referenceID": 5, "context": "Deep architectures, including latent variable models such as Boltzmann machines (Smolensky, 1986), variational autoencoders (Kingma & Welling, 2014), and generative adversarial networks (Goodfellow et al., 2014), have recently shown great success.", "startOffset": 186, "endOffset": 211}, {"referenceID": 2, "context": "Under some conditions on the weak classifiers\u2019 effectiveness, the boosting meta-algorithm can drive the (training) error to zero (Freund et al., 1999).", "startOffset": 129, "endOffset": 150}, {"referenceID": 14, "context": "Surprisingly, our method can even leverage discriminative models, which have been shown to perform extremely well in practice (Krizhevsky et al., 2012; LeCun et al., 2015).", "startOffset": 126, "endOffset": 171}, {"referenceID": 19, "context": "If the partition function is required, it can be estimated using techniques such as Annealed Importance Sampling (Neal, 2001).", "startOffset": 113, "endOffset": 125}, {"referenceID": 17, "context": "We consider sample generation for the binarized MNIST handwritten digits dataset (LeCun et al., 2010), which contains 50,000 train, 10,000 validation, and 10,000 test images of dimensions 28\u00d728.", "startOffset": 81, "endOffset": 101}, {"referenceID": 9, "context": "In RBMs, the log-likelihood can be tractably computed up to a normalization constant and learning is done using contrastive divergence (Hinton, 2002).", "startOffset": 135, "endOffset": 149}, {"referenceID": 10, "context": "For the transductiveSVM, we use a publicly available implemention (Joachims, 1999) with a linear kernel and all other parameters set to their default values.", "startOffset": 66, "endOffset": 82}, {"referenceID": 24, "context": "In this work, we revisited boosting, a meta-algorithmic framework developed in response to a seminal question posed by Kearns & Valiant (1994): can a set of weak learners create a strong learner? For the supervised learning problem, boosting has offered interesting theoretical insights into the fundamental limits of learning and led to the development of practical algorithms that work well in practice (Schapire, 1990; Freund et al., 1999; Friedman, 2002; Caruana & Niculescu-Mizil, 2006).", "startOffset": 405, "endOffset": 491}, {"referenceID": 2, "context": "In this work, we revisited boosting, a meta-algorithmic framework developed in response to a seminal question posed by Kearns & Valiant (1994): can a set of weak learners create a strong learner? For the supervised learning problem, boosting has offered interesting theoretical insights into the fundamental limits of learning and led to the development of practical algorithms that work well in practice (Schapire, 1990; Freund et al., 1999; Friedman, 2002; Caruana & Niculescu-Mizil, 2006).", "startOffset": 405, "endOffset": 491}, {"referenceID": 4, "context": "In this work, we revisited boosting, a meta-algorithmic framework developed in response to a seminal question posed by Kearns & Valiant (1994): can a set of weak learners create a strong learner? For the supervised learning problem, boosting has offered interesting theoretical insights into the fundamental limits of learning and led to the development of practical algorithms that work well in practice (Schapire, 1990; Freund et al., 1999; Friedman, 2002; Caruana & Niculescu-Mizil, 2006).", "startOffset": 405, "endOffset": 491}, {"referenceID": 2, "context": "In the supervised setting, Lebanon & Lafferty (2002) have shown theoretical results connecting the log-loss for exponential families and the exponential loss minimized by AdaBoost (Freund et al., 1999).", "startOffset": 180, "endOffset": 201}, {"referenceID": 21, "context": "For example, highly expressive models such as pixel-RNNs (Oord et al., 2016) and ladder networks (Rasmus et al.", "startOffset": 57, "endOffset": 76}, {"referenceID": 22, "context": ", 2016) and ladder networks (Rasmus et al., 2015) exhibit state-of-the-art performance in generating natural images and semi-supervised learning respectively.", "startOffset": 28, "endOffset": 49}, {"referenceID": 28, "context": "Hybrid generative-discriminative classifiers have been applied to supervised settings (Truyen et al., 2006; Grabner et al., 2007; Negri et al., 2008; Ratner et al., 2016).", "startOffset": 86, "endOffset": 170}, {"referenceID": 7, "context": "Hybrid generative-discriminative classifiers have been applied to supervised settings (Truyen et al., 2006; Grabner et al., 2007; Negri et al., 2008; Ratner et al., 2016).", "startOffset": 86, "endOffset": 170}, {"referenceID": 20, "context": "Hybrid generative-discriminative classifiers have been applied to supervised settings (Truyen et al., 2006; Grabner et al., 2007; Negri et al., 2008; Ratner et al., 2016).", "startOffset": 86, "endOffset": 170}, {"referenceID": 23, "context": "Hybrid generative-discriminative classifiers have been applied to supervised settings (Truyen et al., 2006; Grabner et al., 2007; Negri et al., 2008; Ratner et al., 2016).", "startOffset": 86, "endOffset": 170}, {"referenceID": 5, "context": "Recently, the unsupervised-as-supervised learning approach has been successfully applied for sample generation in generative adversarial networks (GAN) (Goodfellow et al., 2014).", "startOffset": 152, "endOffset": 177}, {"referenceID": 6, "context": "Accordingly, the GAN objective is not guaranteed to converge, and stable training of GANs is difficult in practice (Goodfellow, 2014).", "startOffset": 115, "endOffset": 133}, {"referenceID": 0, "context": "Additionally, GANs do not explicitly represent the likelihood of the generative model limiting their applicability, and Parzen window estimates of the model\u2019s log-likelihood (Breuleux et al., 2011) can be misleading (Theis et al.", "startOffset": 174, "endOffset": 197}], "year": 2017, "abstractText": "We propose a new approach for using boosting to create an ensemble of generative models, where models are trained in sequence to correct earlier mistakes. Our algorithm can leverage many existing base learners, including recent latent variable models. Further, our approach allows the ensemble to leverage discriminative models trained to distinguish real from synthetic data during sample generation. We show theoretical conditions under which incorporating a new model to the ensemble will improve the fit and empirically demonstrate the effectiveness of boosting on density estimation, sample generation, and unsupervised feature learning on real and synthetic datasets.", "creator": "LaTeX with hyperref package"}, "id": "ICLR_2017_268"}