{"name": "ICLR_2017_317.pdf", "metadata": {"source": "CRF", "title": "RECURRENT RECOMMENDER NETWORKS", "authors": ["Chao-Yuan Wu", "Alex Beutel"], "emails": ["cywu@cs.utexas.edu", "amra@google.com", "alexbeutel@google.com", "alex@smola.org"], "sections": [{"heading": "1 INTRODUCTION", "text": "Designing highly accurate recommender systems has been the focus of research in many communities and at the center of many products for the past decade. The core goal is to predict which items a given user will like or dislike, typically based on a database of previous ratings and reviews. In particular, a good recommender system has been defined as one that predicts the rating for randomly chosen and unseen (user,item) pairs. During the Netflix Prize contest, a variety of factorization models were proposed to capture the latent embeddings of users and items that would lead to accurate recommendations (Bell & Koren, 2007; Koren et al., 2009). Generative models for personalized ratings have recently become popular, due to impressive and robust results (Mnih & Salakhutdinov, 2007; Salakhutdinov & Mnih, 2008; Stern et al., 2009; Beutel et al., 2015).\nMore recently, there has been an interest in the recommender system community to also make use of the rich natural language reviews provided by users. Most often, these reviews have been transformed into a bag-of-words-model and used as a sort of regularization for the rating predictions (McAuley & Leskovec, 2013; Diao et al., 2014; Almahairi et al., 2015; Wu et al., 2016b). Using reviews in this way has been found to improve prediction accuracy, and in some cases provide detailed explanations for the recommendations.\nThis previous research has been remarkably successful, but has two significant limitations that we discuss and address in this paper. First, prediction accuracy has rarely been measured by the ability of a model to predict future ratings. Rather, recommendation accuracy has been derived from a random split of the ratings data, which undermines our understanding of the models\u2019 usefulness in practice. Here, we focus on predicting future ratings, splitting our training and testing data by date. In order to be successful at this task, we incorporate the time of ratings and reviews in our model structure and training. Koren (2010) previously derived temporal features of ratings data, but used these features to remove temporal effects since the metric of success was interpolation, not extrapolation. More recently, Recurrent Recommender Networks (RNN) use a recurrent neural network to capture changes\n\u2217A majority of this work was done while the author was at Carnegie Mellon University.\nin both user preferences and item perceptions, and extrapolate future ratings in an autoregressive way (Wu et al., 2016a). However, temporal patterns in reviews are largely unexplored. Note that just like ratings, reviews also depend on changing factors, such as user writing styles, user preferences, movie perceptions, or the popularity of certain slang words or emoticons. Here we use a generative LSTM model that is able to jointly model the temporal effects in ratings and reviews.\nSecond, models of reviews in recommender system fall significantly behind the state-of-the-art in natural language processing. The bag-of-words model used in previous research improves over not using text, but is limited in the degree to which it can understand the review. In fact, the drawback of an underfitting model is especially salient in the case of reviews, because they are much more diverse and unstructured than regular documents. Recently there has been significant research attention on modeling natural language with neural networks, with encouraging results (Lipton et al., 2015; Yang et al., 2016). Here, we combine these powerful neural-based language models with recurrent neural network to learn both accurate recommendations and accurate reviews. Our main contributions are as follows:\n\u2022 Joint generative model: We propose a novel joint model of ratings and reviews via interacting recurrent networks (particularly LSTM).\n\u2022 Nonlinear nonparametric review model: By learning a function of user and movie state dynamics, we can capture the evolution of reviews (as well as ratings) over time.\n\u2022 Experiments show that by jointly modeling ratings and reviews along with temporal patterns, our model achieves state-of-the-art results on IMDb dataset in terms of forward prediction, i.e. in the realistic scenario where we use only ratings strictly prior to prediction time to predict future ratings."}, {"heading": "2 RELATED WORK", "text": "Collaborative Filtering As mentioned in the introduction, recommender systems have been the focus of many different research communities. The Netflix Prize generated a flurry of research to improve recommendation accuracy, with a variety of matrix factorization models being proposed (Bell & Koren, 2007; Koren et al., 2009; Koren, 2008). During the Netflix competition and more afterwards, a stream of research has focused on designing generative Bayesian models for user ratings data (Mnih & Salakhutdinov, 2007; Salakhutdinov & Mnih, 2008; Stern et al., 2009; Beutel et al., 2014; 2015). Nearly all of these models predict ratings by an inner product between a latent user embedding and a latent item embedding; different approaches primarily regularization, e.g., Bayesian models and learning algorithms capture uncertainty in the data.\nOther models have tried to capture interesting patterns discovered in ratings data. As an example, Beutel et al. (2014) finds that some ratings form bimodal rather than Gaussian distributions and designs a model to accommodate this diversity. More closely related to this work, Koren (2010) designs many features to capture and remove the temporal effects in ratings data. By removing these temporal effects, Koren (2010) learns better stationary embeddings for users and items. Work such as this improves prediction accuracy, but has two drawbacks: (1) it requires time consuming feature engineering, and (2) it focuses on interpolation rather than extrapolation into the future. Wu et al. (2016a) addresses both of these concerns by learning a function for the evolution of user preferences and item properties. However, this work focuses exclusively on modeling ratings over time and, in a large part, on the qualitative patterns discovered in the Netflix dataset. Here we focus on the model itself and, in particular, the interaction of jointly understanding ratings, reviews, and temporal patterns.\nReview Modeling Although the most common metric for recommendation accuracy has been rating prediction, natural language reviews provide rich, detailed insight into user preferences. Most often, reviews have been used in a bag-of-words model to regularize rating prediction (McAuley & Leskovec, 2013; Diao et al., 2014; Wu et al., 2016b). For example, McAuley & Leskovec (2013) effectively learns a topic model of reviews regularize item embeddings. By using such coarse models, the impact of and insight from reviews is limited. More recently, Almahairi et al. (2015) use neural network based review models to regularize hidden factors, but their model assumes only stationary states.\nInterestingly, data mining research has found that review patterns are dynamic, with different language being adopted by communities over time (Danescu-Niculescu-Mizil et al., 2013). Therefore, it is important to capture not just the dynamics of ratings, but also the language used to justify those ratings.\nNeural Networks Neural networks have recently offered large improvements in natural language processing. More recently, a few papers have focused these natural language models on online reviews (Lipton et al., 2015; Yang et al., 2016). However, while these papers do model online reviews, they differ greatly from our work in that they are not actually used for recommendation.\nWith the recent remarkable successes of neural networks in other domains, there has been growing attention on using neural networks for model graphs and ratings data. Most similar, Sedhain et al. (2015) design an autoencoder for collaborative filtering.\nLSTM and Recurrent Network Recurrent neural network provides a powerful tool to nonparametrically model temporal data by using a latent variable autoregressive model as follows:\nz\u0302t+1 = f(ht, zt) and ht+1 = g(ht, zt+1).\nWhere zt is the observation at time t, z\u0302t is the model associated estimate, and ht denotes the latent state. A popular class of RNN is the Long Short Term Memory (LSTM) (Hochreiter & Schmidhuber, 1997) and we use this as a building block in our model .The state updates is given below:\n[ft, it, ot] = \u03c3 [W [ht\u22121, zt] + b] (1) lt = tanh [V [ht\u22121, zt] + d] (2) ct = ft \u00b7 ct\u22121 + it \u00b7 lt (3) ht = ot \u00b7 tanh(ct), (4)\nwhere ft, it, ot denote the forget gate, input gate and the output gate respectively. For simplicity in the following we denote this set of operations by ht = LSTM(ht\u22121, zt). We will refer to ht as the output embedding from the LSTM."}, {"heading": "3 MODEL", "text": "A comparison of our model with traditional recommender systems is illustrated in Figure 1. In previous recommender systems, ratings are assumed to be a function of stationary user and movie embeddings. Here we consider dynamic embeddings that predict both ratings and text reviews at a given time step.\nFigure 2 shows a depiction of our model: Joint Review-Rating Recurrent Recommender Network. In addition to stationary embeddings as used in traditional recommender systems, here we use two\nLSTM RNNs that take user/movie history as input to capture the temporal dynamics in both user and movie states. Given stationary and dynamic states of user i and movie j, we define generator functions that emit both rating rij |t and reviews oij |t at time step t. Formally,\nrij |t = f(ui,mj , uit,mjt) and oij |t = \u03c8(ui,mj , uit,mjt) ui,t+1 = g(uit, {rij |t}) and mj,t+1 = h(mjt, {rij |t}),\nwhere ui and mj denote stationary states, and uit and mit denote the dynamic state at t. Note that with learned f, \u03c8, g and h and given user/movie history, an user/movie state can be inferred without further optimization. In other words, different from traditional recommender systems, here we learn the functions that find the states instead of learning the states directly."}, {"heading": "3.1 DYNAMIC USER AND MOVIE STATE", "text": "Here we give a detailed description on the RNNs that find the dynamic states. The key idea is to use user/movie rating history as inputs to update the states. In this way we are able to model causality instead of just finding correlation. That is, we can model e.g. the change of user (movie) state caused by having watched and liked/disliked a movie (being liked/disliked by certain users). At each step, the network takes\nyt :=Wembed [xt, 1newbie, \u03c4t, \u03c4t\u22121] , (5)\nwhere xt is the rating vector, 1newbie is the indicator for new users, and \u03c4t is wall-clock time. The jth element of xt is the rating the user gives for movie j at time t, and 0 otherwise. 1newbie effectively select a default embedding for a new user, and \u03c4t and \u03c4t\u22121 gives the model the information to synchronize between RNNs and model the effects such as rating scale change or movie age. Note that with the inclusion of \u03c4s, we do not need to include the steps where a user did not rate any movie, and this can drastically speed up training. The state update is given by standard ut := LSTM(ut\u22121, yt). In the above we omit user index for clarity. In cases where we need to distinguish different users (and movies) such as in Figure 2, we use additional index i for user i as in uit, and similarly for movie j in mjt."}, {"heading": "3.2 RATING EMISSIONS", "text": "We supplement the time-varying profile vectors uit and mjt with stationary ones ui and mj respectively. These stationary components encode time-invariant properties such as long-term preference of a user or the genre of a movie.\nThe review rating is thus modeled as a function of both dynamic and stationary states, i.e.\nrij = f(uit,mjt, ui,mj) := \u3008u\u0303it, m\u0303jt\u3009+ \u3008ui,mj\u3009 (6)\nwhere u\u0303it and m\u0303jt are affine functions of uit and mjt respectively. That is, we have\nu\u0303it =Wuseruit + buser and m\u0303jt =Wmoviemjt + bmovie\nThis makes the model a strict superset of popular matrix factorization recommender systems that accounts for stationary effects, while we use LSTMs, on top of that, to model longer-range dynamic updates."}, {"heading": "3.3 REVIEW TEXT MODEL", "text": "Review text is modeled by a character-level LSTM network. This network shares the same user/movie latent states with the rating model. After all, the purpose of a review is to explain its rating score. We fuse the stationary and dynamic states of both user of movie by the bottleneck layer xjoint,ij given below:\nxjoint,ij := \u03c6(Wjoint [uit,mjt, ui,mj ] + bjoint) (7) x\u0303ij,k := [ xoij,k , xjoint,ij ] (8)\nwhere oij,k denotes the character at position k for the review given by user i to movie j, and xoij,k denotes the embedding of the character. \u03c6 here is some non-linear function.\nThe review text emission model is itself an RNN, specifically a character-level LSTM generative model. For character index k = 1, 2, . . . ,\nhij,k := LSTM(hij,k\u22121, x\u0303ij,k) (9) o\u0302ij,k := softmax (Wouthij,k + bout) (10)\nHere a softmax layer at output of LSTM is used to predict the next character. Generating text conditioned on contents has been applied to various areas, such as machine translation (Sutskever et al., 2014), question answering (Gao et al., 2015), or image captioning (Vinyals et al., 2015). Probably the most similar approach is Lipton et al. (2015), but it conditions review generation on observed ratings instead of latent states."}, {"heading": "3.4 PREDICTION", "text": "In prediction time, we make rating predictions based on predicted future states. That is, we take the latest ratings as input to update the states, and use the newly predicted states to predict ratings. This differs from traditional approaches where embeddings are estimated instead of inferred."}, {"heading": "3.5 TRAINING", "text": "Our goal is to predict both accurate ratings and accurate reviews, and thus we minimize\nL := \u2211\n(i,j)\u2208Dtrain\n[ (r\u0302ij(\u03b8)\u2212 rij)2 \u2212 \u03bb\nnij\u2211 k=1 log (Pr(oij,k|\u03b8))\n] , (11)\nwhere Dtrain is the training set of (i, j) pairs, \u03b8 denotes all model parameters, and nij is the number of characters in the review user i gives to movie j. The first term corresponds to the deviation of the prediction from the actual rating, and the second term is the likelihood of the text reviews. \u03bb controls the weight between predicting accurate ratings and predicting accurate reviews. Our training follows the subspace descent strategy in Wu et al. (2016a). That is, while the review generative model is updated in every iteration, the user-state and movie-state RNNs are updated in an alternating way.\nThe gradients are calculated with standard backpropagation. Furthermore, we pre-warm train the review LSTM over the review text excluding the auxiliary input from the user and movie states. It is undesirable if the review likelihood overwhelms the rating. We hence normalize review likelihood by the number of characters in a review so that it does not dominates the rating likelihood. This technique is common in NLP literature (Wang & McCallum, 2006)."}, {"heading": "4 EXPERIMENTS", "text": "In this section we empirically demonstrate the ability of our model to accurately predict both ratings and reviews, and capture temporal dynamics."}, {"heading": "4.1 EXPERIMENTAL SETUP", "text": "In the following experiments, we select hyperparameters, optimization parameters and model architecture by cross-validation. The details are as follows. We use 1-layer LSTM recurrent neural networks with 40 hidden factors for user/movie state transitions. The input of this LSTM is an user/item embedding of dimension 40. Stationary and dynamic factors are 160 and 40-dimensional respectively. A 2-layer LSTM network is used to model texts, which takes 30-dimensional character embedding xchar, 40-dimensional state vector xjoint, and a 50-dimensional movie embedding xmovie.\nTo speed up convergence, we initialize the text model by a character-level RNN pre-trained without considering rating. Stationary factors are initialized by a pre-trained iAutoRec (Sedhain et al., 2015) model based on the last layer. We initialize all the other parameters from uniform distribution between [\u2212a, a] with a = \u221a 1.5(fin + fout), where fin and fout are fan-in and fan-out of transition matrices. `2 regularization with magnitude 0.001 is applied to all parameters. Dropout with a 0.5 rate is applied after all fully-connected layers. To prevent exploding gradients in of LSTM, gradients are clipped to [\u221215, 15]. ADAM (Kingma & Ba, 2014) with learning rate 0.0015 is used for optimization.\nData Here we focus on movie recommendations, where the opinions are highly dynamic. We evaluate our model on IMDb dataset, first used in Diao et al. (2014), that is the only large-scale movie\nreview dataset available. Restaurant recommendations (e.g. Yelp) could be also a suitable domain, but full rating history is not available in publicly available datasets1.\nThe IMDb dataset contains full review and rating history of all users and all movies from 1998 to 2013. The characteristics of this dataset is shown in Figure 3. We see that the user and movie ratings follow heavy tail distributions, and thus the majority of users and movies have very few reviews, making accurate recommendation challenging for these users and movies. Review length is summarized in Figure 3 (c). Since one of the major goal of this project is to study temporal dynamics, we focus on users and items that have multiple interactions with the system. Specifically, we select a subset of k-core of the graph with k = 15. That is, each user and movie has at least 15 ratings in this subset. Note that the resulting subgraph is still very sparse \u2013 with only 0.8% density, which is sparser than for example, 1.2 % density of Netflix dataset . For completeness, we also include the 6-month Netflix dataset as used in Wu et al. (2016a), which has only ratings, to study RRN\u2019s ability to model temporal patterns.\nThe dataset is split by date instead of random sampling to simulate the real recommendation settings where we need to predict into the future instead of interpolating the past. IMDb training set contains all ratings from July 1998 to December 2012, and the ratings from January to September 2013 are randomly split into a validation set and a test set. Similarly, the 6-month Netflix dataset is split into January to November 2011 (training) and December 2011 (testing and validation). We report the results on testing set with the model that gives the best results on validation set. The summary of this dataset is given in Table 1.\nBaselines We compare our model with models including the state-of-the-art temporal model, and a state-of-the-art neural network-based model.\n\u2022 PMF (Mnih & Salakhutdinov, 2007): Our model extends matrix factorization by including a dynamic part and a joint review model. Comparing to PMF directly shows us the advantage of our approaches. LIBPMF (Yu et al., 2012) is used in experiments.\n\u2022 Time-SVD++ (Koren, 2010): Time-SVD++ is the state-of-the-art model for temporal effects. It achieves excellent performance in Netflix contest. Implementation in GraphChi (Kyrola et al., 2012) is used in experiments.\n\u2022 AutoRec (Sedhain et al., 2015): AutoRec is the state-of-the-art neural network recommender system. It learns an autoencoder that encodes user (item) histories into a lowdimensional space and then predict ratings by decoding. No temporal effects or causality are considered in this model. We use the software the authors provide in experiments.\nAll models use comparable number of factor sizes. Parameters of PMF and Time-SVD++ are selected by grid-search. Settings of AutoRec follow the original paper. We also include the performance of rating-only RRN, as in Wu et al. (2016a), to separate the benefits obtained from temporal modeling and review texts."}, {"heading": "4.2 RATING PREDICTION", "text": "One important goal of recommender systems is making accurate rating predictions. Here we evaluate the accuracy by root-mean-square error (RMSE) of prediction from the true rating. The results are summarized in Table 2. For completeness, we include the results from Wu et al. (2016a) on\n1 https://www.yelp.com/dataset_challenge\n6-month Netflix dataset that use ratings only to compare the behavior of different models on different datasets. We see that rating-only RRN outperforms all baseline models in terms of rating prediction consistently in both dataset. More importantly, joint-modeling ratings and reviews boosts the performance even more, compared to rating-only RRN. This implies that by sharing statistical strength between ratings and reviews, the rich information in reviews helps us estimate the latent factors better. Note that while the absolute improvements in RMSE might not appear to be huge, the 1.98% improvement over PMF is actually considerable in terms of recommendations2. We also see that while Time-SVD++ performs well in Netflix contest, it does not work as well for predicting future ratings. After all, the goal of Time-SVD++ is estimating the temporal bias in hindsight instead of extrapolating into future states."}, {"heading": "4.3 TEXT MODELING", "text": "Here we examine the impact of conditioning on user and item states for text modeling. Towards this end, we compare perplexity of characters in testing set with and without using the user/item factors. Perplexity is defined as\nppx(Dtest) = exp ( \u2212 1 Nc \u2211 c\u2208Dtest log Pr(c) ) ,\nwhere Nc is the total number of characters in Dtest, and Pr(c) is the likelihood of character c. Interestingly, we found that by jointly training with user and item states, the perplexity improves from 3.3442 to 3.3362."}, {"heading": "4.4 TEMPORAL DYNAMICS", "text": "Here we study if RRN is able to automatically capture the overall rating trends in IMDb by adaptively updating states along history sequence. Specifically, at each time step, we randomly sample up to 1000 users, and see what ratings the users would have given to each of the movie given their states at the time step, even in reality the user might not have given a rating to the movie. This gives us an unbiased estimation of average behavior of our model on each of the ratings. Figure 4 shows the average predicted ratings in this setting and the true average rating in the data set. We see that RRN clearly captures the overall trend in IMDb smoothly."}, {"heading": "5 DISCUSSION & CONCLUSION", "text": "We present a novel approach that jointly models ratings, reviews, and their temporal dynamics with RRN. The contributions we have provided are as follows:\n2For example, in 2009 SVD++ outperforms SVD by 1.09% and Time-SVD++ outperforms SVD++ by 1.25%, and they are considered important progress in recommender systems.\n1. Joint rating-review modeling: We offer an LSTM-based joint rating-review model that provides advantages in both rating prediction and text modeling.\n2. Nonparametric dynamic review modeling: RRN is based on an autoregressive method to model temporal dynamics of users and movies, allowing us to capture how reviews change over time.\n3. Empirical results: We demonstrate that our joint model offers state-of-the-art results on rating prediction in real recommendation settings, i.e. predicting into the future."}], "references": [{"title": "Learning distributed representations from reviews for collaborative filtering", "author": ["Amjad Almahairi", "Kyle Kastner", "Kyunghyun Cho", "Aaron Courville"], "venue": "In Proceedings of the 9th ACM Conference on Recommender Systems,", "citeRegEx": "Almahairi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Almahairi et al\\.", "year": 2015}, {"title": "Lessons from the netflix prize challenge", "author": ["R.M. Bell", "Y. Koren"], "venue": "SIGKDD Explorations,", "citeRegEx": "Bell and Koren.,? \\Q2007\\E", "shortCiteRegEx": "Bell and Koren.", "year": 2007}, {"title": "Cobafi: collaborative bayesian filtering", "author": ["Alex Beutel", "Kenton Murray", "Christos Faloutsos", "Alexander J Smola"], "venue": "In WWW,", "citeRegEx": "Beutel et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Beutel et al\\.", "year": 2014}, {"title": "ACCAMS: Additive Co-Clustering to Approximate Matrices Succinctly", "author": ["Alex Beutel", "Amr Ahmed", "Alexander J Smola"], "venue": "In WWW,", "citeRegEx": "Beutel et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Beutel et al\\.", "year": 2015}, {"title": "No country for old members: User lifecycle and linguistic change in online communities", "author": ["Cristian Danescu-Niculescu-Mizil", "Robert West", "Dan Jurafsky", "Jure Leskovec", "Christopher Potts"], "venue": "In WWW,", "citeRegEx": "Danescu.Niculescu.Mizil et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Danescu.Niculescu.Mizil et al\\.", "year": 2013}, {"title": "Jointly modeling aspects, ratings and sentiments for movie recommendation (jmars)", "author": ["Qiming Diao", "Minghui Qiu", "Chao-Yuan Wu", "Alexander J Smola", "Jing Jiang", "Chong Wang"], "venue": "In KDD. ACM,", "citeRegEx": "Diao et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Diao et al\\.", "year": 2014}, {"title": "Are you talking to a machine? dataset and methods for multilingual image question answering", "author": ["Haoyuan Gao", "Junhua Mao", "Jie Zhou", "Zhiheng Huang", "Lei Wang", "Wei Xu"], "venue": "In NIPS,", "citeRegEx": "Gao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gao et al\\.", "year": 2015}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter and Schmidhuber.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma and Ba.,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Factorization meets the neighborhood: a multifaceted collaborative filtering model", "author": ["Y. Koren"], "venue": "In KDD,", "citeRegEx": "Koren.,? \\Q2008\\E", "shortCiteRegEx": "Koren.", "year": 2008}, {"title": "Matrix factorization techniques for recommender systems", "author": ["Y. Koren", "R.M. Bell", "C. Volinsky"], "venue": "IEEE Computer,", "citeRegEx": "Koren et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Koren et al\\.", "year": 2009}, {"title": "Collaborative filtering with temporal dynamics", "author": ["Yehuda Koren"], "venue": "Communications of the ACM,", "citeRegEx": "Koren.,? \\Q2010\\E", "shortCiteRegEx": "Koren.", "year": 2010}, {"title": "Graphchi: Large-scale graph computation on just a pc", "author": ["Aapo Kyrola", "Guy Blelloch", "Carlos Guestrin"], "venue": "In OSDI,", "citeRegEx": "Kyrola et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kyrola et al\\.", "year": 2012}, {"title": "Capturing meaning in product reviews with character-level generative text models", "author": ["Zachary Chase Lipton", "Sharad Vikram", "Julian McAuley"], "venue": null, "citeRegEx": "Lipton et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lipton et al\\.", "year": 2015}, {"title": "Hidden Factors and Hidden Topics: Understanding Rating Dimensions with Review Text", "author": ["J. McAuley", "J. Leskovec"], "venue": "In RecSys,", "citeRegEx": "McAuley and Leskovec.,? \\Q2013\\E", "shortCiteRegEx": "McAuley and Leskovec.", "year": 2013}, {"title": "Probabilistic matrix factorization", "author": ["Andriy Mnih", "Ruslan Salakhutdinov"], "venue": "In NIPS,", "citeRegEx": "Mnih and Salakhutdinov.,? \\Q2007\\E", "shortCiteRegEx": "Mnih and Salakhutdinov.", "year": 2007}, {"title": "Bayesian probabilistic matrix factorization using markov chain monte carlo", "author": ["R. Salakhutdinov", "A. Mnih"], "venue": null, "citeRegEx": "Salakhutdinov and Mnih.,? \\Q2008\\E", "shortCiteRegEx": "Salakhutdinov and Mnih.", "year": 2008}, {"title": "Autorec: Autoencoders meet collaborative filtering", "author": ["Suvash Sedhain", "Aditya Krishna Menon", "Scott Sanner", "Lexing Xie"], "venue": "In WWW Companion,", "citeRegEx": "Sedhain et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sedhain et al\\.", "year": 2015}, {"title": "Matchbox: large scale online bayesian recommendations", "author": ["David H Stern", "Ralf Herbrich", "Thore Graepel"], "venue": "In WWW. ACM,", "citeRegEx": "Stern et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Stern et al\\.", "year": 2009}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le"], "venue": "In NIPS,", "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Show and tell: A neural image caption generator", "author": ["Oriol Vinyals", "Alexander Toshev", "Samy Bengio", "Dumitru Erhan"], "venue": "In CVPR,", "citeRegEx": "Vinyals et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "Topics over time: a non-markov continuous-time model of topical trends", "author": ["Xuerui Wang", "Andrew McCallum"], "venue": "In KDD. ACM,", "citeRegEx": "Wang and McCallum.,? \\Q2006\\E", "shortCiteRegEx": "Wang and McCallum.", "year": 2006}, {"title": "Recurrent recommender networks. In Web Science and Data Mining (WSDM), 2016a", "author": ["C.-Y. Wu", "A. Beutel", "A. Ahmed", "A.J. Smola", "H. Jing"], "venue": null, "citeRegEx": "Wu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2016}, {"title": "Explaining reviews and ratings with PACO: poisson additive co-clustering", "author": ["Chao-Yuan Wu", "Alex Beutel", "Amr Ahmed", "Alexander J. Smola"], "venue": "In WWW Companion,", "citeRegEx": "Wu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2016}, {"title": "Hierarchical attention networks for document classification", "author": ["Zichao Yang", "Diyi Yang", "Chris Dyer", "Xiaodong He", "Alexander J. Smola", "Eduard Hovy"], "venue": null, "citeRegEx": "Yang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2016}, {"title": "Scalable coordinate descent approaches to parallel matrix factorization for recommender systems", "author": ["Hsiang-Fu Yu", "Cho-Jui Hsieh", "Si Si", "Inderjit S. Dhillon"], "venue": "In ICDM,", "citeRegEx": "Yu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 10, "context": "During the Netflix Prize contest, a variety of factorization models were proposed to capture the latent embeddings of users and items that would lead to accurate recommendations (Bell & Koren, 2007; Koren et al., 2009).", "startOffset": 178, "endOffset": 218}, {"referenceID": 18, "context": "Generative models for personalized ratings have recently become popular, due to impressive and robust results (Mnih & Salakhutdinov, 2007; Salakhutdinov & Mnih, 2008; Stern et al., 2009; Beutel et al., 2015).", "startOffset": 110, "endOffset": 207}, {"referenceID": 3, "context": "Generative models for personalized ratings have recently become popular, due to impressive and robust results (Mnih & Salakhutdinov, 2007; Salakhutdinov & Mnih, 2008; Stern et al., 2009; Beutel et al., 2015).", "startOffset": 110, "endOffset": 207}, {"referenceID": 5, "context": "Most often, these reviews have been transformed into a bag-of-words-model and used as a sort of regularization for the rating predictions (McAuley & Leskovec, 2013; Diao et al., 2014; Almahairi et al., 2015; Wu et al., 2016b).", "startOffset": 138, "endOffset": 225}, {"referenceID": 0, "context": "Most often, these reviews have been transformed into a bag-of-words-model and used as a sort of regularization for the rating predictions (McAuley & Leskovec, 2013; Diao et al., 2014; Almahairi et al., 2015; Wu et al., 2016b).", "startOffset": 138, "endOffset": 225}, {"referenceID": 13, "context": "Recently there has been significant research attention on modeling natural language with neural networks, with encouraging results (Lipton et al., 2015; Yang et al., 2016).", "startOffset": 131, "endOffset": 171}, {"referenceID": 24, "context": "Recently there has been significant research attention on modeling natural language with neural networks, with encouraging results (Lipton et al., 2015; Yang et al., 2016).", "startOffset": 131, "endOffset": 171}, {"referenceID": 10, "context": "The Netflix Prize generated a flurry of research to improve recommendation accuracy, with a variety of matrix factorization models being proposed (Bell & Koren, 2007; Koren et al., 2009; Koren, 2008).", "startOffset": 146, "endOffset": 199}, {"referenceID": 9, "context": "The Netflix Prize generated a flurry of research to improve recommendation accuracy, with a variety of matrix factorization models being proposed (Bell & Koren, 2007; Koren et al., 2009; Koren, 2008).", "startOffset": 146, "endOffset": 199}, {"referenceID": 18, "context": "During the Netflix competition and more afterwards, a stream of research has focused on designing generative Bayesian models for user ratings data (Mnih & Salakhutdinov, 2007; Salakhutdinov & Mnih, 2008; Stern et al., 2009; Beutel et al., 2014; 2015).", "startOffset": 147, "endOffset": 250}, {"referenceID": 2, "context": "During the Netflix competition and more afterwards, a stream of research has focused on designing generative Bayesian models for user ratings data (Mnih & Salakhutdinov, 2007; Salakhutdinov & Mnih, 2008; Stern et al., 2009; Beutel et al., 2014; 2015).", "startOffset": 147, "endOffset": 250}, {"referenceID": 5, "context": "Most often, reviews have been used in a bag-of-words model to regularize rating prediction (McAuley & Leskovec, 2013; Diao et al., 2014; Wu et al., 2016b).", "startOffset": 91, "endOffset": 154}, {"referenceID": 4, "context": "Interestingly, data mining research has found that review patterns are dynamic, with different language being adopted by communities over time (Danescu-Niculescu-Mizil et al., 2013).", "startOffset": 143, "endOffset": 181}, {"referenceID": 13, "context": "More recently, a few papers have focused these natural language models on online reviews (Lipton et al., 2015; Yang et al., 2016).", "startOffset": 89, "endOffset": 129}, {"referenceID": 24, "context": "More recently, a few papers have focused these natural language models on online reviews (Lipton et al., 2015; Yang et al., 2016).", "startOffset": 89, "endOffset": 129}, {"referenceID": 19, "context": "Generating text conditioned on contents has been applied to various areas, such as machine translation (Sutskever et al., 2014), question answering (Gao et al.", "startOffset": 103, "endOffset": 127}, {"referenceID": 6, "context": ", 2014), question answering (Gao et al., 2015), or image captioning (Vinyals et al.", "startOffset": 28, "endOffset": 46}, {"referenceID": 17, "context": "Stationary factors are initialized by a pre-trained iAutoRec (Sedhain et al., 2015) model based on the last layer.", "startOffset": 61, "endOffset": 83}, {"referenceID": 11, "context": "\u2022 Time-SVD++ (Koren, 2010): Time-SVD++ is the state-of-the-art model for temporal effects.", "startOffset": 13, "endOffset": 26}, {"referenceID": 12, "context": "Implementation in GraphChi (Kyrola et al., 2012) is used in experiments.", "startOffset": 27, "endOffset": 48}, {"referenceID": 17, "context": "\u2022 AutoRec (Sedhain et al., 2015): AutoRec is the state-of-the-art neural network recommender system.", "startOffset": 10, "endOffset": 32}], "year": 2016, "abstractText": "Accurate modeling of ratings and text reviews is at the core of successful recommender systems. While neural networks have been remarkably successful in modeling images and natural language, they have been largely unexplored in recommender system research. In this paper, we provide a neural network model that combines ratings, reviews, and temporal patterns to learn highly accurate recommendations. We co-train for prediction on both numerical ratings and natural language reviews, as well as using a recurrent architecture to capture the dynamic components of users\u2019 and items\u2019 states. We demonstrate that incorporating text reviews and temporal dynamic gives state-of-the-art results over the IMDb dataset.", "creator": "LaTeX with hyperref package"}, "id": "ICLR_2017_317"}