{"name": "ICLR_2017_421.pdf", "metadata": {"source": "CRF", "title": "REPRESENTING INFERENTIAL UNCERTAINTY IN DEEP NEURAL NETWORKS THROUGH SAMPLING", "authors": ["Patrick McClure", "Nikolaus Kriegeskorte"], "emails": ["patrick.mcclure@mrc-cbu.cam.ac.uk", "nikolaus.kriegeskorte@mrc-cbu.cam.ac.uk"], "sections": [{"heading": "1 INTRODUCTION", "text": "Deep neural networks (DNNs), particularly convolutional neural networks (CNN), have recently been used to solve complex perceptual and decision tasks (Krizhevsky et al., 2012; Mnih et al., 2015; Silver et al., 2016). However, these networks fail to model the uncertainty of their predictions or actions. Although many networks deterministically map an input to a probabilistic prediction, they do not model the uncertainty of that mapping. In contrast, Bayesian neural networks (NNs) attempt to learn a distribution over their parameters thereby offering uncertainty estimates for their outputs (MacKay, 1992; Neal, 2012). However, these methods do not scale well due to the difficulty in computing the posterior of a network\u2019s parameters.\nOne type of method for sampling from the posteriors of these networks is Hamiltonian Monte Carlo (HMC) (Neal, 2012). These techniques use the gradient information calculated using backpropagation to perform Markov chain Monte Carlo (MCMC) sampling by randomly walking through parameter space. proposed stochastic gadient Langevien dynamcis (SGLD)\nApproximate methods, in particular variational inference, have been used to make Bayesian NNs more tractable (Hinton & Van Camp, 1993; Barber & Bishop, 1998; Graves, 2011; Blundell et al., 2015). Due in large part to the fact that these methods substantially increase the number of parameters in a network, they have not been applied to large DNNs, such as CNNs. Gal & Ghahramani\n(2016) and Kingma et al. (2015) bypassed this issue by developing Bayesian CNNs using dropout (Srivastava et al., 2014). Dropout is a widely used regularization technique where units are dropped out of a network with a probability p during training and the output of all unit are multiplied by p during inference. A similar technique is dropconnect (Wan et al., 2013), which drops network connections instead of units. Gal & Ghahramani (2015) detailed how dropping units was equivalent to sampling weights from a Bernoulli-based variational distribution and that in order to make a DNN with dropout Bayesian, sampling should be used during both training and inference. Monte-Carlo (MC) sampling at inference allows a DNN to efficiently model a distribution over its outputs. One limitation of the Bayesian dropout method is that it does not model the uncertatiniy of each network parameter. The uncertainty of a DNN can then be calculated using this probability distribution. In addition to Bernoulli and Gaussian distributions, there has also been work done using spike-anslab distributions (Louizos, 2015), a combination of the two, which has been shown to increase the quality of linear regression (Ishwaran & Rao, 2005). Interestingly, dropout and dropconnect can be seen as approximations to spike-and-slab distributions for units and weights, respectively (Louizos, 2015; Gal, 2016; Li et al., 2016). Dropout- and dropconnect-based variational DNNs are dependent on the dropout probability, which is often used as a hyperparameter. However, work has been done on automatically learning the dropout probability during training for dropconnect (Louizos, 2015) using spike-and-slab distributions and Gaussian dropout (Kingma et al., 2015).\nIn this paper, we investigate how using MC sampling to model uncertainty affects a network\u2019s probabilistic predictions. Specifically, we test if using MC sampling improves the calibration of the probabilistic predictions made by Bayesian DNNs with softmax output layers. We used variational distributions based on dropout and dropconnect with either Bernoulli or Gaussian sampling during both training and inference. Additonally, we propose a formulation of a spike-and-slab variational distribution based on Bernoulli dropout and Gaussian dropconnect. We find that the spike-and-slab networks robustly represented their uncertainty like Bayesian dropconnect networks and have the increased CNN classification accuracy of Bayesian dropout networks. Each of these variational distributions scale extremely well and make the results of this work applicable to a large range of state-of-the-art DNNs."}, {"heading": "2 METHODS", "text": ""}, {"heading": "2.1 BAYESIAN NEURAL NETWORKS", "text": "Artificial neural networks (NNs) can be trained using Bayesian learning by finding the maximum a posteriori (MAP) weights given the training data (Dtrain) and a prior over the weight matrix W (p(W )):\nmax W p(W |Dtrain) = max W p(Dtrain|W )p(W ) (1)\nThis is usually done by minimizing the mean squared error (MSE) or cross entropy error for either regression or classification, respectively, while using L2 regularization, which corresponds to a Gaussian prior over the weights. At inference, the probability of the test data (Dtest) is then calculated using only the maximum likelihood estimate (MLE) of the weights (W \u2217):\np(Dtest|W \u2217) (2)\nHowever, ideally the full posterior distribution over the weights would be learned instead of just the MLE:\np(W |Dtrain) = p(Dtrain|W )p(W )\np(Dtrain) (3)\nThis can be intractable due to both the difficulty in calculating p(Dtrain) and in calculating the joint distribution of a large number of parameters. Instead, p(W |Dtrain) can be approximated using a variational distribution q(W ). This distribution is constructed to allow for easy generation of samples. Using variational inference, q(W ) is learned by minimizing:\n\u2212 \u222b log p(Dtrain|W )q(W )dW +KL(q(W )||p(W )) (4)\nMonte-Carlo (MC) sampling can then be used to estimate the probability of test data using q(W ):"}, {"heading": "2.2 VARIATIONAL DISTRIBUTIONS", "text": "The number and continuous nature of the parameters in DNNs makes sampling from the entire distribution of possible weight matrices computationally challenging. However, variational distributions can make sampling easier. In deep learning, the most common sampling method is dropout with Bernoulli variables. However, dropconnect, which independently samples a Bernoulli for each weight, and Gaussian weights have also been used. A visualization of the different methods is shown in Figure 1. All of these methods can be formulated as variational distributions where weights are sampled by element-wise multiplying the variational parameters V , the n \u00d7 n connection matrix with an element for each connection between the n units in the network, by a mask M\u0302 , which is sampled from some probability distribution. Mathematically, this can be written as:\nW\u0302 = V \u25e6 M\u0302 where M\u0302 \u223c p(M) (6)\nFrom this perspective, the difference between dropout and dropconnect, as well as Bernoulli and Gaussian methods, is simply the probability distribution used to generate the mask sample, M\u0302 (Figure 2)."}, {"heading": "2.2.1 BERNOULLI DROPCONNECT & DROPOUT", "text": "Bernoulli distributions are simple distributions which return 1 with probability p and 0 with probability (1 \u2212 p). In Bernoulli dropconnect, each element of the mask is sampled independently, so m\u0302i,j \u223c Bernoulli(p). This sets w\u0302i,j to vi,j with probability p and 0 with a probability (1 \u2212 p).\nIn dropout, however, the weights are not sampled independently. Instead, one Bernoulli variable is sampled for each row of the weight matrix, so m\u0302i,\u2217 \u223c Bernoulli(p)."}, {"heading": "2.2.2 GAUSSIAN DROPCONNECT & DROPOUT", "text": "In Gaussian dropconnect and dropout, the elements of the mask are sampled from normal distributions. This corresponds to sampling w\u0302i,j from a Gaussian distribution centered at variational parameter vi,j . Srivastava et al. (2014) proposed using Gaussian distribution with a mean of 1 and a variance of \u03c32dc = (1 \u2212 p)/p, which matches the mean and variance of dropout when training time scaling is used. In Gaussian dropconnect, each element of the mask is sampled independently, which results in m\u0302i,j \u223c N (1, \u03c32dc). In Gaussian dropout, each element in a row has the same random variable, so m\u0302i,\u2217 \u223c N (1, \u03c32dc)."}, {"heading": "2.2.3 SPIKE-AND-SLAB DROPOUT", "text": "A spike-and-slab distribution is the normalized linear combination of a \u201dspike\u201d of probability mass at zero and a \u201dslab\u201d consisting of a Gaussian distribution. This spike-and-slab returns a 0 with probability pspike or a random sample from a Gaussian distribution N (\u00b5slab, \u03c32slab). We propose concurrently using Bernoulli dropout and Gaussian dropconnect to approximate the use of a spikeand-slab variational distribution by optimizing a lower-bound of the objective function (See Appendix A). In this formulation, mi,j \u223c bi,\u2217N (1, \u03c32dc), where bi,\u2217 \u223c Bern(pdo) for each mask row and \u03c32dc = pdc/(1 \u2212 pdc). As for Bernoulli dropout, each row of the mask M , mi,\u2217, is multiplied by 0 with probability (1 \u2212 pdo), otherwise each element in that row is multiplied by a value independently sampled from a Gaussian distribution as in Gaussian dropconnect. During non-sampling inference, spike-and-slab dropout uses the mean weight values and, per Bernoulli dropout, multiplies unit outputs by pdo. This differs from the work done by Louizos (2015) and Gal (2016) in that they used additive Gaussian noise and learn separate means and variances for each weight. In contrast, we define the variance as a function of the learned weight mean vi,j . Tying the variance of a weight to its magnitude makes it only beneficial to learn large weights if they are robust to variance (Wang & Manning, 2013). Although we treat pdo and pdc as a hyperparameters thereby reducing the space of variational distributions we optimize over, similar methods could potentially learn these during training (Louizos, 2015; Kingma et al., 2015; Gal, 2016)."}, {"heading": "3 RESULTS", "text": "In this paper, we investigate how using MC sampling affects a DNN\u2019s ability to represent the uncertainty of it\u2019s probabalistic predictions. To test this, we trained several networks differing only in whether no sampling was performed (baseline DNN and DNN with L2-regularization), sampling was only performed during training (dropout and dropconnect), or sampling was performed both during training and inference (MC dropout and MC dropconnect). We used the MNIST and CIFAR10 datasets to train networks that sampled from different variational distribution using the above methods.\nFor these DNNs, we compared the test classification error, the uncertainty of the softmax output, and the calibration of the softmax output for each type of sampling and variational distribution. The test classification error shows how well the probability distribution learned by each DNN models\nthe data. The uncertainty shows how the probability distribution learned by each DNN is distributed across classes. A low entropy means that the probability mass is primarily located at a few labels and a high entropy means that the probability mass is distributed across many labels. The calibration shows how well the probability distribution learned by the DNN models it\u2019s own uncertainty. We evaluated how calibrated a prediction was by the following procedure: (1) We binned test set predictions by predicted probability. (2) We calculated the percentage of predictions in each predicted-probability bin that correctly predicted a target label. Perfect calibration means that targets predicted with probability z are correct in z times 100% of the cases. We therefore (3) calculated the mean squared calibration error (i.e. the mean across bins of the squared deviations between the bin-mean predicted probability and the proportion of correct predictions in that bin). We evaluated\nthese three measures for the trained networks on the MNIST and CIFAR test set with noise sampled from Gaussian distributions with varying standard deviations (Figure 3). This tested how well modelled each network\u2019s uncertainty was for the test sets and the regions of input space not seen in the training set. For dropout and dropconnect, p was set to 0.5, which corresponds to the best value for regularizing a linear layer Baldi & Sadowski (2013). However in practice, different values for p have been used Srivastava et al. (2014). We found that 0.5 was a robust choice for different networks, measures and sampling methods we used. The one exception were the dropconnect parameter used for spike-and-slab distributions where 0.5 made learning difficult due to the variance during training. Through validation, we found that using larger values spike-and-slab probabilities (0.75 for the fully connected and 0.9 for the convolutional) allowed the networks to fit to the training data better while still maintaining good generalization."}, {"heading": "3.1 MNIST", "text": "We trained two groups of DNNs, one with a fully connected (FC) architecture and one with a convolutional architecture, on digit classification using the MNIST dataset (LeCun et al., 1998). This set contains 60,000 training images and 10,000 testing images. No data augmentation was used."}, {"heading": "3.1.1 FULLY CONNECTED NEURAL NETWORKS", "text": "First, we trained DNNs with two FC hidden layers, each with 800 units and ReLU non-linearities. For the L2-regularized network, an L2-coefficient of 1e-5 was used for all weights. For the dropout methods, unit sampling was performed after each FC layer. For the dropconnect methods, every weight was sampled. The classification errors of the FC networks on the MNIST test set are shown in Table 1. Sampling during learning significantly increased accuracy in comparison to the baseline NNs, with the dropconnect-based networks being the most accurate. MC sampling at inference did not significantly increase accuracy. We found that Gaussian dropconnect and spike-and-slab dropout had the best accuracy.\nThe classification error, uncertainty, and calibration of the learned probability distributions of each FC network for varying levels of noise are shown in Figure 4. While not improving accuracy, MC sampling led to networks that better represent their own uncertainty. As the noise in the test set was increased, the uncertainty of the networks with MC sampling highly increased, especially when compared to networks with no sampling at inference. This resulted in better calibrated FC networks for all levels of noise.\nThe calibration curves show that sampling only during training, especially when using only dropout, led to overconfidence through placing too much probability mass on the most predicted label (Figure 5). In particular, sampling only during training resulted in under-confidence for low predicted probabilities and over-confidence for high predicted probabilities. By distributing probability mass over several labels, the DNNs that sampled at inference better represented the uncertainty of their predictions."}, {"heading": "3.1.2 CONVOLUTIONAL NEURAL NETWORKS", "text": "We also trained CNNs on MNIST. Every network had two convolutional layers and a fully-connected layer (See Appendix B for details). For the L2-regularized network, an L2-coefficient of 1e-5 was used for all weights. For Bernoulli and Gaussian dropout, dropout was performed after each convolutional layer and after the FC layer. For Bernoulli and Gaussian dropconnect, every weight was sampled. The classification error of the CNNs on the MNIST test set is shown in Table 2. Sampling during training significantly increased the accuracy for the all of the networks, but especially for the Gaussian dropout network. However, unlike for the FC networks, the dropout-based methods were more accurate than the dropconnect-based methods. Unlike for the FC networks, spike-and-slab had\naccuracies more similar to Bernoulli dropout, which classified more accurately than Gaussian dropconnect. MC sampling during inference did not significantly increase the accuracy of the networks.\nThe classification error, uncertainty, and calibration of the learned probability distributions of each network for varying levels of noise are shown in Figure 6. As with the FC networks, MC sampling at inference greatly increased the CNNs\u2019 ability to estimate their own uncertainty, particularly for inputs that are different from the training set. MC sampling led to increased entropy as inputs became more noisy, which resulted in better calibration. In particular, this was true of both the Bernoulli and Gaussian dropconnect networks, which very accurately represented their uncertainty even for highly noisy inputs. The spike-and-slab CNN had similar robust calibration. The calibration curves show that not using MC sampling at inference led networks that were under-confident when making low probability predictions and over-confident when making high probability predictions (Figure 7)."}, {"heading": "3.2 CIFAR-10", "text": "We trained large CNNs on natural image classification using the CIFAR-10 dataset, which contains 50,000 training images and 10,000 testing images (Krizhevsky & Hinton, 2009). The CNNs had 13 convolutional layer followed by a fully connected layer (See Appendix B for details). For L2regularization, an L2-coefficient of 5e-4 was used for all weights. For the dropout networks, was used after each convolutional layer, but before the non-linearities. For the dropconnect networks, all weights were sampled. During training, random horizontal flipping was used. The classification error of the CNNs on the CIFAR-10 test set is shown in Table 3. For each variational distribution, MC sampling significantly increased test accuracy. Also, the that used dropout, including spike-andslab, had significantly higher accuracies than the networks that only used dropconnect.\nThe classification error, uncertainty, and calibration of the learned probability distributions of each network for varying levels of noise are shown in Figure 8. One of the major differences between the CIFAR-10 and the MNIST results was that using the layer-wise expectation for dropout did not produce good models, regardless of what variational distribution was used. Instead, the standard test time dropout methods led to relatively inaccurate networks with very high output entropy even when\nno input noise was used. This agrees with the results reported by Gal & Ghahramani (2015)), who also found that using dropout at every layer can reduce accuracy if MC sampling is not used. However, these results differ from those of Srivastava et al. (2014). In our experience, deeper networks with higher regularization (e.g. Bernoulli dropout probabilities closer to 0.5) result in traditional dropout inference performing significantly worse than MC dropout. As for the MNIST networks, MC sampling at inference overall greatly increased the CIFAR-10 trained CNNs\u2019 ability to estimate their own uncertainty when no or little noise was added to the test images.\nThe classification accuracies and the ability to model uncertainty of the networks with dropconnect sampling were far more robust to noise than the networks with only dropout. However, the MC dropconnect networks are significantly less accurate than the MC dropout networks for the CIFAR-\n10 test set when no noise was added. Networks that used traditional dropout inference instead of sampling were consistently uncertain, regardless of the noise. These networks have worse calibration than the MC dropout networks at low levels of noise but better calibration than the MC dropout networks at low levels of noise because they always had high uncertainty. For CIFAR-10, not using MC sampling resulted in networks that were generally over-confident when making predictions (Figure 9). However, this was not true for the non-sampling dropout networks when no input noise was used. In that case, the networks were highly under-confident."}, {"heading": "4 DISCUSSION", "text": "In this paper, we investigated the ability of MC sampling to improve a DNN\u2019s representation of its own uncertainty. We did this by training Bayesian DNNs with either multiplicative masking of the weights (dropconnect) or units (dropout) using Bernoulli, Gaussian, or spike-and-slab sampling. Based on the results, we draw the following main conclusions:\n1. Sampling during both learning and inference improved a network\u2019s ability to represent its own uncertainty\nMC sampling at inference improved the calibration of a network\u2019s predictions. Overall, this improvement was particularly large for inputs from outside the training set, which traditional models classified with high confidence despite not being trained on similar inputs.\n2. Sampling weights independently led to networks that best represented their own uncertainty\nFor all the network architectures and datasets tested, using dropconnect sampling at training and inference resulted in the best calibrated networks overall. This was true regardless of whether dropconnect sampling led to the most accurate network. This is in contrast to CNNs with Gaussian dropout sampling, which were significantly the most accurate and also the worst calibrated of the networks with sampling both during training an inference\n3. Sampling weights independently led to the most accurate FC networks, but sampling units led to the most accurate CNNs\nFor the FC networks, using dropconnect, particularly with Gaussian sampling, resulted in the most accurate networks. However, using dropout led to the most accurate CNNs. A potential cause of this is the large correlation in the information contained by adjacent elements in an image, which are often covered by the same convolutional kernel. This could mean that sampling the weights of a kernel does not provide as much regularization as the dropout methods.\n4. Sampling using both Bernoulli dropout and Gaussian dropconnect led to accurate and well calibrated networks\nUsing spike-and-slab dropout, which combines Bernoulli dropout and Gaussian dropconnect, resulted in networks that performed well for all architectures. Spike-and-slab networks had accuracies similar to the Bernoulli dropout or Gaussian dropconnect depending on which performed better for a given architecture and task, Gaussian dropconnect for FC networks and Bernoulli dropout for CNNs. Spike-and-slab networks also were robustly well calibrated similar to all of the other dropconnect methods.\nThese scalable methods for improving a network\u2019s representation of its own uncertainty are widely applicable, since most DNNs already use dropout and getting uncertainty estimates only requires using MC sampling at inference. We plan to further investigate the use of different variational distributions. We also plan to evaluate the use of dropout and dropconnect sampling on large recurrent neural networks. Our results suggest that sampling at inference allows DNNs to efficiently represent their own uncertainty, an essential part of real-world perception and decision making."}, {"heading": "ACKNOWLEDGMENTS", "text": "We would like to thank Yarin Gal and Sergii Strelchuk for their helpful discussions regarding the manuscript. This research was funded by the Cambridge Commonwealth, European & International Trust, the UK Medical Research Council (Program MC-A060-5PR20), and a European Research Council Starting Grant (ERC-2010-StG 261352)."}, {"heading": "A DERIVATION OF APPROXIMATE SPIKE-AND-SLAB DROPOUT", "text": "For Bayesian inference: p(Dtest|Dtrain) = \u222b p(Dtest|W )p(W |Dtrain)dW (A.1)\nUsing variational inference:\np(Dtest) = \u222b p(Dtest|W )q(W )dW (A.2)\nWhere the variational distribution q(W ) is learned by maximizing the log-evidence lower bound: log(p(Dtrain)) \u2265 \u222b log(p(Dtrain|W ))q(W )dW \u2212KL(q(W )||p(W )) (A.3)\nFor spike-and-slab dropout, as when using Bernoulli dropout, W = B \u25e6V where bi,\u2217 \u223c Bern(pdo), so if we assume independence between the random variables B and V :\nlog(p(Dtrain)) \u2265 \u2211 B \u222b V log(p(Dtrain|B, V ))q(B)q(V )dV dB\n\u2212KL(q(B)||p(B))\u2212KL(q(V )||p(V )) (A.4)\nFor a spike-and-slab distribution, each element of V is independently sampled from a Gaussian distribution, N (\u00b5vi,j , \u03c32vi,j ). As in Gaussian dropconnect, \u03c3 2 vi,j = \u03b1\u00b5 2 vi,j . V can be sampled using the \u201creparameterization trick\u201d:\nvi,j = N(\u00b5vi,j , \u03b1\u00b5 2 vi,j ) = g(\u00b5vi,j , i,j) = \u00b5vi,j + \u221a \u03b1\u00b5vi,j i,j (A.5)\nwhere \u223c N(0, 1), \u03b1 = (1\u2212 pdc)/pdc, and pdc is the dropconnect keep probability.\nThis leads to:\nlog(p(Dtrain)) \u2265 \u2211 B\n\u222b\nlog(p(Dtrain|B, V )q( )q(B)d dB\n\u2212KL(q(B)||p(B))\u2212KL(q(V )||p(V )) (A.6)\nThis results in the following minimization objective function: L\u00b5V := \u2212 \u2211 B\n\u222b\nlog(p(Dtrain|B, V ))q( )q(B)d dB +KL(q(B)||p(B)) +KL(q(V )||p(V )\n(A.7) Using Bern(pdo) as a prior for B leads to a constant KLD of zero. Using a prior of N (0, \u03c32p) for each element of V leads to the following:\nKL(q(vi,j)||p(vi,j)) = (\u00b5vi,j \u2212 0)2\n2\u03c32p + log \u03c3p \u03c3vi,j + \u03c32vi,j 2\u03c32p \u2212 1 2\n(A.8)\nBy using L2 regularization, we are optimizing a lower-bound of the KLD between q(V ) and N (0, \u03bb\u22121) by only matching the first moment (i.e. the mean):\nL\u00b5V \u2265 L\u0303\u00b5V := \u2212 \u2211 B\n\u222b\nlog(p(Dtrain|B, V ))q( )q(B)d dB + \u03bb\n2 \u00b5V \u00b5\n\u1d40 V (A.9)\nwhere \u00b5V is a vector containing each \u00b5vi,j and is a vector containing each i,j .\nApproximating using Monte Carlo integration for learning (Eq. A.10) and inference (Eq. A.11):\nL\u0303\u00b5V :\u2248 \u2212 1\nn \u2211 (B, ) log(p(Dtrain|B, V )) + \u03bb 2 \u00b5V \u00b5 \u1d40 V (A.10)\np(Dtest) \u2248 1\nn \u2211 (B, ) p(Dtest|B, V ) (A.11)\nwhere bi,\u2217 \u223c Bern(pdo) and \u223c N(0, 1)."}, {"heading": "B CONVOLUTIONAL NEURAL NETWORK ARCHITECTURES", "text": "B.1 MNIST"}], "references": [{"title": "Understanding dropout", "author": ["Pierre Baldi", "Peter J Sadowski"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Baldi and Sadowski.,? \\Q2013\\E", "shortCiteRegEx": "Baldi and Sadowski.", "year": 2013}, {"title": "Ensemble learning in bayesian neural networks", "author": ["David Barber", "Christopher M Bishop"], "venue": "NATO ASI SERIES F COMPUTER AND SYSTEMS SCIENCES,", "citeRegEx": "Barber and Bishop.,? \\Q1998\\E", "shortCiteRegEx": "Barber and Bishop.", "year": 1998}, {"title": "Weight uncertainty in neural network", "author": ["Charles Blundell", "Julien Cornebise", "Koray Kavukcuoglu", "Daan Wierstra"], "venue": "In Proceedings of The 32nd International Conference on Machine Learning,", "citeRegEx": "Blundell et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Blundell et al\\.", "year": 2015}, {"title": "Uncertainty in Deep Learning", "author": ["Yarin Gal"], "venue": "PhD thesis, University of Cambridge,", "citeRegEx": "Gal.,? \\Q2016\\E", "shortCiteRegEx": "Gal.", "year": 2016}, {"title": "Dropout as a bayesian approximation: Insights and applications", "author": ["Yarin Gal", "Zoubin Ghahramani"], "venue": "In Deep Learning Workshop,", "citeRegEx": "Gal and Ghahramani.,? \\Q2015\\E", "shortCiteRegEx": "Gal and Ghahramani.", "year": 2015}, {"title": "Bayesian convolutional neural networks with Bernoulli approximate variational inference", "author": ["Yarin Gal", "Zoubin Ghahramani"], "venue": "In 4th International Conference on Learning Representations (ICLR) workshop track,", "citeRegEx": "Gal and Ghahramani.,? \\Q2016\\E", "shortCiteRegEx": "Gal and Ghahramani.", "year": 2016}, {"title": "Practical variational inference for neural networks", "author": ["Alex Graves"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Graves.,? \\Q2011\\E", "shortCiteRegEx": "Graves.", "year": 2011}, {"title": "Keeping the neural networks simple by minimizing the description length of the weights", "author": ["Geoffrey E Hinton", "Drew Van Camp"], "venue": "In Proceedings of the sixth annual conference on Computational learning theory,", "citeRegEx": "Hinton and Camp.,? \\Q1993\\E", "shortCiteRegEx": "Hinton and Camp.", "year": 1993}, {"title": "Spike and slab variable selection: frequentist and bayesian strategies", "author": ["Hemant Ishwaran", "J Sunil Rao"], "venue": "Annals of Statistics,", "citeRegEx": "Ishwaran and Rao.,? \\Q2005\\E", "shortCiteRegEx": "Ishwaran and Rao.", "year": 2005}, {"title": "Variational dropout and the local reparameterization trick", "author": ["Diederik P Kingma", "Tim Salimans", "Max Welling"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Kingma et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2015}, {"title": "Learning multiple layers of features from tiny", "author": ["Alex Krizhevsky", "Geoffrey Hinton"], "venue": null, "citeRegEx": "Krizhevsky and Hinton.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky and Hinton.", "year": 2009}, {"title": "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Gradient-based learning applied to document recognition", "author": ["Yann LeCun", "L\u00e9on Bottou", "Yoshua Bengio", "Patrick Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Learning weight uncertainty with stochastic gradient mcmc for shape classification", "author": ["Chunyuan Li", "Andrew Stevens", "Changyou Chen", "Yunchen Pu", "Zhe Gan", "Lawrence Carin"], "venue": "In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Li et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Smart regularization of deep architectures", "author": ["Christos Louizos"], "venue": "Master\u2019s thesis, University of Amsterdam,", "citeRegEx": "Louizos.,? \\Q2015\\E", "shortCiteRegEx": "Louizos.", "year": 2015}, {"title": "A practical bayesian framework for backpropagation networks", "author": ["David JC MacKay"], "venue": "Neural computation,", "citeRegEx": "MacKay.,? \\Q1992\\E", "shortCiteRegEx": "MacKay.", "year": 1992}, {"title": "Human-level control through deep reinforcement learning", "author": ["Volodymyr Mnih", "Koray Kavukcuoglu", "David Silver", "Andrei A Rusu", "Joel Veness", "Marc G Bellemare", "Alex Graves", "Martin Riedmiller", "Andreas K Fidjeland", "Georg Ostrovski"], "venue": "Nature, 518(7540):529\u2013533,", "citeRegEx": "Mnih et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2015}, {"title": "Bayesian learning for neural networks, volume 118", "author": ["Radford M Neal"], "venue": "Springer Science & Business Media,", "citeRegEx": "Neal.,? \\Q2012\\E", "shortCiteRegEx": "Neal.", "year": 2012}, {"title": "Mastering the game of go with deep neural networks and tree", "author": ["David Silver", "Aja Huang", "Chris J Maddison", "Arthur Guez", "Laurent Sifre", "George Van Den Driessche", "Julian Schrittwieser", "Ioannis Antonoglou", "Veda Panneershelvam", "Marc Lanctot"], "venue": "search. Nature,", "citeRegEx": "Silver et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Silver et al\\.", "year": 2016}, {"title": "Dropout: a simple way to prevent neural networks from overfitting", "author": ["Nitish Srivastava", "Geoffrey E Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Srivastava et al\\.,? \\Q1929\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 1929}, {"title": "Regularization of neural networks using dropconnect", "author": ["Li Wan", "Matthew Zeiler", "Sixin Zhang", "Yann L Cun", "Rob Fergus"], "venue": "In Proceedings of the 30th International Conference on Machine Learning", "citeRegEx": "Wan et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wan et al\\.", "year": 2013}, {"title": "Fast dropout training", "author": ["Sida Wang", "Christopher Manning"], "venue": "In Proceedings of the 30th International Conference on Machine Learning (ICML),", "citeRegEx": "Wang and Manning.,? \\Q2013\\E", "shortCiteRegEx": "Wang and Manning.", "year": 2013}], "referenceMentions": [{"referenceID": 11, "context": "1 INTRODUCTION Deep neural networks (DNNs), particularly convolutional neural networks (CNN), have recently been used to solve complex perceptual and decision tasks (Krizhevsky et al., 2012; Mnih et al., 2015; Silver et al., 2016).", "startOffset": 165, "endOffset": 230}, {"referenceID": 16, "context": "1 INTRODUCTION Deep neural networks (DNNs), particularly convolutional neural networks (CNN), have recently been used to solve complex perceptual and decision tasks (Krizhevsky et al., 2012; Mnih et al., 2015; Silver et al., 2016).", "startOffset": 165, "endOffset": 230}, {"referenceID": 18, "context": "1 INTRODUCTION Deep neural networks (DNNs), particularly convolutional neural networks (CNN), have recently been used to solve complex perceptual and decision tasks (Krizhevsky et al., 2012; Mnih et al., 2015; Silver et al., 2016).", "startOffset": 165, "endOffset": 230}, {"referenceID": 15, "context": "In contrast, Bayesian neural networks (NNs) attempt to learn a distribution over their parameters thereby offering uncertainty estimates for their outputs (MacKay, 1992; Neal, 2012).", "startOffset": 155, "endOffset": 181}, {"referenceID": 17, "context": "In contrast, Bayesian neural networks (NNs) attempt to learn a distribution over their parameters thereby offering uncertainty estimates for their outputs (MacKay, 1992; Neal, 2012).", "startOffset": 155, "endOffset": 181}, {"referenceID": 17, "context": "One type of method for sampling from the posteriors of these networks is Hamiltonian Monte Carlo (HMC) (Neal, 2012).", "startOffset": 103, "endOffset": 115}, {"referenceID": 6, "context": "proposed stochastic gadient Langevien dynamcis (SGLD) Approximate methods, in particular variational inference, have been used to make Bayesian NNs more tractable (Hinton & Van Camp, 1993; Barber & Bishop, 1998; Graves, 2011; Blundell et al., 2015).", "startOffset": 163, "endOffset": 248}, {"referenceID": 2, "context": "proposed stochastic gadient Langevien dynamcis (SGLD) Approximate methods, in particular variational inference, have been used to make Bayesian NNs more tractable (Hinton & Van Camp, 1993; Barber & Bishop, 1998; Graves, 2011; Blundell et al., 2015).", "startOffset": 163, "endOffset": 248}, {"referenceID": 20, "context": "A similar technique is dropconnect (Wan et al., 2013), which drops network connections instead of units.", "startOffset": 35, "endOffset": 53}, {"referenceID": 14, "context": "In addition to Bernoulli and Gaussian distributions, there has also been work done using spike-anslab distributions (Louizos, 2015), a combination of the two, which has been shown to increase the quality of linear regression (Ishwaran & Rao, 2005).", "startOffset": 116, "endOffset": 131}, {"referenceID": 14, "context": "Interestingly, dropout and dropconnect can be seen as approximations to spike-and-slab distributions for units and weights, respectively (Louizos, 2015; Gal, 2016; Li et al., 2016).", "startOffset": 137, "endOffset": 180}, {"referenceID": 3, "context": "Interestingly, dropout and dropconnect can be seen as approximations to spike-and-slab distributions for units and weights, respectively (Louizos, 2015; Gal, 2016; Li et al., 2016).", "startOffset": 137, "endOffset": 180}, {"referenceID": 13, "context": "Interestingly, dropout and dropconnect can be seen as approximations to spike-and-slab distributions for units and weights, respectively (Louizos, 2015; Gal, 2016; Li et al., 2016).", "startOffset": 137, "endOffset": 180}, {"referenceID": 14, "context": "However, work has been done on automatically learning the dropout probability during training for dropconnect (Louizos, 2015) using spike-and-slab distributions and Gaussian dropout (Kingma et al.", "startOffset": 110, "endOffset": 125}, {"referenceID": 9, "context": "However, work has been done on automatically learning the dropout probability during training for dropconnect (Louizos, 2015) using spike-and-slab distributions and Gaussian dropout (Kingma et al., 2015).", "startOffset": 182, "endOffset": 203}, {"referenceID": 14, "context": "Although we treat pdo and pdc as a hyperparameters thereby reducing the space of variational distributions we optimize over, similar methods could potentially learn these during training (Louizos, 2015; Kingma et al., 2015; Gal, 2016).", "startOffset": 187, "endOffset": 234}, {"referenceID": 9, "context": "Although we treat pdo and pdc as a hyperparameters thereby reducing the space of variational distributions we optimize over, similar methods could potentially learn these during training (Louizos, 2015; Kingma et al., 2015; Gal, 2016).", "startOffset": 187, "endOffset": 234}, {"referenceID": 3, "context": "Although we treat pdo and pdc as a hyperparameters thereby reducing the space of variational distributions we optimize over, similar methods could potentially learn these during training (Louizos, 2015; Kingma et al., 2015; Gal, 2016).", "startOffset": 187, "endOffset": 234}, {"referenceID": 12, "context": "1 MNIST We trained two groups of DNNs, one with a fully connected (FC) architecture and one with a convolutional architecture, on digit classification using the MNIST dataset (LeCun et al., 1998).", "startOffset": 175, "endOffset": 195}], "year": 2017, "abstractText": "As deep neural networks (DNNs) are applied to increasingly challenging problems, they will need to be able to represent their own uncertainty. Modelling uncertainty is one of the key features of Bayesian methods. Bayesian DNNs that use dropout-based variational distributions and scale to complex tasks have recently been proposed. We evaluate Bayesian DNNs trained with Bernoulli or Gaussian multiplicative masking of either the units (dropout) or the weights (dropconnect). We compare these Bayesian DNNs ability to represent their uncertainty about their outputs through sampling during inference. We tested the calibration of these Bayesian fully connected and convolutional DNNs on two visual inference tasks (MNIST and CIFAR-10). By adding different levels of Gaussian noise to the test images in z-score space, we assessed how these DNNs represented their uncertainty about regions of input space not covered by the training set. These Bayesian DNNs represented their own uncertainty more accurately than traditional DNNs with a softmax output. We find that sampling of weights, whether Gaussian or Bernoulli, led to more accurate representation of uncertainty compared to sampling of units. However, sampling units using either Gaussian or Bernoulli dropout led to increased convolutional neural network (CNN) classification accuracy. Based on these findings we use both Bernoulli dropout and Gaussian dropconnect concurrently, which approximates the use of a spike-andslab variational distribution. We find that networks with spike-and-slab sampling combine the advantages of the other methods: they classify with high accuracy and robustly represent the uncertainty of their classifications for all tested architectures.", "creator": "LaTeX with hyperref package"}, "id": "ICLR_2017_421"}