{"name": "ICLR_2017_424.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["STOP READING", "IN MA", "CHINE COMPREHENSION", "Yelong Shen", "Po-Sen Huang", "Jianfeng Gao", "Weizhu Chen"], "emails": ["yeshen@microsoft.com", "pshuang@microsoft.com", "jfgao@microsoft.com", "wzchen@microsoft.com"], "sections": [{"heading": "1 INTRODUCTION", "text": "Teaching machines to read, process, and comprehend natural language documents is a coveted goal for artificial intelligence (Bottou, 2014; Richardson et al., 2013; Hermann et al., 2015). Genuine reading comprehension is extremely challenging, since effective comprehension involves thorough understanding of documents and performing sophisticated inference. Toward solving this machine reading comprehension problem, in recent years, several work has collected various datasets, in the form of question, passage, and answer, to test machine on answering a question based on the provided passage (Richardson et al., 2013; Hermann et al., 2015; Hill et al., 2016; Rajpurkar et al., 2016). Some large-scale cloze-style datasets (Hermann et al., 2015; Hill et al., 2016) have gained significant attention along with powerful deep learning models.\nRecent approaches on cloze-style datasets can be separated into two categories: single-turn and multiturn reasoning. Single turn reasoning models utilize attention mechanisms (Bahdanau et al., 2015) with deep learning models to emphasize specific parts of the document which are relevant to the query. These attention models subsequently calculate the relevance between a query and the corresponding weighted representations of document subunits (e.g. sentences or words) to score target candidates (Hill et al., 2016; Hermann et al., 2015; Kadlec et al., 2016). However, considering the sophistication of the problem, after a single-turn comprehension, readers often revisit some specific passage or the question to grasp a better understanding of the problem. With this motivation, recent advances in reading comprehension have made use of multiple turns to infer the relation between query, document and answer (Hill et al., 2016; Dhingra et al., 2016; Trischler et al., 2016; Sordoni et al., 2016). By repeatedly processing the document and question after digesting intermediate information, multi-turn reasoning can generally produce a better answer and all existing work has demonstrated its superior performance consistently.\nExisting multi-turn models have a fixed number of hops or iterations in their inference, i.e., with predetermined reasoning depth, without regard to the complexity of each individual query or document. However, when a human reads a document with a question in mind, we often decide whether we want to stop reading if we believe the observed information is adequate already to answer the question, or continue reading after digesting intermediate information until we can answer the question with confidence. This behavior generally varies from document to document, or question to question\nbecause it is related to the sophistication of the document or the difficulty of the question. Meanwhile, the analysis in Chen et al. (2016) also illustrates the huge variations in the difficulty level with respect to questions in the CNN/Daily Mail datasets (Hermann et al., 2015). For a significant part of the datasets, this analysis shows that the problem cannot be solved without appropriate reasoning on both its query and document.\nWith this motivation, we propose a novel neural network architecture called Reasoning Network (ReasoNet). ReasoNets try to mimic the inference process of human readers. With a question in mind, ReasoNets read a document repeatedly, each time focusing on different parts of the document until a satisfying answer is found or formed. This reminds us of a Chinese proverb: \u201cThe meaning of a book will become clear if you read it hundreds of times.\u201d. Moreover, unlike previous approaches using fixed number of hops or iterations, ReasoNets introduce a termination state in the inference. This state can decide whether to continue the inference to next turn after digesting intermediate information, or to terminate the whole inference when it concludes that existing information is sufficient to yield an answer. This number of turns in the inference is dynamically modeled by both the document and the query, and can be learned automatically according to the difficulty of the problem.\nOne of the significant challenges ReasoNets face is how to design an efficient training method, since the termination state is discrete and not connected to the final output. This prohibits canonical backpropagation method being directly applied to train ReasoNets. Inspired by Williams (1992); Mnih et al. (2014), we tackle this challenge by proposing a novel deep reinforcement learning method called Contrastive Reward (CR) to successfully train ReasoNets. Unlike traditional reinforcement learning optimization methods using a global variable to capture rewards, CR utilizes an instance-based reward baseline assignment. Experiments show the superiority of CR in both training speed and accuracy. Finally, by accounting for a dynamic termination state during inference and applying proposed deep reinforcement learning optimization method, ReasoNets achieve the state-of-the-art results in machine comprehension datasets when the paper is first publicly available in arXiv1, including unstructured CNN and Daily Mail datasets, and a proposed structured Graph Reachability dataset.\nThis paper is organized as follows. In Section 2, we review and compare recent work on machine reading comprehension tasks. In Section 3, we introduce our proposed ReasoNet model architecture and training objectives. Section 4 presents the experimental setting and results on unstructured and structured machine reading comprehension tasks ."}, {"heading": "2 RELATED WORK", "text": "Recently, with large-scale datasets available and the impressive advance of various statistical models, machine reading comprehension tasks have attracted much attention. Here we mainly focus on the related work in cloze-style datasets (Hermann et al., 2015; Hill et al., 2016). Based on how they perform the inference, we can classify their models into two categories: single-turn and multi-turn reasoning.\nSingle-turn reasoning Single turn reasoning models utilize an attention mechanism to emphasis some sections of a document which are relevant to a query. This can be thought of as treating some parts unimportant while focusing on other important ones to find the most probable answer. Hermann et al. (2015) propose the attentive reader and the impatient reader models using neural networks with an attention over passages to predict candidates. Hill et al. (2016) use attention over window-based memory, which encodes a window of words around entity candidates, by leveraging an end-to-end memory network (Sukhbaatar et al., 2015). Meanwhile, given the same entity candidate can appear multiple times in a passage, Kadlec et al. (2016) propose the attention-sum reader to sum up all the attention scores for the same entity. This score captures the relevance between a query and a candidate. Chen et al. (2016) propose using a bilinear term similarity function to calculate attention scores with pretrained word embedding. Trischler et al. (2016) propose the EpiReader which uses two neural network structures: one extracts candidates using the attention-sum reader; the other reranks candidates based on a bilinear term similarity score calculated from query and passage representations.\nMulti-turn reasoning For complex passages and complex queries, human readers often revisit the given document in order to perform deeper inference after reading a document. Several recent studies\n1https://arxiv.org/abs/1609.05284\nAlgorithm 1: Stochastic Inference in a ReasoNet Input :Memory M ; Initial state s1; Step t = 1; Maximum Step Tmax Output :Termination Step T , Answer aT\n1 Sample tt from the distribution p(\u00b7|ftg(st; \u03b8tg)); 2 if tt is false, go to Step 3; otherwise Step 6; 3 Generate attention vector xt = fatt(st,M ; \u03b8x); 4 Update internal state st+1 = RNN(st, xt; \u03b8s); 5 Set t = t+ 1; if t < Tmax go to Step 1; otherwise Step 6; 6 Generate answer at \u223c p(\u00b7|fa(st; \u03b8a)); 7 Return T = t and aT = at;\ntry to simulate this revisit by combining the information in the query with the new information digested from previous iterations (Hill et al., 2016; Dhingra et al., 2016; Sordoni et al., 2016; Weissenborn, 2016; Kumar et al., 2016). Hill et al. (2016) use multiple hops memory network to augment the query with new information from the previous hop. Gated Attention reader (Dhingra et al., 2016) is an extension of the attention-sum reader with multiple iterations by pushing the query encoding into an attention-based gate in each iteration. Iterative Alternative (IA) reader (Sordoni et al., 2016) produces a new query glimpse and document glimpse in each iteration and utilizes them alternatively in the next iteration. Cui et al. (2016) further propose to extend the query-specific attention to both query-to-document attention and document-to-query attention, which is built from the intermediate results in the query-specific attention. By reading documents and enriching the query in an iterative fashion, multi-turn reasoning has demonstrated their superior performance consistently.\nOur proposed approach explores the idea of using both attention-sum to aggregate candidate attention scores and multiple turns to attain a better reasoning capability. Unlike previous approaches using fixed number of hops or iterations, motivated by Nogueira & Cho (2016); Mnih et al. (2014), we propose a termination module in the inference. The termination module can decide whether to continue to infer the next turn after digesting intermediate information, or to terminate the whole inference process when it concludes existing information is sufficient to yield an answer. The number of turns in the inference is dynamically modeled by both a document and a query, and is generally related to the complexity of the document and the query."}, {"heading": "3 REASONING NETWORKS", "text": "ReasoNets are devised to mimic the inference process of human readers. ReasoNets read a document repeatedly, with attention on different parts each time until a satisfying answer is found. As shown in Figure 1, a ReasoNet is composed of the following components:\nInternal State: The internal state is denoted as S which is a vector representation of the question state. Typically, the initial state s1 is the last-word vector representation of query by an RNN. The t-th time step of the internal state is represented by st. The sequence of internal state is modeled by an RNN: st+1 = RNN(st, xt; \u03b8s);\nMemory: The external memory is denoted asM . It is a list of word vectors,M = {mi}i=1..D, where mi is a fixed dimensional vector. In machine comprehensive tasks, mi is the vector representation of each word in the doc by a bidirectional-RNN.\nAttention: Attention vector xt is generated based on the current internal state st and the external memory M : xt = fatt(st,M ; \u03b8x);\nTermination Gate: Termination gate generates a stochastic random variable according to the current internal state; tt \u223c p(\u00b7|ftg(st; \u03b8tg))). tt is a binary random variable. If tt is true, the ReasoNet stops, and the answer module executes at time step t; otherwise the ReasoNet generates an attention vector xt+1, and feed into the state network to update the next internal state st+1.\nAnswer: The action of answer module is triggered when the termination gate variable is true: at \u223c p(\u00b7|fa(st; \u03b8a)).\nIn Algorithm 1, we describe the stochastic inference process of a ReasoNet. The process can be considered as a Partially Observable Markov Decision Process (POMDP) (Kaelbling et al., 1998) in the reinforcement learning (RL) literature. The state sequence s1:T is hidden and dynamic, controlled by an RNN sequence model. The ReasoNet performs an answer action aT at the T -th step, which implies that the termination gate variables t1:T = (t1 = 0, t2 = 0, ..., tT\u22121 = 0, tT = 1). The ReasoNet learns a stochastic policy \u03c0((tt, at)|st; \u03b8) with parameters \u03b8 to get a distribution over termination actions, to continue reading or to stop, and over answer actions if the model decides to stop at the current step. The termination step T varies from instance to instance.\nThe parameters \u03b8 of the ReasoNet are given by the parameters of the embedding matrices W , attention network \u03b8x, the state RNN network \u03b8s, the answer action network \u03b8a, and the termination gate network \u03b8tg . The parameters \u03b8 = {W, \u03b8x, \u03b8s, \u03b8a, \u03b8tg} are trained by maximizing the total expect reward. The expected reward for an instance is defined as:\nJ(\u03b8) = E\u03c0(t1:T ,aT ;\u03b8) [ T\u2211 t=1 rt ]\nThe reward can only be received at the final termination step when an answer action aT is performed. We define rT = 1 if tT = 1 and the answer is correct, and rT = 0 otherwise. The rewards on intermediate steps are zeros, {rt = 0}t=1...T\u22121. J can be maximized by directly applying gradient based optimization methods. The gradient of J is given by:\n\u2207\u03b8J(\u03b8) = E\u03c0(t1:T ,aT ;\u03b8) [\u2207\u03b8log\u03c0(t1:T , aT ; \u03b8)rT ]\nWe apply the REINFORCE algorithm (Williams, 1992) to compute\u2207\u03b8J(\u03b8):\nE\u03c0(t1:T ,aT ;\u03b8) [\u2207\u03b8log\u03c0(t1:T , aT ; \u03b8)rT ] = \u2211\n(t1:T ,aT )\u2208A\u2020 \u03c0(t1:T , aT ; \u03b8) [\u2207\u03b8log\u03c0(t1:T , aT ; \u03b8)(rT \u2212 bT )]\nwhere A\u2020 is all the possible episodes, T, t1:T , aT and rT are the termination step, termination action, answer action, and reward, respectively, for the (t1:T , aT ) episode. bT is called the reward baseline in the RL literature to lower variance (Sutton, 1984). It is common to select bT = E\u03c0 [rT ] (Sutton et al., 1999), and can be updated via an online moving average approach : bT = \u03bbbT + (1\u2212 \u03bb)rT . However, we empirically find that above approach leads to slow convergence in training ReasoNets. Intuitively, the average baselines {bT ;T = 1..Tmax} are global variables independent of instances. It is hard for these baselines to capture the dynamic termination behavior of ReasoNets. In other\nwords, ReasoNets may stop at different time steps for different instances. The adoption of a global variable without considering the dynamic variance in each instance is inappropriate. To resolve this weakness in traditional methods and account for the dynamic characteristic of ReasoNets, we propose an instance-based baseline method called \u201cContrastive Reward\u201d (CR) to calculate\u2207\u03b8J(\u03b8). The basic idea of CR is to utilize an instance-based baseline assignment. We will elaborate its implementation details in Section 3.1. Empirical results show that the proposed reward schema has produced better results compared to the baseline approach."}, {"heading": "3.1 TRAINING DETAILS", "text": "In the machine reading comprehension tasks, a training dataset can be simplified as a collection of triplets of query q, passage p, and answer a. Say \u3008qn, pn, an\u3009 is the n-th training instance. The first step is to extract memory M from pn by mapping each symbolic in the passage to a contextual representation given by the concatenation of forward and backward RNN hidden states, i.e., mk = [\u2212\u2192pnk,\u2190\u2212pn|pn|\u2212k+1], and extract initial state s1 from qn by assigning s1 = [\u2212\u2192qn|qn|,\u2190\u2212qn1]. Given M and s1 for the n-th training instance, a ReasoNet executes |A\u2020| episodes, where all possible episodes A\u2020 can be enumerated by setting a maximum step. Each episode generates actions and a reward from the last step: \u3008(t1:T , aT ), rT \u3009(t1:T ,aT )\u2208A\u2020 . Therefore, the gradient of J can be rewritten as:\n\u2207\u03b8J(\u03b8) = \u2211\n(t1:T ,aT )\u2208A\u2020 \u03c0(t1:T , aT ; \u03b8) [\u2207\u03b8log\u03c0(t1:T , aT ; \u03b8)(rT \u2212 b)]\nwhere the baseline b = \u2211\n(t1:T ,aT )\u2208A\u2020 \u03c0(t1:T , aT ; \u03b8)rT is the average reward on the |A \u2020| episodes\nfor the n-th training instance. It allows different baselines for different training instances. This can be beneficial since the complexity of training instances varies significantly. Since the sum of the proposed rewards over |A\u2020| episodes is zero, \u2211 (t1:T ,aT )\u2208A\u2020 \u03c0(t1:T , aT ; \u03b8)(rT \u2212 b) = 0, we call it Contrastive Reward in this work. In experiments, we empirically find using ( rTb \u2212 1) in replace of (rT \u2212 b) can lead to a faster convergence. Therefore, we adopt this approach to train ReasoNets in the experiments."}, {"heading": "4 EXPERIMENTS", "text": ""}, {"heading": "4.1 CNN AND DAILY MAIL DATASETS", "text": "We evaluate the performance of ReasoNets on CNN and Daily Mail datasets.2 The detailed settings of the ReasoNet model are as follows.\nVocab Size: For training our ReasoNet, we keep the most frequent |V | = 101k words (not including 584 entities and 1 placeholder marker) in the CNN dataset, and |V | = 151k words (not including 530 entities and 1 placeholder marker) in the Daily Mail dataset.\nEmbedding Layer: We choose word embedding size d = 300, and use the 300 dimensional pretrained Glove word embeddings (Pennington et al., 2014) for initialization. We also apply dropout with probability 0.2 to the embedding layer.\nBi-GRU Encoder: We apply bi-directional GRU for encoding query and passage into vector representations. We set the number of hidden units to be 256 and 384 for the CNN and Daily Mail datasets, respectively. The recurrent weights of GRUs are initialized with random orthogonal matrices. The other weights in GRU cell are initialized from a uniform distribution between \u22120.01 and 0.01. We use a shared GRU model for both query and passage.\nMemory and Attention: The memory of the ReasoNet on CNN and Daily Mail dataset is composed of query memory and passage memory. M = (Mquery,Mdoc), where Mquery and Mdoc are extracted from query bidirectional-GRU encoder and passage bidirectional-GRU encoder respectively. We choose projected cosine similarity function as the attention module.\n2The CNN and Daily Mail datasets are available at https://github.com/deepmind/rc-data\nThe attention score adoct,i on memory m doc i given the state st is computed as follows: a doc t,i = softmaxi=1,...,|Mdoc|\u03b3 cos(W doc1 m doc i ,W doc 2 st), where \u03b3 is set to 10. W doc 1 and W doc 2 are weight vectors associated with mdoci and st, respectively, and are joint trained in the ReasoNet. Thus, attention vector on passage is given by xdoct = \u2211|M | i at,im doc i . The final attention vector is the concatenation of the query attention vector and the passage attention vector xt = (x query t , x doc t ). The attention module is parameterized by \u03b8x = (W query 1 ,W query 2 ,W doc 1 ,W doc 2 );\nInternal State Controller: We choose GRU model as the internal state controller. The number of hidden units in the GRU state controller is 256 for CNN and 384 for Daily Mail. The initial state of the GRU controller is set to be the last-word of the query representation by a bidirectional-GRU encoder.\nTermination Module: We adopt a logistical regression to model the termination variable at each time step : ftg(st; \u03b8tg) = sigmoid(Wtgst + btg); \u03b8tg = (Wtg, btg)\nAnswer Module: We apply a linear projection from GRU outputs and make predictions on the entity candidates. Following the settings in AS Reader (Kadlec et al., 2016), we sum up scores from the same candidate and make a prediction. Thus, AS Reader can be viewed as a special case of ReasoNets with Tmax = 1.\nOther Details: The maximum reasoning step, Tmax is set to 5 in experiments on both CNN and Daily Mail datasets. We use ADAM optimizer (Kingma & Ba, 2015) for parameter optimization with an initial learning rate of 0.0005, \u03b21 = 0.9 and \u03b22 = 0.999; The absolute value of gradient on each parameter is clipped within 0.001. The batch size is 64 for both CNN and Daily Mail datasets. For each batch of the CNN and Daily Mail datasets we randomly reshuffle the assignment of named entities (Hermann et al., 2015). This forces the model to treat the named entities as semantically meaningless labels. In the prediction of test cases, we randomly reshuffle named entities up to 4 times, and report the averaged answer. Models are trained on GTX TitanX 12GB. It takes 7 hours per epoch to train on the Daily Mail dataset and 3 hours per epoch to train on the CNN dataset. The models are usually converged within 6 epochs on both CNN and Daily Mail datasets.\nTable 1 shows the performance of all the existing single model baselines and our proposed ReasoNet. By capturing multi-turn reasoning and learning to stop reading a paragraph, we have achieved the state-of-the-art results in both CNN and Daily Mail datasets. To further understand the inference process of the ReasoNet, Figure 2 shows a test example of the CNN dataset. The model initially focuses on wrong entities with low termination probability. In the second and third steps, the model focuses on the right clue with higher termination probability. Interestingly, we also find that query attention focuses on the placeholder token throughout all the steps."}, {"heading": "4.2 GRAPH REACHABILITY TASK", "text": "Recent analysis and results (Chen et al., 2016) on the cloze-style machine comprehension tasks have suggested some simple models without multi-turn reasoning can achieve reasonable performance. Based on these results, we construct a synthetic structured Graph Reachability dataset3 to evaluate longer range machine inference and reasoning capability, since we expect ReasoNets have the capability to handle long range relationships.\nWe generate two synthetic datasets: a small graph dataset and a large graph dataset. In the small graph dataset, it contains 500K small graphs, where each graph contains 9 nodes, and 16 direct edges to randomly connect pairs of nodes. The large graph dataset contains 500K graphs, where each graph contains 18 nodes, and 32 random direct edges. Duplicated edges are removed. Table 2 shows the graph reachability statistics on the two datasets.\nIn Table 3, we show examples of a small graph and a large graph in the synthetic dataset. Both graph and query are represented by a sequence of symbols. In the experiment, we use a 100-dimensional embedding vector for each symbol, and bidirectional-LSTM with 128 and 256 cells for query and graph embedding in the small and the large graph datasets, respectively. The last states of bidirectionalLSTM on query are concatenated to be the initial internal state s1 = [\u2212\u2192q |q|,\u2190\u2212q 1] in the ReasoNet. Another bidirectional-LSTM on graph description maps each symbol gi to a contextual representation given by the concatenation of forward and backward LSTM hidden states mi = [\u2212\u2192g i,\u2190\u2212g |g|\u2212i+1]. The final answer is either \u201cYes\u201d or \u201cNo\u201d and hence logistical regression is used as the answer module: at = \u03c3(Wast + ba); \u03b8a = (Wa, ba). We apply another logistical regression as the termination gate module: tt = \u03c3(Wtgst + btg). The maximum reasoning step Tmax is set to 15 and 25 for the small graph and large graph dataset, respectively.\nWe denote \u201cReasoNet\u201d as the standard ReasoNet with termination gate, as described in Section 3.1. To study the effectiveness of the termination gate in ReasoNets, we remove the termination gate and use the prediction from the last state, a\u0302 = aTmax (Tmax is the maximum reasoning step), denoted as \u201cReasoNet-Last\u201d. To study the effectiveness of multi-turn reasoning, we choose \u201cReasoNet-Tmax = 2\u201d, which only has single-turn reasoning. We compare ReasoNets with a two layer deep LSTM model (Hermann et al., 2015) with 128 hidden units, denoted as \u201cDeep LSTM Reader\u201d, as a baseline. Table 4 shows the performance of these models on the graph reachability dataset. Deep LSTM Reader achieves 90.92% and 71.55% accuracy in the small and large\n3The dataset is available at https://github.com/MSRDL/graph_reachability_dataset\ngraph dataset, respectively, which indicates the graph reachibility task is not trivial. The results of ReasoNet-Tmax = 2 are comparable with the results of Deep LSTM Reader, since both Deep LSTM Reader and ReasoNet-Tmax = 2 perform single-turn reasoning. The ReasoNet-Last model achieves 100% accuracy on the small graph dataset, while the ReasoNet-Last model achieves only 78.95% accuracy on the large graph dataset, as the task becomes more challenging. Meanwhile, the ReasoNet model converges faster than the ReasoNet-Last model. The ReasoNet model converges in 20 epochs in the small graph dataset, and 40 epochs in the large graph dataset, while the ReasoNet-Last model converges around 40 epochs in the small graph dataset, and 70 epochs in the large graph dataset. The results suggest that the termination gate variable in the ReasoNet is helpful when training with sophisticated examples, and makes models converge faster. Both the ReasoNet and ReasoNet-Last models perform better than the ReasoNet-Tmax = 2 model, which demonstrates the importance of multi-turn reasoning.\nTo further understand the inference process in ReasoNets, Figures 3 and 4 show test examples of the large graph dataset. In Figure 3, we can observe that the model does not make a firm prediction till step 9. The highest attention word at each step shows the reasoning process of the model. Interestingly, the model starts from the end node (17), traverses backward till finding the starting node (10) in step 9, and makes a firm termination prediction. On the other hand, in Figure 4, the model learns to stop in step 2. In step 1, the model looks for neighbor nodes (12, 6, 16) to 4 and 9. Then, the model gives up in step 2 and predict \u201cNo\". All of these demonstrate the dynamic termination characteristic and potential reasoning capability of ReasoNets.\nWe show the distribution of termination steps in ReasoNets on the test set in Appendix A. The termination step is chosen with the maximum termination probability p(k) = tk \u220fk\u22121 i=1 (1\u2212 ti), where ti is the termination probability at step i."}, {"heading": "5 CONCLUSION", "text": "In this paper, we propose ReasoNets that dynamically decide whether to continue or to terminate the inference process in machine comprehension tasks. Using reinforcement learning with the proposed contractive reward, our proposed model achieves the start-of-the-art results in machine comprehension datasets, including unstructured CNN and Daily Mail datasets, and a proposed structured Graph\nReachability dataset. For future work, ReasoNets can be generalized to other tasks that requires reasoning capability, such as question answering and knowledge graph inference."}, {"heading": "ACKNOWLEDGMENTS", "text": "We thank Ming-Wei Chang, Li Deng, Lihong Li, and Xiaodong Liu for their thoughtful feedback and discussions."}, {"heading": "A THE TERMINATION STEP DISTRIBUTION IN REASONETS", "text": "In this section, we present the termination step distribution of ReasoNets. Figure 5 and Figure 6 show the termination step distribution of ReasoNets in the CNN dataset and the graph reachability dataset, respectively. The distributions spread out across different steps and there are a large number of instances that terminate in the last step. We study the correlation between the termination steps and the complexity of test instances in Figure 7. We use Breadth-First Search (BFS) algorithm over the target graph given the query to analyze the complexity of test instances. For example, BFS-Step = 2 indicates that there are two intermediate nodes in the shortest reachability path. Test instances with larger BFS-Steps are more challenging. We denote BFS-Step = \u22121 as there is no reachable path for the given query. Figure 7 shows that test instances with larger BFS-Steps require more reasoning steps."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio"], "venue": "In Proceedings of the International Conference on Learning Representations,", "citeRegEx": "Bahdanau et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "From machine learning to machine reasoning", "author": ["L\u00e9on Bottou"], "venue": "Machine Learning,", "citeRegEx": "Bottou.,? \\Q2014\\E", "shortCiteRegEx": "Bottou.", "year": 2014}, {"title": "A thorough examination of the CNN / Daily Mail reading comprehension", "author": ["Danqi Chen", "Jason Bolton", "Christopher D Manning"], "venue": null, "citeRegEx": "Chen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Attention-over-attention neural networks for reading", "author": ["Yiming Cui", "Zhipeng Chen", "Si Wei", "Shijin Wang", "Ting Liu", "Guoping Hu"], "venue": "comprehension. CoRR,", "citeRegEx": "Cui et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Cui et al\\.", "year": 2016}, {"title": "Gated-attention readers for text", "author": ["Bhuwan Dhingra", "Hanxiao Liu", "William W. Cohen", "Ruslan Salakhutdinov"], "venue": "comprehension. CoRR,", "citeRegEx": "Dhingra et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Dhingra et al\\.", "year": 2016}, {"title": "Teaching machines to read and comprehend", "author": ["Karm Moritz Hermann", "Tom\u00e1\u0161 Ko\u010disk\u00fd", "Edward Grefenstette", "Lasse Espeholt", "Will Kay", "Mustafa Suleyman", "Phil Blunsom"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Hermann et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hermann et al\\.", "year": 2015}, {"title": "The Goldilocks principle: Reading children\u2019s books with explicit memory representations", "author": ["Felix Hill", "Antoine Bordes", "Sumit Chopra", "Jason Weston"], "venue": "In Proceedings of the International Conference on Learning Representations,", "citeRegEx": "Hill et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hill et al\\.", "year": 2016}, {"title": "Text understanding with the attention sum reader network. arXiv:1603.01547v1 [cs.CL], 2016", "author": ["Rudolf Kadlec", "Martin Schmid", "Ondrej Bajgar", "Jan Kleindienst"], "venue": null, "citeRegEx": "Kadlec et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Kadlec et al\\.", "year": 2016}, {"title": "Planning and acting in partially observable stochastic domains", "author": ["Leslie Pack Kaelbling", "Michael L. Littman", "Anthony R. Cassandra"], "venue": "Artificial Intelligence,", "citeRegEx": "Kaelbling et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Kaelbling et al\\.", "year": 1998}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik P. Kingma", "Jimmy Ba"], "venue": "In Proceedings of the International Conference on Learning Representations,", "citeRegEx": "Kingma and Ba.,? \\Q2015\\E", "shortCiteRegEx": "Kingma and Ba.", "year": 2015}, {"title": "Dynamic entity representation with maxpooling improves machine reading", "author": ["Sosuke Kobayashi", "Ran Tian", "Naoaki Okazaki", "Kentaro Inui"], "venue": "In Proceedings of the North American Chapter of the Association for Computational Linguistics and Human Language Technologies (NAACL-HLT),", "citeRegEx": "Kobayashi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Kobayashi et al\\.", "year": 2016}, {"title": "Ask me anything: Dynamic memory networks for natural language processing", "author": ["Ankit Kumar", "Ozan Irsoy", "Peter Ondruska", "Mohit Iyyer", "James Bradbury", "Ishaan Gulrajani", "Victor Zhong", "Romain Paulus", "Richard Socher"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "Kumar et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Kumar et al\\.", "year": 2016}, {"title": "Recurrent models of visual attention", "author": ["Volodymyr Mnih", "Nicolas Heess", "Alex Graves"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Mnih et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2014}, {"title": "Webnav: A new large-scale task for natural language based sequential decision making", "author": ["Rodrigo Nogueira", "Kyunghyun Cho"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Nogueira and Cho.,? \\Q2016\\E", "shortCiteRegEx": "Nogueira and Cho.", "year": 2016}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D. Manning"], "venue": "In EMNLP,", "citeRegEx": "Pennington et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "SQuAD: 100, 000+ questions for machine comprehension of text", "author": ["Pranav Rajpurkar", "Jian Zhang", "Konstantin Lopyrev", "Percy Liang"], "venue": "In EMNLP,", "citeRegEx": "Rajpurkar et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Rajpurkar et al\\.", "year": 2016}, {"title": "MCTest: A challenge dataset for the opendomain machine comprehension of text", "author": ["Matthew Richardson", "Christopher JC Burges", "Erin Renshaw"], "venue": "In EMNLP,", "citeRegEx": "Richardson et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Richardson et al\\.", "year": 2013}, {"title": "Iterative alternating neural attention for machine", "author": ["Alessandro Sordoni", "Phillip Bachman", "Yoshua Bengio"], "venue": "reading. CoRR,", "citeRegEx": "Sordoni et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sordoni et al\\.", "year": 2016}, {"title": "End-to-end memory networks", "author": ["Sainbayar Sukhbaatar", "Jason Weston", "Rob Fergus"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Sukhbaatar et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sukhbaatar et al\\.", "year": 2015}, {"title": "Policy gradient methods for reinforcement learning with function approximation", "author": ["Richard S. Sutton", "David McAllester", "Satinder Singh", "Yishay Mansour"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Sutton et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 1999}, {"title": "Temporal Credit Assignment in Reinforcement Learning", "author": ["Richard Stuart Sutton"], "venue": "PhD thesis,", "citeRegEx": "Sutton.,? \\Q1984\\E", "shortCiteRegEx": "Sutton.", "year": 1984}, {"title": "Natural language comprehension with the EpiReader", "author": ["Adam Trischler", "Zheng Ye", "Xingdi Yuan", "Kaheer Suleman"], "venue": "In EMNLP,", "citeRegEx": "Trischler et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Trischler et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 1, "context": "Teaching machines to read, process, and comprehend natural language documents is a coveted goal for artificial intelligence (Bottou, 2014; Richardson et al., 2013; Hermann et al., 2015).", "startOffset": 124, "endOffset": 185}, {"referenceID": 16, "context": "Teaching machines to read, process, and comprehend natural language documents is a coveted goal for artificial intelligence (Bottou, 2014; Richardson et al., 2013; Hermann et al., 2015).", "startOffset": 124, "endOffset": 185}, {"referenceID": 5, "context": "Teaching machines to read, process, and comprehend natural language documents is a coveted goal for artificial intelligence (Bottou, 2014; Richardson et al., 2013; Hermann et al., 2015).", "startOffset": 124, "endOffset": 185}, {"referenceID": 16, "context": "Toward solving this machine reading comprehension problem, in recent years, several work has collected various datasets, in the form of question, passage, and answer, to test machine on answering a question based on the provided passage (Richardson et al., 2013; Hermann et al., 2015; Hill et al., 2016; Rajpurkar et al., 2016).", "startOffset": 237, "endOffset": 327}, {"referenceID": 5, "context": "Toward solving this machine reading comprehension problem, in recent years, several work has collected various datasets, in the form of question, passage, and answer, to test machine on answering a question based on the provided passage (Richardson et al., 2013; Hermann et al., 2015; Hill et al., 2016; Rajpurkar et al., 2016).", "startOffset": 237, "endOffset": 327}, {"referenceID": 6, "context": "Toward solving this machine reading comprehension problem, in recent years, several work has collected various datasets, in the form of question, passage, and answer, to test machine on answering a question based on the provided passage (Richardson et al., 2013; Hermann et al., 2015; Hill et al., 2016; Rajpurkar et al., 2016).", "startOffset": 237, "endOffset": 327}, {"referenceID": 15, "context": "Toward solving this machine reading comprehension problem, in recent years, several work has collected various datasets, in the form of question, passage, and answer, to test machine on answering a question based on the provided passage (Richardson et al., 2013; Hermann et al., 2015; Hill et al., 2016; Rajpurkar et al., 2016).", "startOffset": 237, "endOffset": 327}, {"referenceID": 5, "context": "Some large-scale cloze-style datasets (Hermann et al., 2015; Hill et al., 2016) have gained significant attention along with powerful deep learning models.", "startOffset": 38, "endOffset": 79}, {"referenceID": 6, "context": "Some large-scale cloze-style datasets (Hermann et al., 2015; Hill et al., 2016) have gained significant attention along with powerful deep learning models.", "startOffset": 38, "endOffset": 79}, {"referenceID": 0, "context": "Single turn reasoning models utilize attention mechanisms (Bahdanau et al., 2015) with deep learning models to emphasize specific parts of the document which are relevant to the query.", "startOffset": 58, "endOffset": 81}, {"referenceID": 6, "context": "sentences or words) to score target candidates (Hill et al., 2016; Hermann et al., 2015; Kadlec et al., 2016).", "startOffset": 47, "endOffset": 109}, {"referenceID": 5, "context": "sentences or words) to score target candidates (Hill et al., 2016; Hermann et al., 2015; Kadlec et al., 2016).", "startOffset": 47, "endOffset": 109}, {"referenceID": 7, "context": "sentences or words) to score target candidates (Hill et al., 2016; Hermann et al., 2015; Kadlec et al., 2016).", "startOffset": 47, "endOffset": 109}, {"referenceID": 6, "context": "With this motivation, recent advances in reading comprehension have made use of multiple turns to infer the relation between query, document and answer (Hill et al., 2016; Dhingra et al., 2016; Trischler et al., 2016; Sordoni et al., 2016).", "startOffset": 152, "endOffset": 239}, {"referenceID": 4, "context": "With this motivation, recent advances in reading comprehension have made use of multiple turns to infer the relation between query, document and answer (Hill et al., 2016; Dhingra et al., 2016; Trischler et al., 2016; Sordoni et al., 2016).", "startOffset": 152, "endOffset": 239}, {"referenceID": 21, "context": "With this motivation, recent advances in reading comprehension have made use of multiple turns to infer the relation between query, document and answer (Hill et al., 2016; Dhingra et al., 2016; Trischler et al., 2016; Sordoni et al., 2016).", "startOffset": 152, "endOffset": 239}, {"referenceID": 17, "context": "With this motivation, recent advances in reading comprehension have made use of multiple turns to infer the relation between query, document and answer (Hill et al., 2016; Dhingra et al., 2016; Trischler et al., 2016; Sordoni et al., 2016).", "startOffset": 152, "endOffset": 239}, {"referenceID": 5, "context": "(2016) also illustrates the huge variations in the difficulty level with respect to questions in the CNN/Daily Mail datasets (Hermann et al., 2015).", "startOffset": 125, "endOffset": 147}, {"referenceID": 5, "context": "Here we mainly focus on the related work in cloze-style datasets (Hermann et al., 2015; Hill et al., 2016).", "startOffset": 65, "endOffset": 106}, {"referenceID": 6, "context": "Here we mainly focus on the related work in cloze-style datasets (Hermann et al., 2015; Hill et al., 2016).", "startOffset": 65, "endOffset": 106}, {"referenceID": 18, "context": "(2016) use attention over window-based memory, which encodes a window of words around entity candidates, by leveraging an end-to-end memory network (Sukhbaatar et al., 2015).", "startOffset": 148, "endOffset": 173}, {"referenceID": 6, "context": "try to simulate this revisit by combining the information in the query with the new information digested from previous iterations (Hill et al., 2016; Dhingra et al., 2016; Sordoni et al., 2016; Weissenborn, 2016; Kumar et al., 2016).", "startOffset": 130, "endOffset": 232}, {"referenceID": 4, "context": "try to simulate this revisit by combining the information in the query with the new information digested from previous iterations (Hill et al., 2016; Dhingra et al., 2016; Sordoni et al., 2016; Weissenborn, 2016; Kumar et al., 2016).", "startOffset": 130, "endOffset": 232}, {"referenceID": 17, "context": "try to simulate this revisit by combining the information in the query with the new information digested from previous iterations (Hill et al., 2016; Dhingra et al., 2016; Sordoni et al., 2016; Weissenborn, 2016; Kumar et al., 2016).", "startOffset": 130, "endOffset": 232}, {"referenceID": 11, "context": "try to simulate this revisit by combining the information in the query with the new information digested from previous iterations (Hill et al., 2016; Dhingra et al., 2016; Sordoni et al., 2016; Weissenborn, 2016; Kumar et al., 2016).", "startOffset": 130, "endOffset": 232}, {"referenceID": 4, "context": "Gated Attention reader (Dhingra et al., 2016) is an extension of the attention-sum reader with multiple iterations by pushing the query encoding into an attention-based gate in each iteration.", "startOffset": 23, "endOffset": 45}, {"referenceID": 17, "context": "Iterative Alternative (IA) reader (Sordoni et al., 2016) produces a new query glimpse and document glimpse in each iteration and utilizes them alternatively in the next iteration.", "startOffset": 34, "endOffset": 56}, {"referenceID": 8, "context": "The process can be considered as a Partially Observable Markov Decision Process (POMDP) (Kaelbling et al., 1998) in the reinforcement learning (RL) literature.", "startOffset": 88, "endOffset": 112}, {"referenceID": 20, "context": "bT is called the reward baseline in the RL literature to lower variance (Sutton, 1984).", "startOffset": 72, "endOffset": 86}, {"referenceID": 19, "context": "It is common to select bT = E\u03c0 [rT ] (Sutton et al., 1999), and can be updated via an online moving average approach : bT = \u03bbbT + (1\u2212 \u03bb)rT .", "startOffset": 37, "endOffset": 58}, {"referenceID": 14, "context": "Embedding Layer: We choose word embedding size d = 300, and use the 300 dimensional pretrained Glove word embeddings (Pennington et al., 2014) for initialization.", "startOffset": 117, "endOffset": 142}, {"referenceID": 7, "context": "Following the settings in AS Reader (Kadlec et al., 2016), we sum up scores from the same candidate and make a prediction.", "startOffset": 36, "endOffset": 57}, {"referenceID": 5, "context": "For each batch of the CNN and Daily Mail datasets we randomly reshuffle the assignment of named entities (Hermann et al., 2015).", "startOffset": 105, "endOffset": 127}, {"referenceID": 5, "context": "CNN Daily Mail valid test valid test Deep LSTM Reader (Hermann et al., 2015) 55.", "startOffset": 54, "endOffset": 76}, {"referenceID": 17, "context": "9 - Iterative Attention Reader (Sordoni et al., 2016) 72.", "startOffset": 31, "endOffset": 53}, {"referenceID": 2, "context": "Recent analysis and results (Chen et al., 2016) on the cloze-style machine comprehension tasks have suggested some simple models without multi-turn reasoning can achieve reasonable performance.", "startOffset": 28, "endOffset": 47}, {"referenceID": 5, "context": "We compare ReasoNets with a two layer deep LSTM model (Hermann et al., 2015) with 128 hidden units, denoted as \u201cDeep LSTM Reader\u201d, as a baseline.", "startOffset": 54, "endOffset": 76}], "year": 2016, "abstractText": "Teaching a computer to read a document and answer general questions pertaining to the document is a challenging yet unsolved problem. In this paper, we describe a novel neural network architecture called the Reasoning Network (ReasoNet) for machine comprehension tasks. ReasoNets make use of multiple turns to effectively exploit and then reason over the relation among queries, documents, and answers. Different from previous approaches using a fixed number of turns during inference, ReasoNets introduce a termination state to relax this constraint on the reasoning depth. With the use of reinforcement learning, ReasoNets can dynamically determine whether to continue the comprehension process after digesting intermediate results, or to terminate reading when it concludes that existing information is adequate to produce an answer. ReasoNets have achieved state-of-the-art performance in machine comprehension datasets, including unstructured CNN and Daily Mail datasets, and a structured Graph Reachability dataset.", "creator": "LaTeX with hyperref package"}, "id": "ICLR_2017_424"}