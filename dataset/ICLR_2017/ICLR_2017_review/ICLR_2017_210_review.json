{"id": "ICLR_2017_210", "reviews": [{"review": "This paper presents an algorithm for approximating the solution of certain time-evolution PDEs. The paper presents an interesting learning-based approach to solve such PDEs. The idea is to alternate between:\n1. sampling points in space-time\n2. generating solution to PDE at \"those\" sampled points\n3. regressing a space-time function to satisfy the latter solutions at the sampled points (and hopefully generalize beyond those points).\n\nI actually find the proposed algorithm interesting, and potentially useful in practice. The classic grid-based simulation of PDEs is often too expensive to be practical, due to the curse of dimensionality. Hence, learning the solution of PDEs makes a lot of sense for practical settings. On the other hand, as the authors point out, simply running gradient descent on the regression loss function does not work, because of the non-differentiablity of the \"min\" that shows up in the studied PDEs.\n\nTherefore, I think the proposed idea is actually very interesting approach to learning the PDE solution in presence of non-differentability, which is indeed a \"challenging\" setup for numerically solving PDEs.\n\nThe paper motivates the problem (time-evolution PDE with \"min\" operator applied to the spatial derivatives) by applications in control thery, but I think there is more direct interest in such problems for the machine learning community, and even deep learning community. For example http://link.springer.com/chapter/10.1007/978-3-319-14612-6_4 studies approximate solution to PDEs with very similar properties (evolution+\"min\") to develop new optimization algorithms. The latter is indeed used to training deep networks: https://arxiv.org/abs/1601.04114\n\nI think this work would catch even more attention if the authors could show some experiments with higher-dimensional problems (where grid-based methods are absolutely inapplicable).\n\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, {"review": "Approximating solutions to PDEs with NN approximators is very hard. In particular the HJB and HJI eqs have in general discontinuous and non-differentiable solutions making them particularly tricky (unless the underlying process is a diffusion in which case the Ito term makes everything smooth, but this paper doesn't do that). What's worse, there is no direct correlation between a small PDE residual and a well performing-policy [tsitsiklis? beard? todorov?, I forget]. There's been lots of work on this which is not properly cited. \n\nThe 2D toy examples are inadequate. What reason is there to think this will scale to do anything useful? \n\nThere are a bunch of typos (\"Range-Kutta\"?) .\n\nMore than anything, this paper is submitted to the wrong venue. There are no learned representations here. You're just using a NN. That's not what ICLR is about. Resubmit to ACC, ADPRL or CDC.\n\nSorry for terseness. Despite rough review, I absolutely love this direction of research. More than anything, you have to solve harder control problems for people to take notice...", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, {"review": "I have no familiarity with the HJI PDE (I've only dealt with parabolic PDE's such as diffusion in the past). So the details of transforming this problem into a supervised loss escape me. Therefore, as indicated below, my review should be taken as an \"educated guess\". I imagine that many readers of ICLR will face a similar problem as me, and so, if this paper is accepted, at the least the authors should prepare an appendix that provides an introduction to the HJI PDE. At a high level, my comments are:\n\n1. It seems that another disadvantage of this approach is that a new network must be trained for each new domain (including domain size), system function f(x) or boundary condition. If that is correct, I wonder if it's worth the trouble when existing tools already solve these PDE's. Can the authors shed light on a more \"unifying approach\" that would require minimal changes to generalize across PDE's?\n\n2. How sensitive is the network's result to domains of different sizes? It seems only a single size 51 x 51 was tested. Do errors increase with domain size?\n\n3. How general is this approach to PDE's of other types e.g. diffusion? \n", "rating": "5: Marginally below acceptance threshold", "confidence": "1: The reviewer's evaluation is an educated guess"}]}