{"id": "ICLR_2017_332", "reviews": [{"review": "The paper shows how group convolutions (for two dimensional commutative groups) can be performed by standard CNNs if the input is warped using a fixed warp. The idea is practical and seems to work well. The paper is well written.\n\nI agree with reviewer 1 that the \u2018theorems\u2019 do not deserve to be labelled as such. Theorem 1 is equivalent to the second equation from this section of the wikipedia page on convolution: https://en.wikipedia.org/wiki/Convolution#Convolutions_on_groups. The existence of Haar measure (from which commutation of Lg and convolution follows immediately) is a well known and elementary theorem in harmonic analysis, which would be treated in the first few pages of any textbook on the subject. It also immediately clear that any commutative group has an additive parameterization (theorem 2). The fact that the paper does not present new deep mathematical results is not a significant weakness in my opinion, but the derivations should not be camouflaged as such.\n\nThe claim that previous methods that use group convolutions are slow and that the presented approach has better computational complexity is not supported by empirical evidence, and the theoretical analysis is still a bit misleading. For example, the authors write \u201cUnfortunately these approaches do not possess the same memory and speed benefits that CNNs enjoy. The reason is that, ultimately, they have to enumerate all possible transformations\u201d. The presented method also has to enumerate all transformations (in a limited range, on a discretized grid), and this is feasible only because the group is only 2 dimensional (and indeed this is also true for standard CNNs which enumerate translations). \n\nAs noted in my pre-review question, I believe the computational complexity analysis is not entirely correct, and assume the authors will correct this.\n\nEquation 4 is presented as a new invention, but this has been used in previous works and is well known in mathematics, so a citation should be added.\n\nThe main advantage of the presented method over several earlier methods is that it is very simple to implement, and can re-use highly optimized convolution routines. As I understand it, Dieleman et al. and Cohen & Welling also use standard convolutions (after a fixed filter / feature map warp), but these papers only consider discrete groups. So it seems like this paper occupies a unique place in the space of equivariant convolutional networks: non-commutative (-), low-dimensional (-), continuous (+) groups, simple (+) and efficient (+) algorithm. Given the proximity though, a more thorough and balanced appraisal of the merits and demerits, as well as the novelty, relative to each of the previous works would be useful. \n\nProvided that these issues are cleared up, I would recommend the paper for publication.", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, {"review": "The paper suggests method to make the convolution invariant to other type of spatial transformations besides translation. It is interesting that the convolution can be invariant to different variation types by simple warping of the input image, which is related to arbitrary data perturbation in image recognition.\nExperiment section needs more description and technique implementation details.\nThe relationship of theorems to Lie group is not defined properly.\nIt need more detailed comparison of method with available methods in the literature. \n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, {"review": "This paper deals with convolution along Lie groups.\n\nPros:\n- Good numerical results\n- Interesting applications linked to convolutions on Lie groups\n\nCons:\n- Sometimes, the writing is not clear/poor.\n- The theorems 1 and 2 are in fact direct applications of Lie group theory, but this is not made explicit.\n\nI do not detail more my review, as I believe my questions/answers complete it fairly. However, if the authors require it, I can be more specific. I think the writing should be improved a bit.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}]}