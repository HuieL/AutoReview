{"id": "ICLR_2017_41", "reviews": [{"review": "Update: I thank the authors for their comments! After reading them, I still think the paper is not novel enough so I'm leaving the rating untouched.\n\nThis paper proposes a domain adaptation technique for time series. The core of the approach is a combination of variational recurrent neural networks and adversarial domain adaptation (at the last time step).\n\nPros:\n\n1. The authors consider a very important application of domain adaptation.\n\n2. The paper is well-written and relatively easy to read.\n\n3. Solid empirical evaluation. The authors compare their method against several recent domain adaptation techniques on a number of datasets.\n\nCons:\n\n1. The novelty of the approach is relatively low: it\u2019s just a straightforward fusion of the existing techniques.\n\n2. The paper lacks any motivation for use of the particular combination (VRNN and RevGrad). I still believe comparable results can be obtained by polishing R-DANN (e.g. carefully penalizing domain discrepancy at every step)\n\nAdditional comments:\n\n1. I\u2019m not convinced by the discussion presented in Section 4.4. I don\u2019t think the visualization of firing patterns can be used to support the efficiency of the proposed method.\n\n2. Figure 1(c) looks very suspicious. I can hardly believe t-SNE could produce this _very_ regular structure for non-degenerate (non-synthetic, real-world) data.\n\nOverall, it\u2019s a solid paper but I\u2019m not sure if it is up to the ICLR standard.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, {"review": "The work combines variational recurrent neural networks, and adversarial neural networks to handle domain adaptation for time series data. The proposed method, along with several competing algorithms are compared on two healthcare datasets constructed from MIMIC-III in domain adaptation settings.\n\nThe new contribution of the work is relatively small. It extends VRNN with adversarial training for learning domain agnostic representations. From the experimental results, the proposed method clearly out-performs competing algorithms. However, it is not clear where the advantage is coming from. The only difference between the proposed method and R-DANN is using variational RNN vs RNN. Little insights were provided on how this could bring such a big difference in terms of performance and the drastic difference in the temporal dependencies captured by these two methods in Figure 4.  \n\nDetailed comments:\n1. Please provide more details on what is plotted in Figure 1. Is 1 (b) is the t-sne projection of representations learned by DANN or R-DANN? The text in section 4.4 suggests it\u2019s the later case. It is surprising to see such a regular plot for VRADA.  What do you think are the two dominant latent factors encoded in figure 1 (c)? \n\n2. In Table 2, the two baselines have quite significant difference in performance testing on the entire target (including validation set) vs on the test set only. VRADA, on the other hand, performs almost identical in these two settings. Could you please offer some explanation on this?\n\n3. Please explain figure 3 and 4 in more details. how to interpret the x-axis of figure 3, and the x and y axes of figure 4. Again the right two plots in figure 4 are extremely regular comparing to the ones on the left. \n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, {"review": "This paper combines variational RNN (VRNN) and domain adversarial networks (DANN) for domain adaptation in the sequence modelling domain.  The VRNN is used to learn representations for sequential data, which is the hidden states of the last time step.  The DANN is used to make the representations domain invariant, therefore achieving cross domain adaptation.\n\nExperiments are done on a number of data sets, and the proposed method (VRADA) outperforms baselines including DANN, VFAE and R-DANN on almost all of them.\n\nI don't have questions about the proposed model, the model is quite clear and seems to be a simple combination of VRNN and DANN.  But a few questions came up during the pre-review question phase:\n\n- As the authors have mentioned, DANN in general outperforms MMD based methods, however, the VFAE method which is based on MMD regularization on the representations seems to outperform DANN across the board.  That seems to indicate VRNN + MMD should also be a good combination.\n\n- One baseline the authors showed in the experiments is R-DANN, which is an RNN version of DANN.  There are two differences between R-DANN and VRADA: (1) R-DANN uses deterministic RNN for representation learning, while VRADA uses variational RNN; (2) on target domain R-DANN only optimizes adversarial loss, while VRADA optimizes both adversarial loss and reconstruction loss for feature learning.  It would be good to analyze further where the performance gain comes from.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}]}