{"id": "ICLR_2017_45", "reviews": [{"review": "First I would like to apologize for the late review.\n\nThis paper proposes an extension of the NPI model (Reed & de Freitas) by using an extension of the probabilistic stacks introduced in Mikolov et al.. This allows them to train their model with less supervision than Reed & de Freitas. \n\nOverall the model is a nice extension of NPI. While it requires less supervision than NPI, it still requires \"sequences of elementary operations paired with environment observations, and [...] a couple of examples which include the full abstraction hierarchy\". This may limit the scope of this work.\n\nThe paper claims that their \"method is leverages stronger supervision in the form of elementary action sequences rather than just input-output examples (sic).  Such sequences are relatively easy to gather in many natural settings\". It would be great if the authors clarify what they mean by \"relatively easy to gather in many natural settings\". They also claim that \"the additional supervision improves the data efficiency and allow our technique to scale to more complicated problems\". However, this paper only addresses two toy problems which are neither \"natural settings\" nor of a large scale (or at least not larger than those addressed in the related literature, see Zaremba et al. for addition). \n\nIn the introduction, the author states that \"Existing techniques, however, cannot be applied on data like this because it does not contain the abstraction hierarchy.\" What are the \"existing techniques\", they are referring to? This work only addresses the problem of long addition and puzzle solving in a block world. Afaik, Zaremba et al. has shown that with no supervision, it can solve the long addition problem and Sukhbaatar et al. (\"Mazebase: A sandbox for learning from games\") shows that a memory network can solve puzzles in a blockworld with little supervision.\n\nIn the conclusion,  the author states that \"remarkably, NPL achieves state-of-the-art performances with much less supervision compared to existing models, making itself more applicable to real-world applications where full program traces are hard to get.\" However for all the experiments, they \"include a small number of FULL samples\" (FULL == \"samples with full program traces\"). Unfortunately even if this means that they need less FULL examples, they still need \"full program traces\", contradicting their final claim. Moreover, as shown figure 7, their model does not use a \"small number of FULL samples\" but rather a significantly smaller amount of FULL examples than NPI, i.e., 16 vs 128. \n\n\"All experiments were run with 10 different random seeds\": does the environment change as well between the runs, i.e. are the FULL examples different between the runs? If it is the case and since you select the best run (on a validation set), the NPL model does not consume 16 FULL examples but 160 FULL examples for nanoCraft. \n\nConcerning the NanoCraft example, it would be good to have more details about how the examples are generated: how do you make sure that the train/val/test sets are different? How the rectangular shape are generated? If I consider all possible rectangles in a 6x6 grid, there are (6x6)x(6x6)/2 = 648 possibilities, thus taking 256 examples sum up to ~40% of the total number of rectangles. This does not even account for the fact that from an initial state, many rectangles can be made, making my estimate probably lower than the real coverage of examples.\n\nConcerning the addition, it would interesting to show what an LSTM would do: Take a 2 layer LSTM that takes the 2 current digits as an input and produce the current output ( \"123+45\" would be input[0] = [3,5], input[1]=[2,4], input[2]=[1, 0] and output[0] = 8...). I would be curious to see how such baseline would work. It can be trained on input/output and it is barely different from a standard sequence model. Also, would it be possible to compare with Zaremba et al.?\n\nFinally, as discussed previously with the authors, it would be good if they discuss more in length the relation between their probabilistic stacks and Mikolov et al.. They have a lot of similarities and it is not addressed in the current version. It should be addressed in the section describing the approach. I believe the authors agreed on this and I will wait for the updated version.\n\nOverall, it is a nice extension of Reed & de Freitas, but I'm a bit surprised by the lack of discussion about the rest of the literature (beside Reed & de Freitas, most previous work are only lightly discussed in the related work). This would have been fine if this paper would not suffer from a relatively weak experiment section that does not support the claims made in this work or show results that were not obtained by others before. \n\nMissing references:\n\"Learning simple arithmetic procedures\", Cottrell et al.\n\"Neural gpus learn algorithms\", Kaiser & Sutskever\n\"Mazebase: A sandbox for learning from games\", Sukhbaatar et al.\n\"Learning simple algorithms from examples\", Zaremba et al.\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, {"review": "The paper presents the Neural Program Lattice (NPL), extending the previous Neural Programmer-Interpreters (NPI). The main idea is to generalize stack manipulation of NPI by making it probabilistic. This allows the content of the stack to be stochastic than deterministic, and the paper describes the feed-forward steps of NPL's program inference similar to the NPI formulation. A new objective function is provided to train the model that maximizes the probability of NPL model correctly predicting operation sequences, from execution traces. We believe this is an important extension. The experimental results illustrate that the NPL is able to learn task executions in a clean setting with perfect observations.\n\nThe paper is clearly presented and its background literature (i.e., NPI) is well covered. We also believe the paper is presenting a conceptually/technically meaningful extension of NPI, which will be of interest to a broad audience. We are still a bit concerned whether the NPL would be directly applicable for noisy observations (e.g., human skeletons) in a continuous space with less explicit structure, so more discussions will be interesting.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, {"review": "Neural Programmer-Interpreters (NPI) achieves greatly reduced sample complexity and better generalization than flat seq2seq models for program induction, but requires program traces at multiple levels of abstraction for training, which is a very strong form of supervision. One obvious way to improve this situation, addressed in this work, is to only train on the lowest-level traces, with a latent compositional program structure. This makes sense because the \"raw\" low-level traces can be cheaply gathered in many cases just by watching expert demonstrations, without being explicitly told the more temporally abstract structures.\n\nThis paper shows that a variant of NPI, named NPL, can achieve even better generalization performance with weaker supervision (mostly flat traces), and also extends the model to a new grid world task. Unfortunately, it still requires being told the overall program structure by being given a few *full* execution traces. Still, I see this as important progress. It extends NPI in a quite nontrivial way by introducing a stack mechanism modeling the latent program call structure, which makes the training process much more closely match what the model does at test time. The results tell us that flat execution traces can take us almost all the way toward learning compositional programs from demonstrations - the hard part is of course learning to actually discover the subprogram structure.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}]}