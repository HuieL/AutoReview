{"id": "ICLR_2017_48", "reviews": [{"review": "This paper proposed an integration of memory network with reinforcement learning. The experimental data is simple, but the model is very interesting and relatively novel. There are some questions about the model:\n\n1. how does the model extend to the case with multiple variables in a single sentence?\n\n2. If the answer is out of vocabulary, how would the model handle it?\n\n3. I hope the authors can provide more analysis about the curriculum learning part, since it is very important for the RL model training.\n\n4. In the training, in each iteration, how the data samples were selected, by random or from simple one depth to multiple depth? \n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, {"review": "This paper introduces a nice dataset/data generator that creates bAbI like tasks, except where the questioning answering agent is required to clarify the values of some variables in order to succeed.  I think the baselines the authors use to test the tasks are appropriate.   I am a bit worried that the tasks may be too easy (as the bAbI tasks have been), but still, I think locally these will be useful.  If the generation code is well written, and the tasks are extensible, they may be useful for some time.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, {"review": "This paper investigates a set of tasks that augment the basic bAbI problems. In particular, some of the people and objects in the scenarios are replaced with unknown variables. Some of these variables must be known to solve the question, thus the agent must learn to query for the values of these variables. Interestingly, one can now measure both the performance of the agent in correctly answering the question, and its efficiency in asking for the values of the correct unknown variables (and not variables that are unnecessary to answer the question). This inferring of unknown variables goes beyond what is required for the vanilla version of the bAbI tasks, which are now more or less solved.\n\nThe paper is well-written, and the contributions are clear. Due to the very limited vocabulary and structure of the bAbI problems in general, I think these tasks (and variants on them) should be viewed more as basic reasoning tasks than natural language understanding. I\u2019m not convinced by the claim of the paper that this really tests the \u2018interaction\u2019 capabilities of agents \u2013 while the task is phrased as a kind of interaction, I think it\u2019s more aptly described by simply \u2018inferring important unknown variables\u2019, which (while important) is more related to reasoning. I\u2019m not sure whether the connection of this ability to \u2018interaction\u2019 is more a superficial one.\n\nThat being said, it is certainly true that conversational agents will need basic reasoning abilities to converse meaningfully with humans. I sympathise with the general goal of the bAbI tasks, which is to test these reasoning abilities in synthetic environments, that are just complicated enough (but not more) to drive the construction of interesting models. I am convinced by the authors that their extension to these tasks are interesting and worthy of future investigation, and thus I recommend the acceptance of the paper.\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}]}